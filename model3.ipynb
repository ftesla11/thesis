{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbasecondad424485431ff4a8aa076a99cfa3fb48c",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "from distcorr import distcorr\n",
    "from fractions import gcd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN = 0\n",
    "\n",
    "def fill_nan(array, REPLACE_COUNT):\n",
    "    array.flat[np.random.choice(array.size, int(REPLACE_COUNT), replace=False)] = NAN\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENABLE/DISABLE GPU\n",
    "# UNCOMMENT to.device() FOR TENSORS AND NEURAL NETWORKS TO ENABLE GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "np.set_printoptions(threshold=sys.maxsize, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 33 columns</p>\n</div>",
      "text/plain": "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0      842302         M        17.99         10.38          122.80     1001.0   \n1      842517         M        20.57         17.77          132.90     1326.0   \n2    84300903         M        19.69         21.25          130.00     1203.0   \n3    84348301         M        11.42         20.38           77.58      386.1   \n4    84358402         M        20.29         14.34          135.10     1297.0   \n..        ...       ...          ...           ...             ...        ...   \n564    926424         M        21.56         22.39          142.00     1479.0   \n565    926682         M        20.13         28.25          131.20     1261.0   \n566    926954         M        16.60         28.08          108.30      858.1   \n567    927241         M        20.60         29.33          140.10     1265.0   \n568     92751         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0    ...          17.33           184.60      2019.0           0.16220   \n1    ...          23.41           158.80      1956.0           0.12380   \n2    ...          25.53           152.50      1709.0           0.14440   \n3    ...          26.50            98.87       567.7           0.20980   \n4    ...          16.67           152.20      1575.0           0.13740   \n..   ...            ...              ...         ...               ...   \n564  ...          26.40           166.10      2027.0           0.14100   \n565  ...          38.25           155.00      1731.0           0.11660   \n566  ...          34.12           126.70      1124.0           0.11390   \n567  ...          39.42           184.60      1821.0           0.16500   \n568  ...          30.37            59.16       268.6           0.08996   \n\n     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0              0.66560           0.7119                0.2654          0.4601   \n1              0.18660           0.2416                0.1860          0.2750   \n2              0.42450           0.4504                0.2430          0.3613   \n3              0.86630           0.6869                0.2575          0.6638   \n4              0.20500           0.4000                0.1625          0.2364   \n..                 ...              ...                   ...             ...   \n564            0.21130           0.4107                0.2216          0.2060   \n565            0.19220           0.3215                0.1628          0.2572   \n566            0.30940           0.3403                0.1418          0.2218   \n567            0.86810           0.9387                0.2650          0.4087   \n568            0.06444           0.0000                0.0000          0.2871   \n\n     fractal_dimension_worst  Unnamed: 32  \n0                    0.11890          NaN  \n1                    0.08902          NaN  \n2                    0.08758          NaN  \n3                    0.17300          NaN  \n4                    0.07678          NaN  \n..                       ...          ...  \n564                  0.07115          NaN  \n565                  0.06637          NaN  \n566                  0.07820          NaN  \n567                  0.12400          NaN  \n568                  0.07039          NaN  \n\n[569 rows x 33 columns]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('breast/breast.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>radius_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>25.380</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>24.990</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>23.570</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>14.910</td>\n      <td>98.87</td>\n      <td>567.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>22.540</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>25.450</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>23.690</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>18.980</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>25.740</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>9.456</td>\n      <td>59.16</td>\n      <td>268.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 6 columns</p>\n</div>",
      "text/plain": "     radius_mean  perimeter_mean  area_mean  radius_worst  perimeter_worst  \\\n0          17.99          122.80     1001.0        25.380           184.60   \n1          20.57          132.90     1326.0        24.990           158.80   \n2          19.69          130.00     1203.0        23.570           152.50   \n3          11.42           77.58      386.1        14.910            98.87   \n4          20.29          135.10     1297.0        22.540           152.20   \n..           ...             ...        ...           ...              ...   \n564        21.56          142.00     1479.0        25.450           166.10   \n565        20.13          131.20     1261.0        23.690           155.00   \n566        16.60          108.30      858.1        18.980           126.70   \n567        20.60          140.10     1265.0        25.740           184.60   \n568         7.76           47.92      181.0         9.456            59.16   \n\n     area_worst  \n0        2019.0  \n1        1956.0  \n2        1709.0  \n3         567.7  \n4        1575.0  \n..          ...  \n564      2027.0  \n565      1731.0  \n566      1124.0  \n567      1821.0  \n568       268.6  \n\n[569 rows x 6 columns]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NARROW THE FEATURES\n",
    "array = np.array(['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst'])\n",
    "processed_data = dataset[array]\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(processed_data.columns)):\n",
    "#     for j in range(i+1, len(processed_data.columns)):\n",
    "#         corr, _ = pearsonr(processed_data[processed_data.columns[i]], processed_data[processed_data.columns[j]])\n",
    "#         print(\"PEARSONR: \", processed_data.columns[i], processed_data.columns[j], corr)\n",
    "#         print(\"DCORR: \", processed_data.columns[i], processed_data.columns[j], distcorr(processed_data[processed_data.columns[j]], processed_data[processed_data.columns[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(processed_data.columns)):\n",
    "#     for j in range(i+1, len(processed_data.columns)):\n",
    "#         processed_data.plot(x=processed_data.columns[i], y=processed_data.columns[j], style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  17.99,  122.8 , 1001.  ,   25.38,  184.6 , 2019.  ])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO NUMPY\n",
    "numpy_data = processed_data.to_numpy()\n",
    "numpy_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE THE DATA\n",
    "scaled_data = scaler.fit_transform(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = scaled_data.copy()\n",
    "missing_data = fill_nan(scaled_data, scaled_data.size*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([3, 4, 3, 2, 4, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 2, 2, 1,\n       2, 4, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 3, 2,\n       2, 3, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 1, 1, 1, 2, 1, 2, 2,\n       1, 2, 1, 2, 3, 1, 3, 2, 2, 3, 2, 3, 4, 2, 2, 2, 5, 3, 2, 3, 2, 3,\n       2, 2, 2, 2, 2, 2, 2, 4, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 4, 2,\n       1, 2, 2, 1, 1, 2, 1, 2, 3, 3, 2, 3, 5, 2, 2, 2, 2, 3, 2, 3, 2, 2,\n       3, 3, 3, 2, 2, 2, 2, 1, 1, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n       2, 2, 3, 3, 2, 1, 2, 3, 3, 2, 4, 2, 1, 3, 3, 2, 2, 2, 2, 1, 1, 1,\n       1, 3, 2, 2, 5, 4, 3, 2, 2, 1, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3,\n       3, 2, 2, 3, 4, 2, 2, 2, 1, 3, 2, 2, 4, 2, 5, 3, 2, 2, 2, 1, 3, 3,\n       2, 2, 1, 3, 2, 2, 1, 2, 2, 2, 3, 2, 1, 4, 1, 2, 4, 4, 2, 3, 2, 2,\n       2, 2, 3, 1, 2, 2, 1, 2, 4, 2, 3, 3, 3, 2, 3, 2, 3, 2, 4, 3, 3, 3,\n       3, 4, 1, 2, 2, 1, 2, 1, 4, 1, 3, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2,\n       2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 3, 2, 4, 1, 2, 2, 2, 1,\n       2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 2, 1, 4, 2, 4, 2, 2, 2, 2, 3, 3,\n       3, 2, 1, 1, 2, 3, 2, 3, 1, 4, 2, 1, 1, 3, 2, 1, 2, 2, 2, 2, 2, 3,\n       5, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 3, 2, 4, 4, 2, 4, 4, 3, 2, 4, 4,\n       2, 3, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 3, 1, 1, 2, 4, 2, 2,\n       2, 2, 1, 2, 3, 2, 2, 2, 2, 1, 3, 2, 3, 2, 2, 1, 1, 2, 2, 2, 1, 2,\n       2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 4, 3, 2, 2, 2, 2, 2, 2,\n       1, 3, 2, 1, 3, 2, 3, 2, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 1, 3, 5,\n       2, 2, 2, 2, 2, 1, 3, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2,\n       3, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 3, 4, 2, 2, 2, 4, 1, 1,\n       2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 5, 1, 2, 1, 1, 2, 2,\n       2, 2, 2, 2, 2, 4, 1, 4, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1,\n       1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 4, 4, 4, 3, 4, 1],\n      dtype=int64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = np.linspace(0, 10)\n",
    "y_binned = np.digitize(full_data[:,0], bins)\n",
    "y_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(missing_data, full_data, stratify=y_binned, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.29, 0.29, 0.17, 0.24, 0.25, 0.12],\n       [0.48, 0.47, 0.33, 0.49, 0.  , 0.31],\n       [0.1 , 0.09, 0.  , 0.06, 0.05, 0.02],\n       [0.59, 0.58, 0.43, 0.57, 0.52, 0.  ],\n       [0.19, 0.19, 0.1 , 0.16, 0.2 , 0.07],\n       [0.53, 0.  , 0.37, 0.49, 0.45, 0.  ],\n       [0.35, 0.36, 0.22, 0.29, 0.31, 0.15],\n       [0.44, 0.  , 0.29, 0.34, 0.36, 0.  ],\n       [0.  , 0.68, 0.57, 0.62, 0.  , 0.  ],\n       [0.  , 0.26, 0.15, 0.2 , 0.  , 0.09],\n       [0.59, 0.59, 0.  , 0.64, 0.6 , 0.46],\n       [0.31, 0.3 , 0.  , 0.26, 0.23, 0.13],\n       [0.26, 0.24, 0.14, 0.19, 0.16, 0.09],\n       [0.  , 0.33, 0.19, 0.32, 0.  , 0.17],\n       [0.39, 0.41, 0.  , 0.44, 0.49, 0.27],\n       [0.17, 0.16, 0.08, 0.15, 0.  , 0.06],\n       [0.15, 0.15, 0.07, 0.12, 0.11, 0.05],\n       [0.21, 0.21, 0.11, 0.  , 0.16, 0.  ],\n       [0.42, 0.43, 0.27, 0.44, 0.4 , 0.27],\n       [0.  , 0.35, 0.  , 0.28, 0.26, 0.14],\n       [0.21, 0.19, 0.11, 0.15, 0.13, 0.  ],\n       [0.58, 0.  , 0.43, 0.58, 0.55, 0.4 ],\n       [0.2 , 0.2 , 0.1 , 0.  , 0.  , 0.07],\n       [0.37, 0.38, 0.  , 0.39, 0.38, 0.22],\n       [0.03, 0.03, 0.01, 0.03, 0.02, 0.01],\n       [0.22, 0.21, 0.12, 0.17, 0.15, 0.07],\n       [0.49, 0.48, 0.33, 0.  , 0.4 , 0.  ],\n       [0.28, 0.  , 0.16, 0.23, 0.  , 0.  ],\n       [0.08, 0.07, 0.03, 0.06, 0.05, 0.02],\n       [0.33, 0.31, 0.  , 0.27, 0.25, 0.  ],\n       [0.43, 0.  , 0.  , 0.  , 0.37, 0.22],\n       [0.31, 0.29, 0.18, 0.24, 0.23, 0.12],\n       [0.27, 0.  , 0.  , 0.21, 0.19, 0.1 ],\n       [0.28, 0.27, 0.15, 0.22, 0.21, 0.  ],\n       [0.33, 0.31, 0.19, 0.26, 0.23, 0.13],\n       [0.12, 0.11, 0.05, 0.09, 0.08, 0.04],\n       [0.19, 0.19, 0.  , 0.14, 0.15, 0.06],\n       [0.54, 0.52, 0.38, 0.48, 0.44, 0.  ],\n       [0.58, 0.61, 0.42, 0.46, 0.5 , 0.28],\n       [0.47, 0.46, 0.32, 0.42, 0.4 , 0.25],\n       [0.37, 0.36, 0.23, 0.29, 0.  , 0.15],\n       [0.57, 0.59, 0.42, 0.44, 0.45, 0.27],\n       [0.  , 0.  , 0.5 , 0.61, 0.54, 0.44],\n       [0.  , 0.  , 0.16, 0.  , 0.17, 0.09],\n       [0.24, 0.23, 0.13, 0.  , 0.17, 0.  ],\n       [0.36, 0.35, 0.21, 0.28, 0.26, 0.14],\n       [0.  , 0.45, 0.3 , 0.39, 0.38, 0.23],\n       [0.24, 0.  , 0.  , 0.2 , 0.  , 0.09],\n       [0.25, 0.25, 0.  , 0.2 , 0.18, 0.09],\n       [0.52, 0.53, 0.  , 0.51, 0.5 , 0.  ],\n       [0.  , 0.15, 0.  , 0.13, 0.12, 0.05],\n       [0.58, 0.  , 0.43, 0.  , 0.48, 0.32],\n       [0.  , 0.43, 0.  , 0.41, 0.39, 0.24],\n       [0.77, 0.  , 0.65, 0.71, 0.67, 0.55],\n       [0.48, 0.48, 0.32, 0.46, 0.  , 0.28],\n       [0.63, 0.64, 0.  , 0.62, 0.6 , 0.  ],\n       [0.49, 0.47, 0.33, 0.44, 0.41, 0.27],\n       [0.32, 0.34, 0.19, 0.29, 0.28, 0.15],\n       [0.34, 0.37, 0.  , 0.26, 0.28, 0.13],\n       [0.29, 0.  , 0.17, 0.25, 0.22, 0.12],\n       [0.52, 0.  , 0.36, 0.47, 0.44, 0.29],\n       [0.31, 0.  , 0.17, 0.26, 0.26, 0.13],\n       [0.33, 0.  , 0.19, 0.  , 0.29, 0.16],\n       [0.38, 0.37, 0.23, 0.31, 0.3 , 0.17],\n       [0.29, 0.27, 0.16, 0.  , 0.2 , 0.11],\n       [0.57, 0.  , 0.42, 0.51, 0.49, 0.33],\n       [0.4 , 0.  , 0.28, 0.54, 0.53, 0.38],\n       [0.22, 0.22, 0.  , 0.19, 0.  , 0.09],\n       [0.42, 0.41, 0.27, 0.44, 0.43, 0.27],\n       [0.  , 0.63, 0.5 , 0.59, 0.56, 0.41],\n       [0.28, 0.28, 0.16, 0.23, 0.27, 0.  ],\n       [0.34, 0.34, 0.21, 0.28, 0.33, 0.15],\n       [0.51, 0.51, 0.35, 0.45, 0.  , 0.27],\n       [0.23, 0.  , 0.12, 0.19, 0.17, 0.09],\n       [0.32, 0.31, 0.18, 0.26, 0.24, 0.13],\n       [0.27, 0.26, 0.15, 0.23, 0.21, 0.  ],\n       [0.3 , 0.29, 0.17, 0.23, 0.21, 0.11],\n       [0.59, 0.62, 0.  , 0.61, 0.64, 0.43],\n       [0.21, 0.  , 0.11, 0.16, 0.14, 0.07],\n       [0.29, 0.29, 0.  , 0.28, 0.26, 0.14],\n       [0.16, 0.15, 0.08, 0.12, 0.11, 0.05],\n       [0.16, 0.16, 0.  , 0.13, 0.11, 0.  ],\n       [0.84, 0.84, 0.72, 0.78, 0.77, 0.6 ],\n       [0.  , 0.  , 0.24, 0.36, 0.34, 0.21],\n       [0.35, 0.35, 0.21, 0.31, 0.3 , 0.17],\n       [0.28, 0.28, 0.15, 0.25, 0.  , 0.  ],\n       [0.13, 0.12, 0.06, 0.07, 0.06, 0.03],\n       [0.51, 0.49, 0.  , 0.42, 0.38, 0.25],\n       [0.37, 0.36, 0.22, 0.35, 0.33, 0.2 ],\n       [0.  , 0.16, 0.  , 0.13, 0.12, 0.05],\n       [0.27, 0.27, 0.14, 0.19, 0.19, 0.08],\n       [0.  , 0.22, 0.  , 0.19, 0.19, 0.  ],\n       [0.34, 0.  , 0.2 , 0.28, 0.26, 0.  ],\n       [0.23, 0.  , 0.12, 0.19, 0.  , 0.09],\n       [0.  , 0.41, 0.24, 0.36, 0.  , 0.2 ],\n       [0.23, 0.22, 0.12, 0.19, 0.17, 0.09],\n       [0.86, 0.  , 0.74, 0.79, 0.  , 0.  ],\n       [0.  , 0.36, 0.23, 0.3 , 0.28, 0.16],\n       [0.  , 0.8 , 0.65, 0.61, 0.63, 0.44],\n       [0.11, 0.11, 0.05, 0.07, 0.08, 0.03],\n       [0.33, 0.32, 0.19, 0.  , 0.22, 0.12],\n       [0.  , 0.11, 0.04, 0.  , 0.  , 0.03],\n       [0.26, 0.  , 0.  , 0.  , 0.2 , 0.  ],\n       [0.21, 0.2 , 0.11, 0.16, 0.15, 0.  ],\n       [0.28, 0.27, 0.16, 0.23, 0.21, 0.  ],\n       [0.33, 0.31, 0.19, 0.  , 0.25, 0.  ],\n       [0.  , 0.17, 0.09, 0.  , 0.14, 0.07],\n       [0.24, 0.24, 0.13, 0.2 , 0.18, 0.09],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.21, 0.2 , 0.11, 0.17, 0.16, 0.08],\n       [1.  , 0.  , 1.  , 0.72, 0.69, 0.57],\n       [0.48, 0.49, 0.33, 0.55, 0.5 , 0.37],\n       [0.  , 0.21, 0.  , 0.  , 0.16, 0.  ],\n       [0.23, 0.  , 0.12, 0.2 , 0.19, 0.09],\n       [0.1 , 0.11, 0.05, 0.07, 0.08, 0.  ],\n       [0.  , 0.  , 0.23, 0.27, 0.26, 0.14],\n       [0.33, 0.32, 0.19, 0.25, 0.24, 0.12],\n       [0.08, 0.07, 0.  , 0.05, 0.  , 0.02],\n       [0.27, 0.27, 0.15, 0.  , 0.22, 0.11],\n       [0.33, 0.31, 0.19, 0.26, 0.  , 0.13],\n       [0.08, 0.08, 0.  , 0.06, 0.07, 0.02],\n       [0.  , 0.25, 0.13, 0.19, 0.  , 0.08],\n       [0.15, 0.14, 0.07, 0.11, 0.11, 0.05],\n       [0.23, 0.  , 0.12, 0.19, 0.  , 0.08],\n       [0.54, 0.53, 0.39, 0.5 , 0.46, 0.  ],\n       [0.2 , 0.19, 0.1 , 0.17, 0.16, 0.  ],\n       [0.25, 0.24, 0.14, 0.19, 0.  , 0.  ],\n       [0.57, 0.54, 0.  , 0.59, 0.51, 0.35],\n       [0.56, 0.55, 0.4 , 0.  , 0.55, 0.41],\n       [0.35, 0.  , 0.21, 0.3 , 0.29, 0.16],\n       [0.25, 0.24, 0.13, 0.2 , 0.18, 0.  ],\n       [0.25, 0.23, 0.13, 0.  , 0.16, 0.08],\n       [0.  , 0.59, 0.43, 0.49, 0.47, 0.3 ],\n       [0.18, 0.17, 0.  , 0.18, 0.17, 0.08],\n       [0.2 , 0.19, 0.1 , 0.15, 0.14, 0.06],\n       [0.42, 0.41, 0.27, 0.32, 0.31, 0.  ],\n       [0.2 , 0.  , 0.1 , 0.13, 0.  , 0.06],\n       [0.61, 0.  , 0.47, 0.69, 0.  , 0.54],\n       [0.13, 0.14, 0.07, 0.  , 0.1 , 0.  ],\n       [0.41, 0.4 , 0.  , 0.43, 0.39, 0.  ],\n       [0.23, 0.  , 0.  , 0.  , 0.18, 0.09],\n       [0.  , 0.31, 0.19, 0.24, 0.22, 0.12],\n       [0.3 , 0.28, 0.17, 0.3 , 0.27, 0.  ],\n       [0.19, 0.18, 0.1 , 0.  , 0.11, 0.05],\n       [0.12, 0.11, 0.05, 0.  , 0.08, 0.04],\n       [0.55, 0.56, 0.  , 0.54, 0.55, 0.36],\n       [0.33, 0.31, 0.19, 0.25, 0.24, 0.  ],\n       [0.19, 0.19, 0.09, 0.  , 0.13, 0.05],\n       [0.23, 0.22, 0.  , 0.18, 0.17, 0.08],\n       [0.58, 0.56, 0.  , 0.65, 0.6 , 0.  ],\n       [0.  , 0.29, 0.18, 0.28, 0.26, 0.15],\n       [0.27, 0.  , 0.15, 0.22, 0.21, 0.11],\n       [0.36, 0.36, 0.  , 0.27, 0.28, 0.13],\n       [0.31, 0.31, 0.18, 0.27, 0.28, 0.14],\n       [0.  , 0.2 , 0.11, 0.16, 0.  , 0.07],\n       [0.29, 0.28, 0.17, 0.21, 0.19, 0.1 ],\n       [0.38, 0.  , 0.23, 0.29, 0.26, 0.  ],\n       [0.63, 0.63, 0.49, 0.52, 0.51, 0.34],\n       [0.12, 0.  , 0.  , 0.08, 0.07, 0.  ],\n       [0.25, 0.24, 0.13, 0.  , 0.21, 0.11],\n       [0.33, 0.31, 0.  , 0.27, 0.25, 0.13],\n       [0.  , 0.  , 0.  , 0.7 , 0.72, 0.5 ],\n       [0.36, 0.36, 0.22, 0.3 , 0.29, 0.15],\n       [0.16, 0.15, 0.08, 0.  , 0.1 , 0.04],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.4 , 0.41, 0.25, 0.  , 0.34, 0.18],\n       [0.23, 0.21, 0.12, 0.18, 0.16, 0.  ],\n       [0.32, 0.31, 0.  , 0.25, 0.  , 0.13],\n       [0.  , 0.31, 0.  , 0.  , 0.  , 0.16],\n       [0.36, 0.35, 0.22, 0.3 , 0.29, 0.  ],\n       [0.53, 0.52, 0.  , 0.53, 0.51, 0.  ],\n       [0.  , 0.42, 0.28, 0.43, 0.  , 0.26],\n       [0.5 , 0.48, 0.33, 0.52, 0.45, 0.3 ],\n       [0.6 , 0.6 , 0.45, 0.56, 0.51, 0.37],\n       [0.22, 0.21, 0.  , 0.18, 0.18, 0.08],\n       [0.18, 0.17, 0.09, 0.13, 0.  , 0.06],\n       [0.46, 0.  , 0.  , 0.43, 0.41, 0.26],\n       [0.36, 0.35, 0.21, 0.28, 0.26, 0.14],\n       [0.  , 0.16, 0.09, 0.13, 0.11, 0.05],\n       [0.44, 0.44, 0.29, 0.35, 0.32, 0.19],\n       [0.3 , 0.3 , 0.17, 0.  , 0.  , 0.13],\n       [0.21, 0.2 , 0.  , 0.18, 0.  , 0.08],\n       [0.  , 0.41, 0.26, 0.38, 0.38, 0.21],\n       [0.64, 0.67, 0.48, 0.63, 0.67, 0.4 ],\n       [0.52, 0.49, 0.36, 0.46, 0.42, 0.28],\n       [0.62, 0.62, 0.47, 0.5 , 0.48, 0.32],\n       [0.61, 0.6 , 0.  , 0.  , 0.49, 0.35],\n       [0.21, 0.21, 0.11, 0.18, 0.17, 0.08],\n       [0.28, 0.27, 0.16, 0.  , 0.  , 0.1 ],\n       [0.2 , 0.  , 0.1 , 0.14, 0.  , 0.06],\n       [0.34, 0.33, 0.21, 0.29, 0.28, 0.  ],\n       [0.39, 0.  , 0.25, 0.34, 0.32, 0.  ],\n       [0.28, 0.28, 0.16, 0.22, 0.23, 0.11],\n       [0.12, 0.12, 0.  , 0.  , 0.1 , 0.04],\n       [0.2 , 0.  , 0.  , 0.14, 0.13, 0.06],\n       [0.29, 0.28, 0.  , 0.23, 0.21, 0.  ],\n       [0.  , 0.22, 0.12, 0.18, 0.  , 0.  ],\n       [0.  , 0.39, 0.23, 0.29, 0.28, 0.  ],\n       [0.29, 0.  , 0.16, 0.  , 0.  , 0.14],\n       [0.  , 0.23, 0.13, 0.18, 0.16, 0.08],\n       [0.  , 0.2 , 0.1 , 0.  , 0.  , 0.07],\n       [0.4 , 0.41, 0.25, 0.39, 0.37, 0.  ],\n       [0.27, 0.25, 0.15, 0.23, 0.21, 0.11],\n       [0.29, 0.29, 0.16, 0.22, 0.22, 0.  ],\n       [0.39, 0.38, 0.  , 0.  , 0.32, 0.19],\n       [0.  , 0.49, 0.34, 0.43, 0.42, 0.26],\n       [0.12, 0.11, 0.06, 0.15, 0.  , 0.06],\n       [0.  , 0.27, 0.16, 0.23, 0.22, 0.11],\n       [0.11, 0.12, 0.  , 0.08, 0.  , 0.  ],\n       [0.  , 0.63, 0.47, 0.  , 0.54, 0.  ],\n       [0.25, 0.24, 0.14, 0.  , 0.18, 0.  ],\n       [0.26, 0.24, 0.  , 0.18, 0.16, 0.08],\n       [0.45, 0.45, 0.  , 0.35, 0.36, 0.2 ],\n       [0.  , 0.19, 0.11, 0.16, 0.14, 0.07],\n       [0.  , 0.  , 0.09, 0.19, 0.21, 0.08],\n       [0.19, 0.  , 0.1 , 0.16, 0.  , 0.  ],\n       [0.19, 0.  , 0.1 , 0.17, 0.18, 0.08],\n       [0.28, 0.27, 0.16, 0.21, 0.2 , 0.1 ],\n       [0.25, 0.  , 0.13, 0.23, 0.  , 0.11],\n       [0.39, 0.38, 0.24, 0.  , 0.34, 0.2 ],\n       [0.  , 0.22, 0.  , 0.16, 0.15, 0.  ],\n       [0.  , 0.  , 0.16, 0.21, 0.21, 0.1 ],\n       [0.77, 0.76, 0.65, 0.  , 0.77, 0.68],\n       [0.13, 0.14, 0.05, 0.09, 0.  , 0.04],\n       [0.6 , 0.6 , 0.45, 0.67, 0.62, 0.5 ],\n       [0.36, 0.35, 0.22, 0.31, 0.29, 0.17],\n       [0.14, 0.13, 0.07, 0.11, 0.1 , 0.  ],\n       [0.17, 0.16, 0.08, 0.13, 0.12, 0.  ],\n       [0.65, 0.  , 0.  , 0.  , 0.58, 0.  ],\n       [0.31, 0.29, 0.18, 0.25, 0.22, 0.13],\n       [0.  , 0.  , 0.24, 0.  , 0.39, 0.18],\n       [0.23, 0.23, 0.12, 0.  , 0.  , 0.08],\n       [0.63, 0.  , 0.46, 0.58, 0.55, 0.37],\n       [0.14, 0.  , 0.07, 0.12, 0.  , 0.05],\n       [0.21, 0.  , 0.11, 0.17, 0.17, 0.08],\n       [0.39, 0.37, 0.24, 0.29, 0.27, 0.  ],\n       [0.  , 0.6 , 0.48, 0.54, 0.5 , 0.  ],\n       [0.  , 0.58, 0.46, 0.71, 0.  , 0.56],\n       [0.  , 0.03, 0.  , 0.05, 0.04, 0.02],\n       [0.21, 0.2 , 0.11, 0.18, 0.17, 0.  ],\n       [0.13, 0.13, 0.06, 0.11, 0.  , 0.04],\n       [0.17, 0.18, 0.08, 0.1 , 0.  , 0.04],\n       [0.54, 0.53, 0.4 , 0.53, 0.51, 0.35],\n       [0.  , 0.21, 0.12, 0.16, 0.15, 0.07],\n       [0.  , 0.34, 0.18, 0.25, 0.29, 0.  ],\n       [0.04, 0.03, 0.01, 0.04, 0.03, 0.02],\n       [0.28, 0.27, 0.15, 0.22, 0.21, 0.1 ],\n       [0.2 , 0.19, 0.1 , 0.14, 0.13, 0.06],\n       [0.28, 0.29, 0.15, 0.26, 0.27, 0.  ],\n       [0.32, 0.32, 0.18, 0.32, 0.  , 0.  ],\n       [0.35, 0.35, 0.21, 0.28, 0.29, 0.14],\n       [0.44, 0.44, 0.28, 0.4 , 0.  , 0.23],\n       [0.26, 0.  , 0.14, 0.  , 0.17, 0.09],\n       [0.26, 0.  , 0.  , 0.22, 0.  , 0.1 ],\n       [0.  , 0.31, 0.  , 0.32, 0.29, 0.18],\n       [0.  , 0.45, 0.3 , 0.41, 0.39, 0.24],\n       [0.64, 0.62, 0.49, 0.  , 0.55, 0.  ],\n       [0.31, 0.  , 0.18, 0.24, 0.23, 0.12],\n       [0.55, 0.  , 0.4 , 0.53, 0.  , 0.34],\n       [0.17, 0.18, 0.09, 0.  , 0.14, 0.06],\n       [0.26, 0.27, 0.14, 0.21, 0.24, 0.1 ],\n       [0.97, 0.99, 1.  , 1.  , 1.  , 1.  ],\n       [0.22, 0.21, 0.12, 0.  , 0.  , 0.09],\n       [0.54, 0.54, 0.39, 0.53, 0.48, 0.35],\n       [0.18, 0.18, 0.09, 0.14, 0.  , 0.06],\n       [0.  , 0.69, 0.51, 0.58, 0.64, 0.4 ],\n       [0.  , 0.  , 0.13, 0.  , 0.19, 0.09],\n       [0.35, 0.35, 0.21, 0.  , 0.  , 0.  ],\n       [0.59, 0.59, 0.44, 0.46, 0.46, 0.28],\n       [0.48, 0.48, 0.32, 0.41, 0.41, 0.25],\n       [0.3 , 0.29, 0.17, 0.  , 0.22, 0.  ],\n       [0.25, 0.  , 0.14, 0.2 , 0.18, 0.09],\n       [0.  , 0.16, 0.08, 0.12, 0.11, 0.  ],\n       [0.5 , 0.49, 0.34, 0.44, 0.44, 0.26],\n       [0.  , 0.24, 0.13, 0.21, 0.2 , 0.1 ],\n       [0.29, 0.29, 0.  , 0.24, 0.24, 0.12],\n       [0.  , 0.29, 0.18, 0.  , 0.33, 0.2 ],\n       [0.28, 0.27, 0.16, 0.23, 0.2 , 0.  ],\n       [0.34, 0.35, 0.21, 0.  , 0.  , 0.13],\n       [0.25, 0.23, 0.13, 0.  , 0.17, 0.09],\n       [0.26, 0.25, 0.15, 0.  , 0.18, 0.1 ],\n       [0.23, 0.22, 0.12, 0.16, 0.14, 0.07],\n       [0.  , 0.  , 0.42, 0.56, 0.  , 0.38],\n       [0.19, 0.18, 0.1 , 0.17, 0.15, 0.08],\n       [0.31, 0.3 , 0.17, 0.25, 0.22, 0.  ],\n       [0.13, 0.12, 0.06, 0.11, 0.  , 0.05],\n       [0.31, 0.3 , 0.18, 0.22, 0.2 , 0.1 ],\n       [0.52, 0.52, 0.37, 0.48, 0.46, 0.3 ],\n       [0.76, 0.75, 0.  , 0.81, 0.8 , 0.64],\n       [0.29, 0.29, 0.16, 0.23, 0.23, 0.  ],\n       [0.32, 0.3 , 0.18, 0.25, 0.24, 0.12],\n       [0.6 , 0.6 , 0.45, 0.62, 0.54, 0.43],\n       [0.31, 0.3 , 0.18, 0.26, 0.25, 0.13],\n       [0.15, 0.  , 0.07, 0.14, 0.  , 0.  ],\n       [0.  , 0.12, 0.  , 0.  , 0.09, 0.04],\n       [0.22, 0.21, 0.  , 0.  , 0.18, 0.08],\n       [0.16, 0.15, 0.08, 0.  , 0.1 , 0.04],\n       [0.27, 0.26, 0.  , 0.  , 0.19, 0.1 ],\n       [0.52, 0.49, 0.36, 0.  , 0.39, 0.26],\n       [0.67, 0.65, 0.  , 0.63, 0.59, 0.45],\n       [0.37, 0.4 , 0.23, 0.3 , 0.  , 0.  ],\n       [0.14, 0.13, 0.06, 0.  , 0.12, 0.  ],\n       [0.  , 0.1 , 0.04, 0.05, 0.06, 0.02],\n       [0.29, 0.3 , 0.16, 0.3 , 0.28, 0.16],\n       [0.43, 0.42, 0.  , 0.42, 0.39, 0.26],\n       [0.  , 0.  , 0.26, 0.47, 0.  , 0.29],\n       [0.24, 0.22, 0.13, 0.18, 0.16, 0.  ],\n       [0.  , 0.26, 0.  , 0.2 , 0.18, 0.09],\n       [0.08, 0.  , 0.  , 0.04, 0.03, 0.01],\n       [0.  , 0.17, 0.08, 0.11, 0.  , 0.05],\n       [0.56, 0.55, 0.  , 0.52, 0.47, 0.35],\n       [0.36, 0.35, 0.  , 0.29, 0.26, 0.  ],\n       [0.28, 0.27, 0.15, 0.21, 0.2 , 0.1 ],\n       [0.26, 0.28, 0.14, 0.  , 0.24, 0.13],\n       [0.  , 0.13, 0.06, 0.12, 0.11, 0.05],\n       [0.2 , 0.  , 0.1 , 0.14, 0.  , 0.06],\n       [0.21, 0.  , 0.11, 0.17, 0.  , 0.08],\n       [0.08, 0.08, 0.03, 0.06, 0.06, 0.02],\n       [0.64, 0.63, 0.  , 0.54, 0.51, 0.36],\n       [0.36, 0.37, 0.22, 0.  , 0.37, 0.19],\n       [0.  , 0.  , 0.17, 0.23, 0.21, 0.11],\n       [0.61, 0.6 , 0.45, 0.  , 0.55, 0.36],\n       [0.72, 0.75, 0.58, 0.73, 0.78, 0.53],\n       [0.24, 0.  , 0.  , 0.18, 0.  , 0.08],\n       [0.35, 0.  , 0.  , 0.27, 0.25, 0.14],\n       [0.25, 0.24, 0.14, 0.  , 0.  , 0.  ],\n       [0.  , 0.18, 0.09, 0.  , 0.  , 0.05],\n       [0.31, 0.3 , 0.18, 0.32, 0.  , 0.  ],\n       [0.22, 0.23, 0.11, 0.19, 0.19, 0.08],\n       [0.18, 0.  , 0.  , 0.13, 0.13, 0.06],\n       [0.3 , 0.28, 0.17, 0.26, 0.  , 0.  ],\n       [0.3 , 0.29, 0.18, 0.25, 0.23, 0.13],\n       [0.33, 0.32, 0.2 , 0.26, 0.24, 0.13],\n       [0.68, 0.67, 0.53, 0.53, 0.51, 0.  ],\n       [0.52, 0.  , 0.  , 0.46, 0.49, 0.27],\n       [0.  , 0.  , 0.17, 0.  , 0.23, 0.11],\n       [0.08, 0.07, 0.04, 0.05, 0.04, 0.02],\n       [0.34, 0.  , 0.  , 0.  , 0.32, 0.15],\n       [0.44, 0.45, 0.28, 0.  , 0.38, 0.21],\n       [0.  , 0.22, 0.11, 0.19, 0.17, 0.08],\n       [0.38, 0.36, 0.23, 0.29, 0.27, 0.  ],\n       [0.69, 0.  , 0.54, 0.65, 0.61, 0.47],\n       [0.2 , 0.19, 0.1 , 0.16, 0.14, 0.07],\n       [0.33, 0.  , 0.2 , 0.27, 0.25, 0.14],\n       [0.47, 0.45, 0.31, 0.37, 0.35, 0.21],\n       [0.55, 0.54, 0.4 , 0.48, 0.45, 0.3 ],\n       [0.24, 0.23, 0.12, 0.  , 0.16, 0.08],\n       [0.63, 0.62, 0.49, 0.58, 0.56, 0.41],\n       [0.58, 0.  , 0.  , 0.55, 0.58, 0.37],\n       [0.57, 0.  , 0.42, 0.6 , 0.58, 0.41],\n       [0.22, 0.21, 0.  , 0.  , 0.15, 0.07],\n       [0.7 , 0.72, 0.57, 0.72, 0.72, 0.54],\n       [0.  , 0.31, 0.19, 0.26, 0.24, 0.13],\n       [0.32, 0.32, 0.  , 0.3 , 0.3 , 0.15],\n       [0.15, 0.14, 0.07, 0.  , 0.1 , 0.05],\n       [0.27, 0.27, 0.  , 0.  , 0.22, 0.  ],\n       [0.25, 0.25, 0.  , 0.21, 0.2 , 0.  ],\n       [0.21, 0.21, 0.11, 0.16, 0.14, 0.  ],\n       [0.  , 0.  , 0.06, 0.11, 0.11, 0.  ],\n       [0.  , 0.44, 0.28, 0.44, 0.  , 0.26],\n       [0.2 , 0.19, 0.1 , 0.  , 0.  , 0.06],\n       [0.  , 0.12, 0.06, 0.1 , 0.08, 0.04],\n       [0.5 , 0.52, 0.36, 0.49, 0.46, 0.31],\n       [0.21, 0.21, 0.11, 0.17, 0.15, 0.08],\n       [0.64, 0.65, 0.49, 0.58, 0.55, 0.4 ],\n       [0.23, 0.22, 0.  , 0.17, 0.15, 0.  ],\n       [0.27, 0.  , 0.15, 0.21, 0.19, 0.1 ],\n       [0.25, 0.26, 0.14, 0.27, 0.26, 0.14],\n       [0.1 , 0.1 , 0.05, 0.08, 0.  , 0.03],\n       [0.  , 0.22, 0.12, 0.  , 0.18, 0.09],\n       [0.  , 0.34, 0.  , 0.3 , 0.  , 0.16],\n       [0.39, 0.37, 0.24, 0.  , 0.3 , 0.18],\n       [0.28, 0.27, 0.16, 0.  , 0.19, 0.  ],\n       [0.29, 0.3 , 0.16, 0.24, 0.24, 0.11],\n       [0.09, 0.09, 0.04, 0.07, 0.07, 0.03],\n       [0.22, 0.23, 0.11, 0.18, 0.18, 0.07],\n       [0.38, 0.37, 0.23, 0.  , 0.  , 0.15],\n       [0.48, 0.47, 0.  , 0.53, 0.51, 0.36],\n       [0.28, 0.  , 0.16, 0.2 , 0.  , 0.1 ],\n       [0.89, 0.9 , 0.79, 0.9 , 0.89, 0.75],\n       [0.52, 0.  , 0.36, 0.44, 0.41, 0.27],\n       [0.25, 0.24, 0.14, 0.19, 0.17, 0.  ],\n       [0.  , 0.68, 0.5 , 0.67, 0.  , 0.47],\n       [0.51, 0.51, 0.36, 0.48, 0.47, 0.31],\n       [0.  , 0.49, 0.34, 0.44, 0.44, 0.27],\n       [0.31, 0.  , 0.18, 0.27, 0.24, 0.14],\n       [0.21, 0.2 , 0.11, 0.18, 0.17, 0.08],\n       [0.48, 0.47, 0.33, 0.46, 0.46, 0.29],\n       [0.28, 0.27, 0.16, 0.  , 0.19, 0.1 ],\n       [0.  , 0.  , 0.16, 0.  , 0.  , 0.  ],\n       [0.  , 0.58, 0.41, 0.57, 0.63, 0.  ],\n       [0.28, 0.27, 0.15, 0.21, 0.  , 0.1 ],\n       [0.14, 0.13, 0.06, 0.  , 0.08, 0.04],\n       [0.78, 0.77, 0.  , 0.  , 0.  , 0.67],\n       [0.  , 0.  , 0.22, 0.3 , 0.26, 0.15],\n       [0.31, 0.31, 0.18, 0.25, 0.  , 0.  ],\n       [0.38, 0.37, 0.23, 0.  , 0.35, 0.19],\n       [0.27, 0.  , 0.15, 0.2 , 0.  , 0.09],\n       [0.  , 0.  , 0.17, 0.23, 0.22, 0.11],\n       [0.  , 0.05, 0.02, 0.04, 0.  , 0.01],\n       [0.38, 0.37, 0.24, 0.34, 0.  , 0.  ],\n       [0.61, 0.59, 0.46, 0.63, 0.6 , 0.  ],\n       [0.38, 0.37, 0.  , 0.3 , 0.32, 0.15],\n       [0.41, 0.46, 0.27, 0.42, 0.46, 0.26],\n       [0.24, 0.23, 0.13, 0.2 , 0.18, 0.09],\n       [0.25, 0.24, 0.14, 0.22, 0.19, 0.1 ],\n       [0.  , 0.35, 0.  , 0.  , 0.36, 0.23],\n       [0.26, 0.24, 0.14, 0.19, 0.  , 0.  ],\n       [0.  , 0.35, 0.22, 0.31, 0.28, 0.16],\n       [0.34, 0.32, 0.2 , 0.  , 0.  , 0.14],\n       [0.  , 0.27, 0.14, 0.  , 0.26, 0.14],\n       [0.16, 0.  , 0.08, 0.1 , 0.1 , 0.04],\n       [0.6 , 0.6 , 0.  , 0.53, 0.53, 0.  ],\n       [0.  , 0.33, 0.18, 0.28, 0.27, 0.14],\n       [0.  , 0.3 , 0.18, 0.28, 0.25, 0.14],\n       [0.  , 0.41, 0.24, 0.  , 0.  , 0.  ],\n       [0.38, 0.38, 0.23, 0.31, 0.  , 0.17],\n       [0.25, 0.24, 0.14, 0.22, 0.  , 0.1 ],\n       [0.  , 0.  , 0.25, 0.3 , 0.  , 0.  ],\n       [0.36, 0.35, 0.22, 0.3 , 0.28, 0.16],\n       [0.22, 0.21, 0.11, 0.15, 0.14, 0.07],\n       [0.32, 0.31, 0.19, 0.24, 0.24, 0.12],\n       [0.64, 0.61, 0.49, 0.58, 0.55, 0.  ],\n       [0.35, 0.32, 0.  , 0.25, 0.22, 0.  ],\n       [0.37, 0.37, 0.  , 0.33, 0.32, 0.18],\n       [0.34, 0.35, 0.2 , 0.28, 0.28, 0.14]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.29, 0.29, 0.17, 0.24, 0.25, 0.12],\n       [0.48, 0.47, 0.33, 0.49, 0.45, 0.31],\n       [0.1 , 0.09, 0.04, 0.06, 0.05, 0.02],\n       [0.59, 0.58, 0.43, 0.57, 0.52, 0.38],\n       [0.19, 0.19, 0.1 , 0.16, 0.2 , 0.07],\n       [0.53, 0.52, 0.37, 0.49, 0.45, 0.32],\n       [0.35, 0.36, 0.22, 0.29, 0.31, 0.15],\n       [0.44, 0.46, 0.29, 0.34, 0.36, 0.19],\n       [0.69, 0.68, 0.57, 0.62, 0.58, 0.45],\n       [0.27, 0.26, 0.15, 0.2 , 0.19, 0.09],\n       [0.59, 0.59, 0.46, 0.64, 0.6 , 0.46],\n       [0.31, 0.3 , 0.17, 0.26, 0.23, 0.13],\n       [0.26, 0.24, 0.14, 0.19, 0.16, 0.09],\n       [0.33, 0.33, 0.19, 0.32, 0.32, 0.17],\n       [0.39, 0.41, 0.25, 0.44, 0.49, 0.27],\n       [0.17, 0.16, 0.08, 0.15, 0.15, 0.06],\n       [0.15, 0.15, 0.07, 0.12, 0.11, 0.05],\n       [0.21, 0.21, 0.11, 0.16, 0.16, 0.07],\n       [0.42, 0.43, 0.27, 0.44, 0.4 , 0.27],\n       [0.36, 0.35, 0.22, 0.28, 0.26, 0.14],\n       [0.21, 0.19, 0.11, 0.15, 0.13, 0.07],\n       [0.58, 0.58, 0.43, 0.58, 0.55, 0.4 ],\n       [0.2 , 0.2 , 0.1 , 0.16, 0.14, 0.07],\n       [0.37, 0.38, 0.23, 0.39, 0.38, 0.22],\n       [0.03, 0.03, 0.01, 0.03, 0.02, 0.01],\n       [0.22, 0.21, 0.12, 0.17, 0.15, 0.07],\n       [0.49, 0.48, 0.33, 0.42, 0.4 , 0.25],\n       [0.28, 0.28, 0.16, 0.23, 0.24, 0.11],\n       [0.08, 0.07, 0.03, 0.06, 0.05, 0.02],\n       [0.33, 0.31, 0.19, 0.27, 0.25, 0.14],\n       [0.43, 0.43, 0.28, 0.39, 0.37, 0.22],\n       [0.31, 0.29, 0.18, 0.24, 0.23, 0.12],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.28, 0.27, 0.15, 0.22, 0.21, 0.11],\n       [0.33, 0.31, 0.19, 0.26, 0.23, 0.13],\n       [0.12, 0.11, 0.05, 0.09, 0.08, 0.04],\n       [0.19, 0.19, 0.1 , 0.14, 0.15, 0.06],\n       [0.54, 0.52, 0.38, 0.48, 0.44, 0.3 ],\n       [0.58, 0.61, 0.42, 0.46, 0.5 , 0.28],\n       [0.47, 0.46, 0.32, 0.42, 0.4 , 0.25],\n       [0.37, 0.36, 0.23, 0.29, 0.27, 0.15],\n       [0.57, 0.59, 0.42, 0.44, 0.45, 0.27],\n       [0.64, 0.62, 0.5 , 0.61, 0.54, 0.44],\n       [0.29, 0.27, 0.16, 0.19, 0.17, 0.09],\n       [0.24, 0.23, 0.13, 0.18, 0.17, 0.08],\n       [0.36, 0.35, 0.21, 0.28, 0.26, 0.14],\n       [0.46, 0.45, 0.3 , 0.39, 0.38, 0.23],\n       [0.24, 0.23, 0.13, 0.2 , 0.18, 0.09],\n       [0.25, 0.25, 0.14, 0.2 , 0.18, 0.09],\n       [0.52, 0.53, 0.37, 0.51, 0.5 , 0.35],\n       [0.15, 0.15, 0.08, 0.13, 0.12, 0.05],\n       [0.58, 0.57, 0.43, 0.5 , 0.48, 0.32],\n       [0.43, 0.43, 0.28, 0.41, 0.39, 0.24],\n       [0.77, 0.75, 0.65, 0.71, 0.67, 0.55],\n       [0.48, 0.48, 0.32, 0.46, 0.43, 0.28],\n       [0.63, 0.64, 0.48, 0.62, 0.6 , 0.43],\n       [0.49, 0.47, 0.33, 0.44, 0.41, 0.27],\n       [0.32, 0.34, 0.19, 0.29, 0.28, 0.15],\n       [0.34, 0.37, 0.21, 0.26, 0.28, 0.13],\n       [0.29, 0.28, 0.17, 0.25, 0.22, 0.12],\n       [0.52, 0.51, 0.36, 0.47, 0.44, 0.29],\n       [0.31, 0.3 , 0.17, 0.26, 0.26, 0.13],\n       [0.33, 0.33, 0.19, 0.3 , 0.29, 0.16],\n       [0.38, 0.37, 0.23, 0.31, 0.3 , 0.17],\n       [0.29, 0.27, 0.16, 0.22, 0.2 , 0.11],\n       [0.57, 0.55, 0.42, 0.51, 0.49, 0.33],\n       [0.4 , 0.41, 0.28, 0.54, 0.53, 0.38],\n       [0.22, 0.22, 0.12, 0.19, 0.18, 0.09],\n       [0.42, 0.41, 0.27, 0.44, 0.43, 0.27],\n       [0.64, 0.63, 0.5 , 0.59, 0.56, 0.41],\n       [0.28, 0.28, 0.16, 0.23, 0.27, 0.11],\n       [0.34, 0.34, 0.21, 0.28, 0.33, 0.15],\n       [0.51, 0.51, 0.35, 0.45, 0.41, 0.27],\n       [0.23, 0.21, 0.12, 0.19, 0.17, 0.09],\n       [0.32, 0.31, 0.18, 0.26, 0.24, 0.13],\n       [0.27, 0.26, 0.15, 0.23, 0.21, 0.12],\n       [0.3 , 0.29, 0.17, 0.23, 0.21, 0.11],\n       [0.59, 0.62, 0.45, 0.61, 0.64, 0.43],\n       [0.21, 0.2 , 0.11, 0.16, 0.14, 0.07],\n       [0.29, 0.29, 0.17, 0.28, 0.26, 0.14],\n       [0.16, 0.15, 0.08, 0.12, 0.11, 0.05],\n       [0.16, 0.16, 0.08, 0.13, 0.11, 0.05],\n       [0.84, 0.84, 0.72, 0.78, 0.77, 0.6 ],\n       [0.38, 0.37, 0.24, 0.36, 0.34, 0.21],\n       [0.35, 0.35, 0.21, 0.31, 0.3 , 0.17],\n       [0.28, 0.28, 0.15, 0.25, 0.24, 0.12],\n       [0.13, 0.12, 0.06, 0.07, 0.06, 0.03],\n       [0.51, 0.49, 0.36, 0.42, 0.38, 0.25],\n       [0.37, 0.36, 0.22, 0.35, 0.33, 0.2 ],\n       [0.17, 0.16, 0.08, 0.13, 0.12, 0.05],\n       [0.27, 0.27, 0.14, 0.19, 0.19, 0.08],\n       [0.23, 0.22, 0.12, 0.19, 0.19, 0.09],\n       [0.34, 0.34, 0.2 , 0.28, 0.26, 0.14],\n       [0.23, 0.22, 0.12, 0.19, 0.17, 0.09],\n       [0.4 , 0.41, 0.24, 0.36, 0.37, 0.2 ],\n       [0.23, 0.22, 0.12, 0.19, 0.17, 0.09],\n       [0.86, 0.88, 0.74, 0.79, 0.8 , 0.58],\n       [0.37, 0.36, 0.23, 0.3 , 0.28, 0.16],\n       [0.77, 0.8 , 0.65, 0.61, 0.63, 0.44],\n       [0.11, 0.11, 0.05, 0.07, 0.08, 0.03],\n       [0.33, 0.32, 0.19, 0.24, 0.22, 0.12],\n       [0.1 , 0.11, 0.04, 0.08, 0.09, 0.03],\n       [0.26, 0.26, 0.14, 0.18, 0.2 , 0.08],\n       [0.21, 0.2 , 0.11, 0.16, 0.15, 0.07],\n       [0.28, 0.27, 0.16, 0.23, 0.21, 0.11],\n       [0.33, 0.31, 0.19, 0.27, 0.25, 0.14],\n       [0.19, 0.17, 0.09, 0.16, 0.14, 0.07],\n       [0.24, 0.24, 0.13, 0.2 , 0.18, 0.09],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.21, 0.2 , 0.11, 0.17, 0.16, 0.08],\n       [1.  , 1.  , 1.  , 0.72, 0.69, 0.57],\n       [0.48, 0.49, 0.33, 0.55, 0.5 , 0.37],\n       [0.22, 0.21, 0.11, 0.18, 0.16, 0.08],\n       [0.23, 0.22, 0.12, 0.2 , 0.19, 0.09],\n       [0.1 , 0.11, 0.05, 0.07, 0.08, 0.03],\n       [0.37, 0.35, 0.23, 0.27, 0.26, 0.14],\n       [0.33, 0.32, 0.19, 0.25, 0.24, 0.12],\n       [0.08, 0.07, 0.03, 0.05, 0.06, 0.02],\n       [0.27, 0.27, 0.15, 0.23, 0.22, 0.11],\n       [0.33, 0.31, 0.19, 0.26, 0.25, 0.13],\n       [0.08, 0.08, 0.04, 0.06, 0.07, 0.02],\n       [0.25, 0.25, 0.13, 0.19, 0.17, 0.08],\n       [0.15, 0.14, 0.07, 0.11, 0.11, 0.05],\n       [0.23, 0.24, 0.12, 0.19, 0.18, 0.08],\n       [0.54, 0.53, 0.39, 0.5 , 0.46, 0.32],\n       [0.2 , 0.19, 0.1 , 0.17, 0.16, 0.08],\n       [0.25, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.57, 0.54, 0.4 , 0.59, 0.51, 0.35],\n       [0.56, 0.55, 0.4 , 0.59, 0.55, 0.41],\n       [0.35, 0.35, 0.21, 0.3 , 0.29, 0.16],\n       [0.25, 0.24, 0.13, 0.2 , 0.18, 0.09],\n       [0.25, 0.23, 0.13, 0.17, 0.16, 0.08],\n       [0.59, 0.59, 0.43, 0.49, 0.47, 0.3 ],\n       [0.18, 0.17, 0.09, 0.18, 0.17, 0.08],\n       [0.2 , 0.19, 0.1 , 0.15, 0.14, 0.06],\n       [0.42, 0.41, 0.27, 0.32, 0.31, 0.17],\n       [0.2 , 0.18, 0.1 , 0.13, 0.12, 0.06],\n       [0.61, 0.6 , 0.47, 0.69, 0.68, 0.54],\n       [0.13, 0.14, 0.07, 0.11, 0.1 , 0.05],\n       [0.41, 0.4 , 0.26, 0.43, 0.39, 0.27],\n       [0.23, 0.22, 0.12, 0.2 , 0.18, 0.09],\n       [0.32, 0.31, 0.19, 0.24, 0.22, 0.12],\n       [0.3 , 0.28, 0.17, 0.3 , 0.27, 0.16],\n       [0.19, 0.18, 0.1 , 0.12, 0.11, 0.05],\n       [0.12, 0.11, 0.05, 0.09, 0.08, 0.04],\n       [0.55, 0.56, 0.4 , 0.54, 0.55, 0.36],\n       [0.33, 0.31, 0.19, 0.25, 0.24, 0.12],\n       [0.19, 0.19, 0.09, 0.13, 0.13, 0.05],\n       [0.23, 0.22, 0.12, 0.18, 0.17, 0.08],\n       [0.58, 0.56, 0.43, 0.65, 0.6 , 0.48],\n       [0.31, 0.29, 0.18, 0.28, 0.26, 0.15],\n       [0.27, 0.27, 0.15, 0.22, 0.21, 0.11],\n       [0.36, 0.36, 0.22, 0.27, 0.28, 0.13],\n       [0.31, 0.31, 0.18, 0.27, 0.28, 0.14],\n       [0.21, 0.2 , 0.11, 0.16, 0.15, 0.07],\n       [0.29, 0.28, 0.17, 0.21, 0.19, 0.1 ],\n       [0.38, 0.36, 0.23, 0.29, 0.26, 0.15],\n       [0.63, 0.63, 0.49, 0.52, 0.51, 0.34],\n       [0.12, 0.11, 0.06, 0.08, 0.07, 0.03],\n       [0.25, 0.24, 0.13, 0.23, 0.21, 0.11],\n       [0.33, 0.31, 0.19, 0.27, 0.25, 0.13],\n       [0.71, 0.71, 0.57, 0.7 , 0.72, 0.5 ],\n       [0.36, 0.36, 0.22, 0.3 , 0.29, 0.15],\n       [0.16, 0.15, 0.08, 0.1 , 0.1 , 0.04],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.4 , 0.41, 0.25, 0.33, 0.34, 0.18],\n       [0.23, 0.21, 0.12, 0.18, 0.16, 0.08],\n       [0.32, 0.31, 0.19, 0.25, 0.24, 0.13],\n       [0.33, 0.31, 0.19, 0.3 , 0.27, 0.16],\n       [0.36, 0.35, 0.22, 0.3 , 0.29, 0.16],\n       [0.53, 0.52, 0.38, 0.53, 0.51, 0.35],\n       [0.43, 0.42, 0.28, 0.43, 0.39, 0.26],\n       [0.5 , 0.48, 0.33, 0.52, 0.45, 0.3 ],\n       [0.6 , 0.6 , 0.45, 0.56, 0.51, 0.37],\n       [0.22, 0.21, 0.11, 0.18, 0.18, 0.08],\n       [0.18, 0.17, 0.09, 0.13, 0.12, 0.06],\n       [0.46, 0.46, 0.31, 0.43, 0.41, 0.26],\n       [0.36, 0.35, 0.21, 0.28, 0.26, 0.14],\n       [0.17, 0.16, 0.09, 0.13, 0.11, 0.05],\n       [0.44, 0.44, 0.29, 0.35, 0.32, 0.19],\n       [0.3 , 0.3 , 0.17, 0.27, 0.32, 0.13],\n       [0.21, 0.2 , 0.11, 0.18, 0.16, 0.08],\n       [0.4 , 0.41, 0.26, 0.38, 0.38, 0.21],\n       [0.64, 0.67, 0.48, 0.63, 0.67, 0.4 ],\n       [0.52, 0.49, 0.36, 0.46, 0.42, 0.28],\n       [0.62, 0.62, 0.47, 0.5 , 0.48, 0.32],\n       [0.61, 0.6 , 0.44, 0.52, 0.49, 0.35],\n       [0.21, 0.21, 0.11, 0.18, 0.17, 0.08],\n       [0.28, 0.27, 0.16, 0.21, 0.19, 0.1 ],\n       [0.2 , 0.19, 0.1 , 0.14, 0.13, 0.06],\n       [0.34, 0.33, 0.21, 0.29, 0.28, 0.16],\n       [0.39, 0.38, 0.25, 0.34, 0.32, 0.18],\n       [0.28, 0.28, 0.16, 0.22, 0.23, 0.11],\n       [0.12, 0.12, 0.06, 0.1 , 0.1 , 0.04],\n       [0.2 , 0.2 , 0.1 , 0.14, 0.13, 0.06],\n       [0.29, 0.28, 0.17, 0.23, 0.21, 0.11],\n       [0.23, 0.22, 0.12, 0.18, 0.17, 0.08],\n       [0.38, 0.39, 0.23, 0.29, 0.28, 0.14],\n       [0.29, 0.29, 0.16, 0.3 , 0.27, 0.14],\n       [0.25, 0.23, 0.13, 0.18, 0.16, 0.08],\n       [0.2 , 0.2 , 0.1 , 0.17, 0.17, 0.07],\n       [0.4 , 0.41, 0.25, 0.39, 0.37, 0.23],\n       [0.27, 0.25, 0.15, 0.23, 0.21, 0.11],\n       [0.29, 0.29, 0.16, 0.22, 0.22, 0.1 ],\n       [0.39, 0.38, 0.24, 0.35, 0.32, 0.19],\n       [0.5 , 0.49, 0.34, 0.43, 0.42, 0.26],\n       [0.12, 0.11, 0.06, 0.15, 0.13, 0.06],\n       [0.28, 0.27, 0.16, 0.23, 0.22, 0.11],\n       [0.11, 0.12, 0.04, 0.08, 0.09, 0.03],\n       [0.62, 0.63, 0.47, 0.56, 0.54, 0.37],\n       [0.25, 0.24, 0.14, 0.19, 0.18, 0.09],\n       [0.26, 0.24, 0.14, 0.18, 0.16, 0.08],\n       [0.45, 0.45, 0.29, 0.35, 0.36, 0.2 ],\n       [0.2 , 0.19, 0.11, 0.16, 0.14, 0.07],\n       [0.19, 0.2 , 0.09, 0.19, 0.21, 0.08],\n       [0.19, 0.18, 0.1 , 0.16, 0.16, 0.07],\n       [0.19, 0.19, 0.1 , 0.17, 0.18, 0.08],\n       [0.28, 0.27, 0.16, 0.21, 0.2 , 0.1 ],\n       [0.25, 0.24, 0.13, 0.23, 0.22, 0.11],\n       [0.39, 0.38, 0.24, 0.35, 0.34, 0.2 ],\n       [0.23, 0.22, 0.12, 0.16, 0.15, 0.07],\n       [0.28, 0.28, 0.16, 0.21, 0.21, 0.1 ],\n       [0.77, 0.76, 0.65, 0.82, 0.77, 0.68],\n       [0.13, 0.14, 0.05, 0.09, 0.09, 0.04],\n       [0.6 , 0.6 , 0.45, 0.67, 0.62, 0.5 ],\n       [0.36, 0.35, 0.22, 0.31, 0.29, 0.17],\n       [0.14, 0.13, 0.07, 0.11, 0.1 , 0.05],\n       [0.17, 0.16, 0.08, 0.13, 0.12, 0.05],\n       [0.65, 0.63, 0.51, 0.62, 0.58, 0.43],\n       [0.31, 0.29, 0.18, 0.25, 0.22, 0.13],\n       [0.39, 0.41, 0.24, 0.34, 0.39, 0.18],\n       [0.23, 0.23, 0.12, 0.17, 0.16, 0.08],\n       [0.63, 0.62, 0.46, 0.58, 0.55, 0.37],\n       [0.14, 0.14, 0.07, 0.12, 0.11, 0.05],\n       [0.21, 0.2 , 0.11, 0.17, 0.17, 0.08],\n       [0.39, 0.37, 0.24, 0.29, 0.27, 0.16],\n       [0.62, 0.6 , 0.48, 0.54, 0.5 , 0.36],\n       [0.59, 0.58, 0.46, 0.71, 0.65, 0.56],\n       [0.04, 0.03, 0.02, 0.05, 0.04, 0.02],\n       [0.21, 0.2 , 0.11, 0.18, 0.17, 0.08],\n       [0.13, 0.13, 0.06, 0.11, 0.09, 0.04],\n       [0.17, 0.18, 0.08, 0.1 , 0.13, 0.04],\n       [0.54, 0.53, 0.4 , 0.53, 0.51, 0.35],\n       [0.22, 0.21, 0.12, 0.16, 0.15, 0.07],\n       [0.32, 0.34, 0.18, 0.25, 0.29, 0.13],\n       [0.04, 0.03, 0.01, 0.04, 0.03, 0.02],\n       [0.28, 0.27, 0.15, 0.22, 0.21, 0.1 ],\n       [0.2 , 0.19, 0.1 , 0.14, 0.13, 0.06],\n       [0.28, 0.29, 0.15, 0.26, 0.27, 0.13],\n       [0.32, 0.32, 0.18, 0.32, 0.3 , 0.17],\n       [0.35, 0.35, 0.21, 0.28, 0.29, 0.14],\n       [0.44, 0.44, 0.28, 0.4 , 0.4 , 0.23],\n       [0.26, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.26, 0.25, 0.14, 0.22, 0.22, 0.1 ],\n       [0.31, 0.31, 0.19, 0.32, 0.29, 0.18],\n       [0.44, 0.45, 0.3 , 0.41, 0.39, 0.24],\n       [0.64, 0.62, 0.49, 0.58, 0.55, 0.39],\n       [0.31, 0.31, 0.18, 0.24, 0.23, 0.12],\n       [0.55, 0.55, 0.4 , 0.53, 0.5 , 0.34],\n       [0.17, 0.18, 0.09, 0.14, 0.14, 0.06],\n       [0.26, 0.27, 0.14, 0.21, 0.24, 0.1 ],\n       [0.97, 0.99, 1.  , 1.  , 1.  , 1.  ],\n       [0.22, 0.21, 0.12, 0.19, 0.18, 0.09],\n       [0.54, 0.54, 0.39, 0.53, 0.48, 0.35],\n       [0.18, 0.18, 0.09, 0.14, 0.15, 0.06],\n       [0.66, 0.69, 0.51, 0.58, 0.64, 0.4 ],\n       [0.25, 0.24, 0.13, 0.19, 0.19, 0.09],\n       [0.35, 0.35, 0.21, 0.37, 0.34, 0.21],\n       [0.59, 0.59, 0.44, 0.46, 0.46, 0.28],\n       [0.48, 0.48, 0.32, 0.41, 0.41, 0.25],\n       [0.3 , 0.29, 0.17, 0.24, 0.22, 0.12],\n       [0.25, 0.24, 0.14, 0.2 , 0.18, 0.09],\n       [0.15, 0.16, 0.08, 0.12, 0.11, 0.05],\n       [0.5 , 0.49, 0.34, 0.44, 0.44, 0.26],\n       [0.24, 0.24, 0.13, 0.21, 0.2 , 0.1 ],\n       [0.29, 0.29, 0.17, 0.24, 0.24, 0.12],\n       [0.31, 0.29, 0.18, 0.36, 0.33, 0.2 ],\n       [0.28, 0.27, 0.16, 0.23, 0.2 , 0.11],\n       [0.34, 0.35, 0.21, 0.26, 0.27, 0.13],\n       [0.25, 0.23, 0.13, 0.19, 0.17, 0.09],\n       [0.26, 0.25, 0.15, 0.21, 0.18, 0.1 ],\n       [0.23, 0.22, 0.12, 0.16, 0.14, 0.07],\n       [0.58, 0.57, 0.42, 0.56, 0.54, 0.38],\n       [0.19, 0.18, 0.1 , 0.17, 0.15, 0.08],\n       [0.31, 0.3 , 0.17, 0.25, 0.22, 0.12],\n       [0.13, 0.12, 0.06, 0.11, 0.1 , 0.05],\n       [0.31, 0.3 , 0.18, 0.22, 0.2 , 0.1 ],\n       [0.52, 0.52, 0.37, 0.48, 0.46, 0.3 ],\n       [0.76, 0.75, 0.65, 0.81, 0.8 , 0.64],\n       [0.29, 0.29, 0.16, 0.23, 0.23, 0.11],\n       [0.32, 0.3 , 0.18, 0.25, 0.24, 0.12],\n       [0.6 , 0.6 , 0.45, 0.62, 0.54, 0.43],\n       [0.31, 0.3 , 0.18, 0.26, 0.25, 0.13],\n       [0.15, 0.14, 0.07, 0.14, 0.12, 0.06],\n       [0.13, 0.12, 0.06, 0.1 , 0.09, 0.04],\n       [0.22, 0.21, 0.12, 0.18, 0.18, 0.08],\n       [0.16, 0.15, 0.08, 0.1 , 0.1 , 0.04],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.52, 0.49, 0.36, 0.45, 0.39, 0.26],\n       [0.67, 0.65, 0.53, 0.63, 0.59, 0.45],\n       [0.37, 0.4 , 0.23, 0.3 , 0.37, 0.16],\n       [0.14, 0.13, 0.06, 0.12, 0.12, 0.05],\n       [0.09, 0.1 , 0.04, 0.05, 0.06, 0.02],\n       [0.29, 0.3 , 0.16, 0.3 , 0.28, 0.16],\n       [0.43, 0.42, 0.29, 0.42, 0.39, 0.26],\n       [0.4 , 0.41, 0.26, 0.47, 0.46, 0.29],\n       [0.24, 0.22, 0.13, 0.18, 0.16, 0.08],\n       [0.27, 0.26, 0.15, 0.2 , 0.18, 0.09],\n       [0.08, 0.07, 0.03, 0.04, 0.03, 0.01],\n       [0.17, 0.17, 0.08, 0.11, 0.11, 0.05],\n       [0.56, 0.55, 0.41, 0.52, 0.47, 0.35],\n       [0.36, 0.35, 0.22, 0.29, 0.26, 0.15],\n       [0.28, 0.27, 0.15, 0.21, 0.2 , 0.1 ],\n       [0.26, 0.28, 0.14, 0.25, 0.24, 0.13],\n       [0.13, 0.13, 0.06, 0.12, 0.11, 0.05],\n       [0.2 , 0.19, 0.1 , 0.14, 0.13, 0.06],\n       [0.21, 0.21, 0.11, 0.17, 0.16, 0.08],\n       [0.08, 0.08, 0.03, 0.06, 0.06, 0.02],\n       [0.64, 0.63, 0.49, 0.54, 0.51, 0.36],\n       [0.36, 0.37, 0.22, 0.34, 0.37, 0.19],\n       [0.29, 0.28, 0.17, 0.23, 0.21, 0.11],\n       [0.61, 0.6 , 0.45, 0.56, 0.55, 0.36],\n       [0.72, 0.75, 0.58, 0.73, 0.78, 0.53],\n       [0.24, 0.23, 0.13, 0.18, 0.17, 0.08],\n       [0.35, 0.33, 0.21, 0.27, 0.25, 0.14],\n       [0.25, 0.24, 0.14, 0.18, 0.19, 0.08],\n       [0.19, 0.18, 0.09, 0.12, 0.11, 0.05],\n       [0.31, 0.3 , 0.18, 0.32, 0.31, 0.16],\n       [0.22, 0.23, 0.11, 0.19, 0.19, 0.08],\n       [0.18, 0.18, 0.09, 0.13, 0.13, 0.06],\n       [0.3 , 0.28, 0.17, 0.26, 0.24, 0.13],\n       [0.3 , 0.29, 0.18, 0.25, 0.23, 0.13],\n       [0.33, 0.32, 0.2 , 0.26, 0.24, 0.13],\n       [0.68, 0.67, 0.53, 0.53, 0.51, 0.33],\n       [0.52, 0.56, 0.36, 0.46, 0.49, 0.27],\n       [0.3 , 0.29, 0.17, 0.22, 0.23, 0.11],\n       [0.08, 0.07, 0.04, 0.05, 0.04, 0.02],\n       [0.34, 0.34, 0.2 , 0.32, 0.32, 0.15],\n       [0.44, 0.45, 0.28, 0.38, 0.38, 0.21],\n       [0.22, 0.22, 0.11, 0.19, 0.17, 0.08],\n       [0.38, 0.36, 0.23, 0.29, 0.27, 0.15],\n       [0.69, 0.7 , 0.54, 0.65, 0.61, 0.47],\n       [0.2 , 0.19, 0.1 , 0.16, 0.14, 0.07],\n       [0.33, 0.32, 0.2 , 0.27, 0.25, 0.14],\n       [0.47, 0.45, 0.31, 0.37, 0.35, 0.21],\n       [0.55, 0.54, 0.4 , 0.48, 0.45, 0.3 ],\n       [0.24, 0.23, 0.12, 0.17, 0.16, 0.08],\n       [0.63, 0.62, 0.49, 0.58, 0.56, 0.41],\n       [0.58, 0.58, 0.43, 0.55, 0.58, 0.37],\n       [0.57, 0.55, 0.42, 0.6 , 0.58, 0.41],\n       [0.22, 0.21, 0.11, 0.16, 0.15, 0.07],\n       [0.7 , 0.72, 0.57, 0.72, 0.72, 0.54],\n       [0.32, 0.31, 0.19, 0.26, 0.24, 0.13],\n       [0.32, 0.32, 0.19, 0.3 , 0.3 , 0.15],\n       [0.15, 0.14, 0.07, 0.11, 0.1 , 0.05],\n       [0.27, 0.27, 0.15, 0.23, 0.22, 0.11],\n       [0.25, 0.25, 0.14, 0.21, 0.2 , 0.1 ],\n       [0.21, 0.21, 0.11, 0.16, 0.14, 0.07],\n       [0.13, 0.13, 0.06, 0.11, 0.11, 0.04],\n       [0.43, 0.44, 0.28, 0.44, 0.41, 0.26],\n       [0.2 , 0.19, 0.1 , 0.14, 0.12, 0.06],\n       [0.13, 0.12, 0.06, 0.1 , 0.08, 0.04],\n       [0.5 , 0.52, 0.36, 0.49, 0.46, 0.31],\n       [0.21, 0.21, 0.11, 0.17, 0.15, 0.08],\n       [0.64, 0.65, 0.49, 0.58, 0.55, 0.4 ],\n       [0.23, 0.22, 0.12, 0.17, 0.15, 0.07],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.25, 0.26, 0.14, 0.27, 0.26, 0.14],\n       [0.1 , 0.1 , 0.05, 0.08, 0.08, 0.03],\n       [0.22, 0.22, 0.12, 0.19, 0.18, 0.09],\n       [0.36, 0.34, 0.22, 0.3 , 0.27, 0.16],\n       [0.39, 0.37, 0.24, 0.33, 0.3 , 0.18],\n       [0.28, 0.27, 0.16, 0.21, 0.19, 0.1 ],\n       [0.29, 0.3 , 0.16, 0.24, 0.24, 0.11],\n       [0.09, 0.09, 0.04, 0.07, 0.07, 0.03],\n       [0.22, 0.23, 0.11, 0.18, 0.18, 0.07],\n       [0.38, 0.37, 0.23, 0.3 , 0.29, 0.15],\n       [0.48, 0.47, 0.33, 0.53, 0.51, 0.36],\n       [0.28, 0.26, 0.16, 0.2 , 0.18, 0.1 ],\n       [0.89, 0.9 , 0.79, 0.9 , 0.89, 0.75],\n       [0.52, 0.51, 0.36, 0.44, 0.41, 0.27],\n       [0.25, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.67, 0.68, 0.5 , 0.67, 0.63, 0.47],\n       [0.51, 0.51, 0.36, 0.48, 0.47, 0.31],\n       [0.49, 0.49, 0.34, 0.44, 0.44, 0.27],\n       [0.31, 0.29, 0.18, 0.27, 0.24, 0.14],\n       [0.21, 0.2 , 0.11, 0.18, 0.17, 0.08],\n       [0.48, 0.47, 0.33, 0.46, 0.46, 0.29],\n       [0.28, 0.27, 0.16, 0.21, 0.19, 0.1 ],\n       [0.29, 0.27, 0.16, 0.24, 0.22, 0.12],\n       [0.57, 0.58, 0.41, 0.57, 0.63, 0.36],\n       [0.28, 0.27, 0.15, 0.21, 0.2 , 0.1 ],\n       [0.14, 0.13, 0.06, 0.09, 0.08, 0.04],\n       [0.78, 0.77, 0.68, 0.81, 0.76, 0.67],\n       [0.37, 0.35, 0.22, 0.3 , 0.26, 0.15],\n       [0.31, 0.31, 0.18, 0.25, 0.25, 0.12],\n       [0.38, 0.37, 0.23, 0.38, 0.35, 0.19],\n       [0.27, 0.26, 0.15, 0.2 , 0.19, 0.09],\n       [0.29, 0.28, 0.17, 0.23, 0.22, 0.11],\n       [0.06, 0.05, 0.02, 0.04, 0.03, 0.01],\n       [0.38, 0.37, 0.24, 0.34, 0.32, 0.19],\n       [0.61, 0.59, 0.46, 0.63, 0.6 , 0.45],\n       [0.38, 0.37, 0.23, 0.3 , 0.32, 0.15],\n       [0.41, 0.46, 0.27, 0.42, 0.46, 0.26],\n       [0.24, 0.23, 0.13, 0.2 , 0.18, 0.09],\n       [0.25, 0.24, 0.14, 0.22, 0.19, 0.1 ],\n       [0.36, 0.35, 0.23, 0.4 , 0.36, 0.23],\n       [0.26, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.37, 0.35, 0.22, 0.31, 0.28, 0.16],\n       [0.34, 0.32, 0.2 , 0.27, 0.24, 0.14],\n       [0.26, 0.27, 0.14, 0.27, 0.26, 0.14],\n       [0.16, 0.15, 0.08, 0.1 , 0.1 , 0.04],\n       [0.6 , 0.6 , 0.45, 0.53, 0.53, 0.33],\n       [0.33, 0.33, 0.18, 0.28, 0.27, 0.14],\n       [0.32, 0.3 , 0.18, 0.28, 0.25, 0.14],\n       [0.39, 0.41, 0.24, 0.35, 0.35, 0.18],\n       [0.38, 0.38, 0.23, 0.31, 0.3 , 0.17],\n       [0.25, 0.24, 0.14, 0.22, 0.2 , 0.1 ],\n       [0.4 , 0.39, 0.25, 0.3 , 0.28, 0.16],\n       [0.36, 0.35, 0.22, 0.3 , 0.28, 0.16],\n       [0.22, 0.21, 0.11, 0.15, 0.14, 0.07],\n       [0.32, 0.31, 0.19, 0.24, 0.24, 0.12],\n       [0.64, 0.61, 0.49, 0.58, 0.55, 0.38],\n       [0.35, 0.32, 0.21, 0.25, 0.22, 0.12],\n       [0.37, 0.37, 0.22, 0.33, 0.32, 0.18],\n       [0.34, 0.35, 0.2 , 0.28, 0.28, 0.14]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SPLIT INTO TRAIN/TEST SETS (0.8 / 0.2)\n",
    "# trainset = scaled_data[:455, :]\n",
    "# testset = scaled_data[455:, :]\n",
    "# trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data_train = trainset.copy()\n",
    "\n",
    "# missing_data_train = fill_nan(trainset, trainset.size*0.2)\n",
    "\n",
    "# full_data_test = testset.copy()\n",
    "\n",
    "# missing_data_test = fill_nan(testset, testset.size*0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_data_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_data_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Linear(in_features=6, out_features=8)\n",
    "        self.enc2 = nn.Linear(in_features=8, out_features=16)\n",
    "\n",
    "        self.dec2 = nn.Linear(in_features=16, out_features=8)\n",
    "        self.dec3 = nn.Linear(in_features=8, out_features=6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.enc1(x))\n",
    "        x = F.leaky_relu(self.enc2(x))\n",
    "        x = F.leaky_relu(self.dec2(x))\n",
    "        x = self.dec3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SEED FOR CONSISTENT WEIGHT INITIALIZATIONS - FOR TESTING PURPOSES\n",
    "random.seed(2)\n",
    "torch.manual_seed(random.randint(1, 10))\n",
    "net = Autoencoder().double()\n",
    "#net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 110\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = -1\n",
    "NUM_FEATURES = 6\n",
    "BATCH_SIZE_TEST = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.float64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([426, 6])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.from_numpy(x_train)\n",
    "#x_train = x_train.to(device)\n",
    "x_train = x_train.view(BATCH_SIZE, NUM_FEATURES)\n",
    "\n",
    "y_train = torch.from_numpy(y_train)\n",
    "#y_train = y_train.to(device)\n",
    "y_train = y_train.view(BATCH_SIZE, NUM_FEATURES)\n",
    "\n",
    "x_test = torch.from_numpy(x_test)\n",
    "#x_test = x_test.to(device)\n",
    "x_test = x_test.view(BATCH_SIZE_TEST, NUM_FEATURES)\n",
    "\n",
    "y_test = torch.from_numpy(y_test)\n",
    "#y_test = y_test.to(device)\n",
    "y_test = y_test.view(BATCH_SIZE_TEST, NUM_FEATURES)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    train_loss = []\n",
    "    torch.set_printoptions(precision=2, sci_mode=True)\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # running_loss: LOSS OF THE PREDICTED MISSING VALUE ONLY\n",
    "        # overall_loss: LOSS OF ALL RECONSTRUCTED VALUES\n",
    "\n",
    "        running_loss = 0.0\n",
    "        overall_loss = 0.0\n",
    "        count = 0\n",
    "        for missing_data, full_data in zip(x_train, y_train):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(missing_data.double())\n",
    "\n",
    "            # LEARN FROM LOSS OF ALL RECONSTRUCTED VALUES\n",
    "            loss = criterion(outputs, full_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            overall_loss += loss.item()\n",
    "            \n",
    "            # COMPUTE LOSS OF PREDICTED MISSING VALUE\n",
    "            if NAN in missing_data:\n",
    "                for index in range(len(missing_data)):\n",
    "                    if missing_data[index] == NAN:\n",
    "                        predicted_loss = criterion(outputs[index], full_data[index])\n",
    "                        running_loss += predicted_loss.item()\n",
    "                        count += 1\n",
    "            \n",
    "            # PRINT ALL VALUES ON LAST EPOCH FOR TESTING PURPOSES\n",
    "            if epoch == NUM_EPOCHS-1:\n",
    "                if missing_data.detach().numpy().all() == full_data.detach().numpy().all():\n",
    "                    print(\"Input: \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                    print(\"Target: \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                    print(\"Outputs: \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "                else:\n",
    "                    print(\"Input (missing): \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                    print(\"Target (missing): \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                    print(\"Outputs (missing): \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "        \n",
    "      #  loss = running_loss / count\n",
    "        overall_loss = overall_loss / len(x_train)\n",
    "        x_loss = running_loss / count\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        print('Epoch {} of {}, Train Loss: {:.5f}, Overall: {:.5f}'\n",
    "             .format(epoch+1, NUM_EPOCHS, x_loss, overall_loss))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(net):\n",
    "\n",
    "    net.eval()\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = []\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for missing_data, full_data in zip(x_test, y_test):\n",
    "            outputs = net(missing_data.double())\n",
    "            if NAN in missing_data:\n",
    "                for index in range(len(missing_data)):\n",
    "                    if missing_data[index] == NAN:\n",
    "                        predicted_loss = criterion(outputs[index], full_data[index])\n",
    "                        running_loss += predicted_loss.item()\n",
    "                        count += 1\n",
    "            \n",
    "            if missing_data.detach().numpy().all() == full_data.detach().numpy().all():\n",
    "                print(\"Input: \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                print(\"Target: \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                print(\"Outputs: \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "            else:\n",
    "                print(\"Input (missing): \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                print(\"Target (missing): \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                print(\"Outputs (missing): \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "\n",
    "        overall_loss = running_loss / len(x_test)\n",
    "        x_loss = running_loss / count\n",
    "        test_loss.append(loss)\n",
    "        print('Test Loss: {:.3f}, Overall: {:.5f}'.format(x_loss, overall_loss))\n",
    "\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\nOutputs (missing):  [[  18.67  124.86 1142.02   23.17  149.61 1659.13]]\nInput (missing):  [[   6.98  152.8  1509.     28.4   206.8  2360.  ]]\nTarget (missing):  [[  22.27  152.8  1509.     28.4   206.8  2360.  ]]\nOutputs (missing):  [[  23.19  154.92 1597.49   28.89  197.45 2336.95]]\nInput (missing):  [[  6.98  43.79 143.5   13.09  85.07 523.7 ]]\nTarget (missing):  [[ 12.    76.77 442.5   13.09  85.07 523.7 ]]\nOutputs (missing):  [[ 11.36  72.94 384.71  12.56  80.85 456.31]]\nInput:  [[ 14.4   92.25 646.1   15.4  100.4  734.6 ]]\nTarget:  [[ 14.4   92.25 646.1   15.4  100.4  734.6 ]]\nOutputs:  [[ 14.22  92.01 643.54  16.11 107.96 877.67]]\nInput (missing):  [[ 12.21  78.78 462.    13.13  50.41 529.9 ]]\nTarget (missing):  [[ 12.21  78.78 462.    13.13  87.65 529.9 ]]\nOutputs (missing):  [[ 12.15  78.8  477.93  13.79  89.11 590.01]]\nInput (missing):  [[ 10.91  69.14 143.5   11.37  50.41 392.2 ]]\nTarget (missing):  [[ 10.91  69.14 363.7   11.37  72.42 392.2 ]]\nOutputs (missing):  [[ 10.65  68.29 321.58  11.69  74.24 351.11]]\nInput (missing):  [[ 13.61  43.79 572.6   16.89  50.41 848.7 ]]\nTarget (missing):  [[ 13.61  87.76 572.6   16.89 113.2  848.7 ]]\nOutputs (missing):  [[ 13.77  90.32 641.28  16.16 103.57 859.38]]\nInput:  [[ 11.62  76.38 408.8   13.36  88.14 528.1 ]]\nTarget:  [[ 11.62  76.38 408.8   13.36  88.14 528.1 ]]\nOutputs:  [[ 12.46  80.08 477.22  13.82  91.28 609.46]]\nInput (missing):  [[ 10.71  43.79 344.9   11.69  50.41 185.2 ]]\nTarget (missing):  [[ 10.71  69.5  344.9   11.69  76.51 410.4 ]]\nOutputs (missing):  [[ 10.37  66.09 277.77  11.15  70.82 293.67]]\nInput (missing):  [[ 13.27  84.55 143.5   15.14  98.84 708.8 ]]\nTarget (missing):  [[ 13.27  84.55 546.4   15.14  98.84 708.8 ]]\nOutputs (missing):  [[ 13.51  87.47 585.15  15.37 100.85 787.01]]\nInput (missing):  [[  6.98  86.34 557.2   15.05  96.69 185.2 ]]\nTarget (missing):  [[ 13.38  86.34 557.2   15.05  96.69 705.6 ]]\nOutputs (missing):  [[ 12.66  82.05 527.39  14.43  94.25 671.1 ]]\nInput (missing):  [[ 14.03  89.79 603.4   15.33  98.27 185.2 ]]\nTarget (missing):  [[ 14.03  89.79 603.4   15.33  98.27 715.5 ]]\nOutputs (missing):  [[ 13.35  86.14 564.82  15.01  99.94 749.43]]\nInput:  [[  21.37  141.3  1386.     22.69  152.1  1535.  ]]\nTarget:  [[  21.37  141.3  1386.     22.69  152.1  1535.  ]]\nOutputs:  [[  20.7   136.14 1261.01   24.66  169.12 1874.6 ]]\nInput:  [[  17.91  124.4   994.     20.8   149.6  1304.  ]]\nTarget:  [[  17.91  124.4   994.     20.8   149.6  1304.  ]]\nOutputs:  [[  18.39  120.23 1039.27   21.53  147.79 1511.55]]\nInput (missing):  [[  6.98  43.79 541.8    7.93  96.59 623.7 ]]\nTarget (missing):  [[ 13.28  85.79 541.8   14.24  96.59 623.7 ]]\nOutputs (missing):  [[ 11.13  70.92 352.95  12.05  79.07 404.86]]\nInput (missing):  [[  6.98  43.79 143.5    9.26  58.36 259.2 ]]\nTarget (missing):  [[  8.67  54.42 227.2    9.26  58.36 259.2 ]]\nOutputs (missing):  [[  9.48  60.16 203.44  10.07  62.86 166.27]]\nInput:  [[ 14.19  92.87 610.7   16.86 115.   811.3 ]]\nTarget:  [[ 14.19  92.87 610.7   16.86 115.   811.3 ]]\nOutputs:  [[ 14.89  96.52 706.55  16.96 114.38 975.67]]\nInput (missing):  [[  16.24  108.8   143.5    18.55  126.9  1031.  ]]\nTarget (missing):  [[  16.24  108.8   805.1    18.55  126.9  1031.  ]]\nOutputs (missing):  [[  16.09  105.17  837.17   18.86  125.07 1192.15]]\nInput:  [[ 11.64  75.17 412.5   13.14  85.51 521.7 ]]\nTarget:  [[ 11.64  75.17 412.5   13.14  85.51 521.7 ]]\nOutputs:  [[ 12.32  79.17 463.26  13.62  89.91 584.92]]\nInput (missing):  [[ 14.97  96.22 685.9   16.11  50.41 793.7 ]]\nTarget (missing):  [[ 14.97  96.22 685.9   16.11 104.6  793.7 ]]\nOutputs (missing):  [[ 14.33  94.16 705.55  16.84 110.68 936.11]]\nInput (missing):  [[  21.61  144.4  1407.      7.93  172.   2081.  ]]\nTarget (missing):  [[  21.61  144.4  1407.     26.23  172.   2081.  ]]\nOutputs (missing):  [[  21.93  145.17 1414.92   26.79  180.74 2118.66]]\nInput:  [[ 11.16  70.95 380.3   12.36  79.26 458.  ]]\nTarget:  [[ 11.16  70.95 380.3   12.36  79.26 458.  ]]\nOutputs:  [[ 11.79  75.59 412.8   12.93  84.78 503.43]]\nInput (missing):  [[ 14.04  89.78 611.2    7.93 101.2  750.  ]]\nTarget (missing):  [[ 14.04  89.78 611.2   15.66 101.2  750.  ]]\nOutputs (missing):  [[ 14.05  91.21 644.8   16.13 106.28 876.42]]\nInput:  [[  16.84  108.4   880.2    18.22  120.3  1032.  ]]\nTarget:  [[  16.84  108.4   880.2    18.22  120.3  1032.  ]]\nOutputs:  [[  16.38  106.7   846.52   18.89  128.32 1198.99]]\nInput (missing):  [[  18.61  122.1  1094.     21.31   50.41 1403.  ]]\nTarget (missing):  [[  18.61  122.1  1094.     21.31  139.9  1403.  ]]\nOutputs (missing):  [[  18.12  120.96 1108.15   22.24  148.17 1547.09]]\nInput (missing):  [[ 11.95  77.23 143.5    7.93  83.09 185.2 ]]\nTarget (missing):  [[ 11.95  77.23 426.7   12.81  83.09 496.2 ]]\nOutputs (missing):  [[ 11.26  72.2  378.27  12.45  79.95 445.96]]\nInput (missing):  [[   6.98  132.9   143.5     7.93   50.41 1844.  ]]\nTarget (missing):  [[  20.31  132.9  1288.     24.33  162.3  1844.  ]]\nOutputs (missing):  [[  15.9   107.38  990.79   20.25  131.41 1293.21]]\nInput (missing):  [[ 19.18 127.5  143.5   23.36 166.4  185.2 ]]\nTarget (missing):  [[  19.18  127.5  1148.     23.36  166.4  1688.  ]]\nOutputs (missing):  [[  17.25  113.04  955.72   20.42  136.44 1374.27]]\nInput (missing):  [[  18.94  123.6  1130.     24.86   50.41 1866.  ]]\nTarget (missing):  [[  18.94  123.6  1130.     24.86  165.9  1866.  ]]\nOutputs (missing):  [[  19.48  130.8  1259.57   24.29  161.4  1773.74]]\nInput:  [[ 11.54  73.73 409.1   12.34  81.23 467.8 ]]\nTarget:  [[ 11.54  73.73 409.1   12.34  81.23 467.8 ]]\nOutputs:  [[ 11.97  76.74 428.2   13.13  86.39 525.41]]\nInput (missing):  [[   6.98  147.3   143.5    28.19   50.41 2384.  ]]\nTarget (missing):  [[  21.75  147.3  1491.     28.19  195.9  2384.  ]]\nOutputs (missing):  [[  18.9   129.56 1333.49   24.94  160.82 1802.85]]\nInput (missing):  [[ 13.78  88.37 585.9    7.93  97.9  706.6 ]]\nTarget (missing):  [[ 13.78  88.37 585.9   15.27  97.9  706.6 ]]\nOutputs (missing):  [[ 13.84  89.75 622.41  15.82 104.07 838.68]]\nInput (missing):  [[  6.98  90.63 588.9    7.93  50.41 806.9 ]]\nTarget (missing):  [[ 13.77  90.63 588.9   16.39 111.6  806.9 ]]\nOutputs (missing):  [[ 13.32  88.25 666.24  16.06 103.54 830.55]]\nInput (missing):  [[ 10.17  64.55 311.9    7.93  69.86 368.6 ]]\nTarget (missing):  [[ 10.17  64.55 311.9   11.02  69.86 368.6 ]]\nOutputs (missing):  [[ 10.83  69.07 324.41  11.69  75.78 358.31]]\nInput (missing):  [[ 12.65  82.69 485.6   14.38  50.41 633.7 ]]\nTarget (missing):  [[ 12.65  82.69 485.6   14.38  95.29 633.7 ]]\nOutputs (missing):  [[ 12.76  83.22 544.11  14.65  95.15 683.02]]\nInput (missing):  [[ 12.36  43.79 466.1   13.83  91.46 185.2 ]]\nTarget (missing):  [[ 12.36  79.78 466.1   13.83  91.46 574.7 ]]\nOutputs (missing):  [[ 12.15  78.14 449.16  13.47  87.84 562.83]]\nInput (missing):  [[ 11.41  73.53 402.     7.93  79.12 467.2 ]]\nTarget (missing):  [[ 11.41  73.53 402.    12.37  79.12 467.2 ]]\nOutputs (missing):  [[ 11.9   76.44 430.17  13.16  85.82 529.51]]\nInput (missing):  [[  9.78  62.5  143.5   11.05  71.68 185.2 ]]\nTarget (missing):  [[  9.78  62.5  290.2   11.05  71.68 367.  ]]\nOutputs (missing):  [[ 10.55  67.12 294.79  11.3   72.93 312.15]]\nInput (missing):  [[ 16.13 107.   807.2   20.21 132.7  185.2 ]]\nTarget (missing):  [[  16.13  107.    807.2    20.21  132.7  1261.  ]]\nOutputs (missing):  [[  15.9   103.4   804.25   18.28  123.95 1127.84]]\nInput (missing):  [[ 11.2   43.79 143.5    7.93  75.19 439.6 ]]\nTarget (missing):  [[ 11.2   70.67 386.    11.92  75.19 439.6 ]]\nOutputs (missing):  [[ 10.52  67.11 298.97  11.39  72.54 321.23]]\nInput (missing):  [[  6.98  43.79 288.5   10.62  66.53 342.9 ]]\nTarget (missing):  [[  9.74  61.24 288.5   10.62  66.53 342.9 ]]\nOutputs (missing):  [[ 10.28  65.68 280.44  11.11  70.56 283.78]]\nInput:  [[  17.6   119.    980.5    21.57  143.6  1437.  ]]\nTarget:  [[  17.6   119.    980.5    21.57  143.6  1437.  ]]\nOutputs:  [[  18.55  121.35 1045.58   21.64  148.67 1518.46]]\nInput (missing):  [[ 11.52  73.87 143.5   12.65  50.41 491.8 ]]\nTarget (missing):  [[ 11.52  73.87 406.3   12.65  80.88 491.8 ]]\nOutputs (missing):  [[ 11.35  73.35 397.95  12.69  81.26 460.78]]\nInput (missing):  [[  20.55   43.79 1308.     24.3   160.2  1809.  ]]\nTarget (missing):  [[  20.55  137.8  1308.     24.3   160.2  1809.  ]]\nOutputs (missing):  [[  21.46  142.29 1348.21   26.13  173.86 2027.29]]\nInput:  [[ 11.81  75.27 428.9   12.57  79.57 489.5 ]]\nTarget:  [[ 11.81  75.27 428.9   12.57  79.57 489.5 ]]\nOutputs:  [[ 12.14  77.92 442.6   13.35  87.89 551.18]]\nInput (missing):  [[ 12.67  81.25 489.9    7.93  50.41 185.2 ]]\nTarget (missing):  [[ 12.67  81.25 489.9   13.71  88.7  574.4 ]]\nOutputs (missing):  [[ 12.08  78.39 474.42  13.76  88.06 586.76]]\nInput (missing):  [[ 12.34  81.15 477.4   15.65 101.7  185.2 ]]\nTarget (missing):  [[ 12.34  81.15 477.4   15.65 101.7  768.9 ]]\nOutputs (missing):  [[ 13.11  84.43 536.4   14.6   97.45 698.93]]\nInput:  [[  9.03  58.79 250.5   10.31  65.5  324.7 ]]\nTarget:  [[  9.03  58.79 250.5   10.31  65.5  324.7 ]]\nOutputs:  [[ 10.47  66.81 292.28  11.28  72.21 307.16]]\nInput (missing):  [[ 11.68  75.49 143.5   13.32  50.41 549.8 ]]\nTarget (missing):  [[ 11.68  75.49 420.5   13.32  86.57 549.8 ]]\nOutputs (missing):  [[ 11.69  75.8  436.68  13.21  84.7  518.44]]\nInput:  [[ 14.61  92.68 664.9   16.46 103.7  840.8 ]]\nTarget:  [[ 14.61  92.68 664.9   16.46 103.7  840.8 ]]\nOutputs:  [[ 14.73  95.48 685.46  16.69 112.45 941.18]]\nInput (missing):  [[  6.98  96.71 719.5   17.26 110.1  931.4 ]]\nTarget (missing):  [[ 15.13  96.71 719.5   17.26 110.1  931.4 ]]\nOutputs (missing):  [[  14.89   97.84  764.08   17.58  116.43 1023.37]]\nInput:  [[ 12.88  82.5  514.3   13.89  88.84 595.7 ]]\nTarget:  [[ 12.88  82.5  514.3   13.89  88.84 595.7 ]]\nOutputs:  [[ 13.05  84.07 527.84  14.52  96.6  687.6 ]]\nInput (missing):  [[ 13.11  43.79 529.4   14.55  50.41 639.3 ]]\nTarget (missing):  [[ 13.11  87.02 529.4   14.55  99.48 639.3 ]]\nOutputs (missing):  [[ 12.66  82.39 517.77  14.46  92.56 664.77]]\nInput (missing):  [[  8.88  56.74 241.     9.98  65.27 185.2 ]]\nTarget (missing):  [[  8.88  56.74 241.     9.98  65.27 302.  ]]\nOutputs (missing):  [[ 10.14  64.41 256.25  10.8   68.88 252.67]]\nInput (missing):  [[ 11.69  76.37 406.4   12.98  50.41 487.7 ]]\nTarget (missing):  [[ 11.69  76.37 406.4   12.98  86.12 487.7 ]]\nOutputs (missing):  [[ 11.87  77.   451.44  13.4   86.51 541.28]]\nInput:  [[ 14.96  97.03 687.3   16.25 109.1  809.8 ]]\nTarget:  [[ 14.96  97.03 687.3   16.25 109.1  809.8 ]]\nOutputs:  [[ 14.9   96.64 703.58  16.93 114.22 969.2 ]]\nInput (missing):  [[ 17.08 111.2  930.9   22.96 152.1  185.2 ]]\nTarget (missing):  [[  17.08  111.2   930.9    22.96  152.1  1648.  ]]\nOutputs (missing):  [[  17.24  112.49  931.42   20.04  136.64 1332.96]]\nInput (missing):  [[ 12.89  81.89 515.9   13.62  50.41 577.  ]]\nTarget (missing):  [[ 12.89  81.89 515.9   13.62  87.4  577.  ]]\nOutputs (missing):  [[ 12.66  82.45 530.71  14.47  94.19 664.21]]\nInput:  [[  25.73  174.2  2010.     33.13  229.3  3234.  ]]\nTarget:  [[  25.73  174.2  2010.     33.13  229.3  3234.  ]]\nOutputs:  [[  28.4   188.56 1990.82   34.59  242.73 3022.26]]\nInput (missing):  [[  18.03  117.5   143.5     7.93  133.3  1292.  ]]\nTarget (missing):  [[  18.03  117.5   990.     20.38  133.3  1292.  ]]\nOutputs (missing):  [[  15.95  104.47  839.64   18.88  123.95 1192.84]]\nInput (missing):  [[ 12.3   77.88 464.4   13.35  50.41 544.3 ]]\nTarget (missing):  [[ 12.3   77.88 464.4   13.35  84.53 544.3 ]]\nOutputs (missing):  [[ 12.23  79.45 486.49  13.88  89.92 597.3 ]]\nInput:  [[  21.09  142.7  1311.     26.68  176.5  2089.  ]]\nTarget:  [[  21.09  142.7  1311.     26.68  176.5  2089.  ]]\nOutputs:  [[  22.39  147.65 1417.38   26.75  185.23 2112.83]]\nInput (missing):  [[   6.98  117.3   981.6    21.53  145.4  1437.  ]]\nTarget (missing):  [[  17.75  117.3   981.6    21.53  145.4  1437.  ]]\nOutputs (missing):  [[  17.91  118.71 1068.89   21.7   146.   1499.74]]\nInput:  [[  17.29  114.4   947.8    20.39  137.9  1295.  ]]\nTarget:  [[  17.29  114.4   947.8    20.39  137.9  1295.  ]]\nOutputs:  [[  17.79  116.27  977.06   20.69  141.62 1410.25]]\nInput (missing):  [[ 13.59  43.79 572.3   15.5   98.91 739.1 ]]\nTarget (missing):  [[ 13.59  86.24 572.3   15.5   98.91 739.1 ]]\nOutputs (missing):  [[ 14.08  91.58 637.58  16.16 105.48 874.1 ]]\nInput:  [[ 11.34  72.48 396.5   13.01  83.99 518.1 ]]\nTarget:  [[ 11.34  72.48 396.5   13.01  83.99 518.1 ]]\nOutputs:  [[ 12.2   78.4  450.45  13.46  88.56 565.09]]\nInput (missing):  [[  17.06   43.79  918.6    20.99  143.2  1362.  ]]\nTarget (missing):  [[  17.06  111.8   918.6    20.99  143.2  1362.  ]]\nOutputs (missing):  [[  18.42  121.44 1058.85   22.05  145.97 1558.02]]\nInput (missing):  [[  6.98  82.38 512.2   13.9   50.41 597.5 ]]\nTarget (missing):  [[ 12.87  82.38 512.2   13.9   89.27 597.5 ]]\nOutputs (missing):  [[ 12.43  81.96 559.96  14.73  93.94 679.34]]\nInput (missing):  [[ 13.05  43.79 530.6    7.93  93.96 672.4 ]]\nTarget (missing):  [[ 13.05  82.71 530.6   14.73  93.96 672.4 ]]\nOutputs (missing):  [[ 11.76  75.36 414.08  12.94  84.65 505.32]]\nInput (missing):  [[  19.07  128.3   143.5    24.09  177.4  1651.  ]]\nTarget (missing):  [[  19.07  128.3  1104.     24.09  177.4  1651.  ]]\nOutputs (missing):  [[  20.26  133.9  1243.71   24.53  164.14 1850.01]]\nInput (missing): [[ 12.8   83.05 508.3    7.93  90.72 591.  ]]\nTarget (missing):  [[ 12.8   83.05 508.3   13.74  90.72 591.  ]]\nOutputs (missing):  [[ 13.02  84.2  543.01  14.74  96.51 714.41]]\nInput (missing):  [[  6.98  62.92 295.4   10.42  67.08 331.6 ]]\nTarget (missing):  [[  9.88  62.92 295.4   10.42  67.08 331.6 ]]\nOutputs (missing):  [[ 10.49  67.27 312.1   11.51  73.04 329.32]]\nInput (missing):  [[ 23.51  43.79 143.5   30.67 202.4  185.2 ]]\nTarget (missing):  [[  23.51  155.1  1747.     30.67  202.4  2906.  ]]\nOutputs (missing):  [[  21.07  140.69 1361.     26.48  169.69 2060.95]]\nInput (missing):  [[  6.98  94.89 673.7   16.31 102.3  777.5 ]]\nTarget (missing):  [[ 14.86  94.89 673.7   16.31 102.3  777.5 ]]\nOutputs (missing):  [[ 14.21  93.23 698.68  16.71 109.98 924.76]]\nInput (missing):  [[  6.98  43.79 143.5   14.98 101.1  686.6 ]]\nTarget (missing):  [[ 13.56  88.59 561.3   14.98 101.1  686.6 ]]\nOutputs (missing):  [[ 12.46  80.53 491.74  14.01  91.53 623.75]]\nInput (missing):  [[ 14.95  96.85 678.1   18.55 121.4  185.2 ]]\nTarget (missing):  [[ 14.95  96.85 678.1   18.55 121.4  971.4 ]]\nOutputs (missing):  [[ 14.78  95.83 699.67  16.86 113.5  964.12]]\nInput (missing):  [[  6.98  80.88 495.    13.65  88.12 566.9 ]]\nTarget (missing):  [[ 12.7   80.88 495.    13.65  88.12 566.9 ]]\nOutputs (missing):  [[ 12.54  81.53 523.26  14.36  93.37 656.78]]\nInput (missing):  [[ 13.16  84.06 538.7   14.5   95.29 185.2 ]]\nTarget (missing):  [[ 13.16  84.06 538.7   14.5   95.29 648.3 ]]\nOutputs (missing):  [[ 12.81  82.43 510.62  14.26  94.8  660.29]]\nInput (missing):  [[  8.2   43.79 143.5    8.96  57.26 185.2 ]]\nTarget (missing):  [[  8.2   51.71 201.9    8.96  57.26 242.2 ]]\nOutputs (missing):  [[  9.46  59.86 195.03   9.96  62.58 156.11]]\nInput (missing):  [[ 15.05  97.26 701.9    7.93 113.8  967.  ]]\nTarget (missing):  [[ 15.05  97.26 701.9   17.58 113.8  967.  ]]\nOutputs (missing):  [[  15.17   98.86  753.43   17.66  116.97 1054.5 ]]\nInput:  [[  19.8   129.7  1230.     25.73  170.3  2009.  ]]\nTarget:  [[  19.8   129.7  1230.     25.73  170.3  2009.  ]]\nOutputs:  [[  21.51  141.69 1333.31   25.65  176.97 1988.05]]\nInput (missing):  [[ 15.    97.45 143.5   16.41 114.2  808.2 ]]\nTarget (missing):  [[ 15.    97.45 684.5   16.41 114.2  808.2 ]]\nOutputs (missing):  [[ 14.64  95.25 695.54  16.9  111.63 964.12]]\nInput (missing):  [[ 15.66 110.2  143.5   19.85 143.7  185.2 ]]\nTarget (missing):  [[  15.66  110.2   773.5    19.85  143.7  1226.  ]]\nOutputs (missing):  [[  15.36  100.05  769.62   17.87  119.07 1079.07]]\nInput:  [[ 12.04  76.85 449.9   13.6   87.24 567.6 ]]\nTarget:  [[ 12.04  76.85 449.9   13.6   87.24 567.6 ]]\nOutputs:  [[ 12.61  81.14 489.5   14.01  92.7  629.15]]\nInput (missing):  [[  6.98  78.41 466.1   14.1   50.41 185.2 ]]\nTarget (missing):  [[ 12.27  78.41 466.1   14.1   89.   610.2 ]]\nOutputs (missing):  [[ 11.56  75.61 458.64  13.42  85.03 533.37]]\nInput (missing):  [[ 14.68  94.74 684.5   19.07 123.4  185.2 ]]\nTarget (missing):  [[  14.68   94.74  684.5    19.07  123.4  1138.  ]]\nOutputs (missing):  [[ 14.89  96.6  710.72  17.03 114.75 983.32]]\nInput (missing):  [[ 12.49  79.19 143.5   13.34  84.48 544.2 ]]\nTarget (missing):  [[ 12.49  79.19 481.6   13.34  84.48 544.2 ]]\nOutputs (missing):  [[ 12.29  79.11 464.72  13.7   89.48 591.76]]\nInput:  [[ 14.74  94.7  668.6   16.51 107.4  826.4 ]]\nTarget:  [[ 14.74  94.7  668.6   16.51 107.4  826.4 ]]\nOutputs:  [[ 14.76  95.73 693.2   16.82 113.29 957.45]]\nInput (missing):  [[ 14.11  43.79 616.5   15.53  98.4  185.2 ]]\nTarget (missing):  [[ 14.11  90.03 616.5   15.53  98.4  749.9 ]]\nOutputs (missing):  [[ 13.07  84.55 541.34  14.81  96.66 718.71]]\nInput:  [[ 12.45  82.57 477.1   15.47 103.4  741.6 ]]\nTarget:  [[ 12.45  82.57 477.1   15.47 103.4  741.6 ]]\nOutputs:  [[ 13.77  88.96 599.13  15.52 103.87 805.73]]\nInput (missing):  [[ 10.26  65.85 320.8   10.83  50.41 357.4 ]]\nTarget (missing):  [[ 10.26  65.85 320.8   10.83  71.08 357.4 ]]\nOutputs (missing):  [[ 10.71  68.77 328.14  11.78  75.05 359.9 ]]\nInput (missing):  [[  19.68  129.9  1194.      7.93  157.6  1540.  ]]\nTarget (missing):  [[  19.68  129.9  1194.     22.75  157.6  1540.  ]]\nOutputs (missing):  [[  19.71  130.04 1201.48   23.9   160.31 1780.39]]\nInput (missing):  [[  6.98  90.96 578.9   15.75 104.4  750.1 ]]\nTarget (missing):  [[ 13.86  90.96 578.9   15.75 104.4  750.1 ]]\nOutputs (missing):  [[ 13.8   90.11 646.82  16.07 105.69 854.2 ]]\nInput:  [[ 13.68  87.76 575.5   15.85 101.6  773.4 ]]\nTarget:  [[ 13.68  87.76 575.5   15.85 101.6  773.4 ]]\nOutputs:  [[ 14.11  91.31 630.83  15.97 107.15 857.36]]\nInput:  [[ 15.32 103.2  713.3   17.73 119.8  928.8 ]]\nTarget:  [[ 15.32 103.2  713.3   17.73 119.8  928.8 ]]\nOutputs:  [[  15.67  101.88  780.06   18.02  122.09 1096.81]]\nInput:  [[ 15.04  98.73 689.4   16.76 109.7  856.9 ]]\nTarget:  [[ 15.04  98.73 689.4   16.76 109.7  856.9 ]]\nOutputs:  [[ 15.01  97.38 716.18  17.15 115.69 994.44]]\nInput:  [[ 12.31  79.19 470.9   14.11  89.71 611.1 ]]\nTarget:  [[ 12.31  79.19 470.9   14.11  89.71 611.1 ]]\nOutputs:  [[ 12.9   83.1  516.39  14.4   95.55 673.22]]\nInput (missing):  [[ 15.37  43.79 143.5   16.43 107.5  830.9 ]]\nTarget (missing):  [[ 15.37 100.2  728.2   16.43 107.5  830.9 ]]\nOutputs (missing):  [[  14.98   98.35  746.01   17.84  113.46 1061.1 ]]\nInput (missing):  [[ 14.64  43.79 666.    16.46 106.   831.  ]]\nTarget (missing):  [[ 14.64  94.21 666.    16.46 106.   831.  ]]\nOutputs (missing):  [[ 14.84  96.83 712.97  17.26 112.97 999.68]]\nInput (missing):  [[ 11.54  74.65 143.5   12.26  78.78 457.8 ]]\nTarget (missing):  [[ 11.54  74.65 402.9   12.26  78.78 457.8 ]]\nOutputs (missing):  [[ 11.57  74.11 392.95  12.7   82.85 474.2 ]]\nInput:  [[ 13.66  88.27 580.6   14.54  97.96 657.  ]]\nTarget:  [[ 13.66  88.27 580.6   14.54  97.96 657.  ]]\nOutputs:  [[ 13.62  87.92 584.19  15.32 102.55 780.13]]\nInput (missing):  [[  20.48  132.5  1306.      7.93  161.7  1750.  ]]\nTarget (missing):  [[  20.48  132.5  1306.     24.22  161.7  1750.  ]]\nOutputs (missing):  [[  20.4   134.77 1265.49   24.8   166.82 1881.84]]\nInput:  [[ 14.29  90.3  632.6   14.91  94.44 684.6 ]]\nTarget:  [[ 14.29  90.3  632.6   14.91  94.44 684.6 ]]\nOutputs:  [[ 13.87  89.71 608.05  15.67 104.74 819.6 ]]\nInput:  [[ 14.78  97.4  668.3   17.31 114.6  925.1 ]]\nTarget:  [[ 14.78  97.4  668.3   17.31 114.6  925.1 ]]\nOutputs:  [[  15.23   98.89  736.03   17.42  117.78 1023.96]]\nInput (missing):  [[ 14.22  94.37 609.9   15.74  50.41 762.4 ]]\nTarget (missing):  [[ 14.22  94.37 609.9   15.74 106.4  762.4 ]]\nOutputs (missing):  [[ 13.89  91.15 660.66  16.28 106.56 866.99]]\nEpoch 110 of 110, Train Loss: 0.00037, Overall: 0.00201\n"
    }
   ],
   "source": [
    "# TRAIN THE NEURAL NETWORK\n",
    "results = train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x17e187d4c50>]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAaFUlEQVR4nO3dbYwd133f8e9v5t591JJLWiuJJqlSRmnLrAvZBCvTceE2dtKSShD2VSGhrlIhACFUap0iQCA3r/KuL4ogVqGKVWUlVuJaDRQnJQzCSuDESYtGsla2oujBjNeSIm5JiSvxmct9/vfFzN2dvXuXOxSXWu3h7wNc7J2ZM/ees5R+c/bMzBlFBGZmlq5srStgZmbXloPezCxxDnozs8Q56M3MEuegNzNLXGOtK9DJjTfeGDt27FjrapiZrRsvvPDCuxEx1GnbhzLod+zYwfDw8FpXw8xs3ZD0d8tt89CNmVniHPRmZolz0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJS6poP8v3/sJf/G3Y2tdDTOzD5Wkgv7Rv/gp/9tBb2a2SFJBn2diZs4PUjEzq0oq6Jt5xszc3FpXw8zsQyWpoG9kYtY9ejOzRZIL+ulZB72ZWVVaQZ9nzMx66MbMrCqtoPfJWDOzJdIK+lzMeOjGzGyRtII+y9yjNzNrUyvoJe2TdFTSiKSHOmyXpIfL7S9J2l3ZNijpaUk/lvSapM+tZgOqGrl8eaWZWZsVg15SDjwC7Ad2AfdI2tVWbD+ws3wdBB6tbPsa8N2IuB24A3htFerdUSPz0I2ZWbs6Pfo7gZGIeD0ipoCngANtZQ4AT0bhWWBQ0hZJG4AvAF8HiIipiDizivVfpOEbpszMlqgT9FuBY5Xl0XJdnTIfA8aA35H0I0mPS+rv9CWSDkoaljQ8Nvb+5qtxj97MbKk6Qa8O69rTdLkyDWA38GhEfAa4CCwZ4weIiMciYk9E7BkaGqpRraWKHr2D3sysqk7QjwLbK8vbgOM1y4wCoxHxXLn+aYrgvyaK6+g9dGNmVlUn6J8Hdkq6TVIXcDdwuK3MYeDe8uqbvcDZiDgREW8DxyR9oiz3JeDV1ap8Ow/dmJkt1VipQETMSHoQeAbIgSci4hVJ95fbDwFHgLuAEWAcuK/yEf8O+GZ5kHi9bduqanroxsxsiRWDHiAijlCEeXXdocr7AB5YZt8XgT1XUcfa8kye68bMrE1ad8bmnr3SzKxdWkHv+ejNzJZIK+h9w5SZ2RJJBX3T0xSbmS2RVNDnWebLK83M2iQV9M1cTPuqGzOzRZIK+twnY83Mlkgq6Ftz3RSX9ZuZGSQW9M2smFvNvXozswVJBX2eF0HvK2/MzBYkFfTNrGiOT8iamS1IKugbuYduzMzapRX05Ri957sxM1uQVtDnRXM8DYKZ2YKkgj4ve/S+O9bMbEFSQd/0VTdmZkskFfSN8qqbWQ/dmJnNSyzofTLWzKxdWkHfOhnroDczm5dW0LdOxnroxsxsXlpB75OxZmZLpBX0mYduzMza1Qp6SfskHZU0IumhDtsl6eFy+0uSdle2vSnpbyS9KGl4NSvfbqFH76EbM7OWxkoFJOXAI8DPA6PA85IOR8SrlWL7gZ3l67PAo+XPlp+NiHdXrdbLaPiGKTOzJer06O8ERiLi9YiYAp4CDrSVOQA8GYVngUFJW1a5riuaH7rxGL2Z2bw6Qb8VOFZZHi3X1S0TwJ9IekHSweW+RNJBScOShsfGxmpUa6n5oRtPU2xmNq9O0KvDuvYu8+XKfD4idlMM7zwg6QudviQiHouIPRGxZ2hoqEa1lvIUCGZmS9UJ+lFge2V5G3C8bpmIaP08CfwRxVDQNZFnnr3SzKxdnaB/Htgp6TZJXcDdwOG2MoeBe8urb/YCZyPihKR+SQMAkvqBfwa8vIr1X8RTIJiZLbXiVTcRMSPpQeAZIAeeiIhXJN1fbj8EHAHuAkaAceC+cvebgT+S1Pqu/xER3131VpSaeWtSMwe9mVnLikEPEBFHKMK8uu5Q5X0AD3TY73XgjqusY20L89F76MbMrCWpO2NbJ2M9dGNmtiCpoG/16D10Y2a2IKmgb43RT/uqGzOzeUkFfeuqm1kP3ZiZzUsq6FtDN9MeujEzm5dU0EuikclX3ZiZVSQV9FD06n0y1sxsQXJB38wzX15pZlaRXNA3cjHrq27MzOalF/SZfDLWzKwiwaDPfDLWzKwiuaDPM3k+ejOziuSCvpnLz4w1M6tILugbeeYHj5iZVaQX9Jl79GZmVekFfe4xejOzqvSCPssc9GZmFQkGvee6MTOrSi/ofdWNmdki6QV95qtuzMyq0gt6n4w1M1skvaDPMg/dmJlV1Ap6SfskHZU0IumhDtsl6eFy+0uSdrdtzyX9SNJ3Vqviy2lk8tCNmVnFikEvKQceAfYDu4B7JO1qK7Yf2Fm+DgKPtm3/CvDaVde2Bp+MNTNbrE6P/k5gJCJej4gp4CngQFuZA8CTUXgWGJS0BUDSNuAXgMdXsd7LanhSMzOzReoE/VbgWGV5tFxXt8xvA78OXHY8RdJBScOShsfGxmpUq7NG7mmKzcyq6gS9Oqxr7zJ3LCPpF4GTEfHCSl8SEY9FxJ6I2DM0NFSjWp01fdWNmdkidYJ+FNheWd4GHK9Z5vPAL0l6k2LI54uSfv9917YGz0dvZrZYnaB/Htgp6TZJXcDdwOG2MoeBe8urb/YCZyPiRER8NSK2RcSOcr8/i4gvr2YD2jWyjGkP3ZiZzWusVCAiZiQ9CDwD5MATEfGKpPvL7YeAI8BdwAgwDtx37ap8ec1czLpHb2Y2b8WgB4iIIxRhXl13qPI+gAdW+IzvA9+/4hpeodw3TJmZLZLcnbHNXEz7hikzs3nJBX2eiQiY8/CNmRmQYNA386JJ7tWbmRWSC/pGVlzS7xOyZmaF5II+L4N+2idkzcyABIO+NXTjaRDMzArJBX3uoRszs0WSC/pmXg7dOOjNzIAEg76RFU2a9Ri9mRmQYtDP9+g9Rm9mBikGfdY6GesevZkZJBj0rZOxfm6smVkhuaBvnYx1j97MrJBc0Dda19G7R29mBqQY9Jl79GZmVekGva+jNzMDUgz6+aEbB72ZGaQY9PNDNx6jNzODFIM+9+yVZmZV6QV9awoED92YmQEpBn3uG6bMzKqSC/qmp0AwM1ukVtBL2ifpqKQRSQ912C5JD5fbX5K0u1zfI+kHkv5a0iuSfnO1G9Aud4/ezGyRFYNeUg48AuwHdgH3SNrVVmw/sLN8HQQeLddPAl+MiDuATwP7JO1dpbp31PSjBM3MFqnTo78TGImI1yNiCngKONBW5gDwZBSeBQYlbSmXL5RlmuXrmiawnzBlZrZYnaDfChyrLI+W62qVkZRLehE4CfxpRDzX6UskHZQ0LGl4bGysbv2XaN0wNe3r6M3MgHpBrw7r2rvLy5aJiNmI+DSwDbhT0qc6fUlEPBYReyJiz9DQUI1qdTY/e6V79GZmQL2gHwW2V5a3AcevtExEnAG+D+y74lpeAQ/dmJktVifonwd2SrpNUhdwN3C4rcxh4N7y6pu9wNmIOCFpSNIggKRe4OeAH69i/ZdoXV7poRszs0JjpQIRMSPpQeAZIAeeiIhXJN1fbj8EHAHuAkaAceC+cvctwDfKK3cy4A8i4jur34wFWSYk9+jNzFpWDHqAiDhCEebVdYcq7wN4oMN+LwGfuco6XrFmlvnySjOzUnJ3xkIxDYJnrzQzKyQZ9HkmX3VjZlZKMuibeeYpEMzMSkkGfSOTT8aamZWSDXqfjDUzK6QZ9Hnmk7FmZqU0g94nY83M5qUZ9Ln84BEzs1KaQZ9l7tGbmZXSDPpcvrzSzKyUZtBnHroxM2tJNOh9w5SZWUuaQe+TsWZm8xIN+oxpn4w1MwNSDfpMzHroxswMSDjoPXRjZlZIM+hz3xlrZtaSZtBnnuvGzKwlzaDPPXulmVlLmkHv+ejNzOalGfR+wpSZ2bwkg77paYrNzObVCnpJ+yQdlTQi6aEO2yXp4XL7S5J2l+u3S/pzSa9JekXSV1a7AZ3kWebLK83MSisGvaQceATYD+wC7pG0q63YfmBn+ToIPFqunwF+LSI+CewFHuiw76pr5mLaV92YmQH1evR3AiMR8XpETAFPAQfayhwAnozCs8CgpC0RcSIifggQEeeB14Ctq1j/jnKfjDUzm1cn6LcCxyrLoywN6xXLSNoBfAZ47koreaWKk7FBhMPezKxO0KvDuvYEvWwZSTcAfwj8akSc6/gl0kFJw5KGx8bGalRrec2sqI5PyJqZ1Qv6UWB7ZXkbcLxuGUlNipD/ZkR8e7kviYjHImJPROwZGhqqU/dl5XkR9B6+MTOrF/TPAzsl3SapC7gbONxW5jBwb3n1zV7gbESckCTg68BrEfFbq1rzy2hmRbN8QtbMDBorFYiIGUkPAs8AOfBERLwi6f5y+yHgCHAXMAKMA/eVu38e+NfA30h6sVz3HyPiyOo2Y7E8c4/ezKxlxaAHKIP5SNu6Q5X3ATzQYb//Q+fx+2uqWQ7deL4bM7NE74xt5EWzPA2CmVmiQd8auvHdsWZmiQZ9a+jGl1eamSUa9I3yqhs/N9bMLNmg98lYM7OWNIO+dTLWQW9mlmjQz0+B4KEbM7M0g94nY83M5qUZ9JmHbszMWtIM+txDN2ZmLWkGvW+YMjObl2jQt6ZAcNCbmaUZ9K2hG09TbGaWZtD3NnMALk3PrnFNzMzWXpJBP9jXBOD0+PQa18TMbO0lGfQbeppkgjPjU2tdFTOzNZdk0GeZ2Njb5LSD3swszaAH2NTX5aEbMzMSDvrBvqaHbszMSDjoN/V1cfqie/RmZskG/WBfl3v0ZmYkHPSb+poeozczI+Wg7+/i0vQsE75pysyuc7WCXtI+SUcljUh6qMN2SXq43P6SpN2VbU9IOinp5dWs+EpaN02dca/ezK5zKwa9pBx4BNgP7ALukbSrrdh+YGf5Ogg8Wtn2u8C+1ajsldjU1wXga+nN7LpXp0d/JzASEa9HxBTwFHCgrcwB4MkoPAsMStoCEBF/CZxazUrXsTANgoPezK5vdYJ+K3CssjxarrvSMpcl6aCkYUnDY2NjV7JrR4O9RY/eQzdmdr2rE/TqsK59ovc6ZS4rIh6LiD0RsWdoaOhKdu1oU7979GZmUC/oR4HtleVtwPH3UeYD1Rqjd4/ezK53dYL+eWCnpNskdQF3A4fbyhwG7i2vvtkLnI2IE6tc1yvS08zpaWa+acrMrnsrBn1EzAAPAs8ArwF/EBGvSLpf0v1lsSPA68AI8N+Bf9vaX9K3gL8CPiFpVNKvrHIbluWJzczMoFGnUEQcoQjz6rpDlfcBPLDMvvdcTQWvhqdBMDNL+M5Y8DQIZmaQfNB3+aobM7vuJR30xZz07tGb2fUt6aDfVI7Rz81d0SX9ZmZJSTroB/uazAWcn5hZ66qYma2ZpIPeE5uZmaUe9J4Gwcws7aAf9DQIZmZpB72HbszMkg/61tCNe/Rmdv1KOug39DTJhKdBMLPrWtJBn2ViY2/TQzdmdl1LOujBM1iamSUf9MU0CO7Rm9n1K/mg39TXxemL7tGb2fUr+aD3nPRmdr2r9eCR9ezDNCf93FwwG8FcBM0sI8s6PVPdzGx1pR/0/V1cmp5lYnqWnmb+gXznmfEpfvDGKZ574xRH3z7P8TOXOH72EhPTc4vKdTUyeps5G3obDPZ2MdjX5KaBHm7a0M2WjT1s29TLtk193LKxh4HuBpIPDGZ25dIP+vLu2KNvn+eO7YOr9rlnx6c5+s553nz3Im+dGuetU+OMnh5n9PQlTp6fBKC7kXH7lg3cvmWAn739JgZ6GuQSWSamZuaYmJllYmqWs5emOXtpmlMXpxg5eYGx85PMtE2t3NeVc/OGHrZs7GHLxl62DvZw88Zi+ZYNvWzZ2MNgX9MHAzNbIvmg/+LtN3HTQDcHf2+Yp+//GbZv7rviz3jvwiQvHz/Hi2+d4a9Hz/Dq8XO8fW5ifnueiY8O9rBtsI9/8vEhdtzYzz/asZk7tm+ku3Hlf0XMzQXvXpxk9PQlRk9f4u2zl3j77CTvnJvgxNlL/N+fvss75yZon2a/u5Fxy8Yebh4oDgI3D3Rz04Zuhga6aebF6Zi5gKmZOSZnZskkPtLfxY0D3Xykv4tN/V3+y8EsQSqe6/3hsmfPnhgeHl61zzv69nn+5X/7Kzb2Nnn6/s9x04aeJWXOT0zz5rvjvPHeRY6dGufYqXHefO8iP3nnAu9dLE7mSvD3h27gU1s3cvstA3zilgE+duMNfHSwh0b+wZ7XnpmdY+zCJCfOTvB263Vu4ec75at9uGgljUxs6u9ic18Xm/u72HxDFzf2d7G5v5tN/U029RVDTBt7mwz2drGxr8lAd8PnG8zWmKQXImJPx23XQ9AD/Oit0/yrx58jz8Stm/sYGuhmLuDkuQlOnp/k1MXFV+bceEMX2zf38fGbBvj4LQN88pYB/uG2jQz0NFe1XtdSRHB+coZ3z08yW3b/JejKc7oaGbMRvHdhkncvTHLq4jSnL05xanyq+Fl5vXthknOXeXhLXt6BvLG3yYaeBgM9Tfq6cvq7G/R35wz0NNnQ02Sgp1ju72pwQ3eDG3oa9Hc3GOhpsKGnSXcj818TZu/TVQe9pH3A14AceDwi/lPbdpXb7wLGgX8TET+ss28n1yLoAX741mn+5w+OMXZhkpPnJ8glhsqTn7du7mPHR/q57cZ+tm/upa8r+VGtKzI9O8eZ8WnOjE9xerw4p3BmfKr8Oc3p8SnOT8xwbmKac5emGZ+a5eLUDBcmZjg/MbPknEMnzVz0NosDRG9XTl9XTl+zQV95cOjryuntyult5nQ3c7ob2fwry0QjE5lEnhUvScU5ERXTYeSVbY3Wz1zkWVaeOykOWq3zKMW+CweePNdCOS18hwQCsrJ8lhXv89Y2H7zsA3C5oF8xzSTlwCPAzwOjwPOSDkfEq5Vi+4Gd5euzwKPAZ2vu+4HZfesmdt+6aS2+et1r5hlDA8V4/5WKCCam5zg/Mc3FqVkuTs5wYbI4CFyYnOH85AznJ6Y5PzHDpXL7+NQsl6ZnGZ+a4dTFKUZPX+Li5AyXpme5NDXL5MyVDUmtpUwsHBQo/qpqHRQW3jO/XC0nFg4k8weVVtny81V5jyACZueKy3jbtT6zulzu1vGA1KkjKGl+fafDdwQEQfuu7d+9ZL/y01r7tQ7amYpzSzNzc8zNUTmQs+TTWm24XAc2lqv4cparcvtnaOm2VpGIqPWVm/q6+OMHPn8FlaunTrf1TmAkIl4HkPQUcACohvUB4MkofrvPShqUtAXYUWNfS5ykoifetXqXt87NBVOzc0zOzDE1M8dcBDNzUdyrUIZc8SpCr7Wu9XNmtijf2lZ939p3dm4hrKL8zpnWvRCVsrAQbrNzFPvPld/dKlt+JrHwWQHzQ2rz39f6rFj47rloW1+uW/jeso7ltrxy4GgPn2rYVMO6movB4t2q+d/6PrH4INFu/uDT2hj1srX9gDVT/o4X/oJq3Y/C0gNZ+W8wfzC5zB9Syx3Y2nU6YFR/P9UDy9LfmxZVo9OBqd21GhquE/RbgWOV5VGKXvtKZbbW3BcASQeBgwC33nprjWrZ9SzLRE+Wf2D3RpitZ3UuFel0ELrcHy3VMnX2LVZGPBYReyJiz9DQUI1qmZlZHXV69KPA9sryNuB4zTJdNfY1M7NrqE6P/nlgp6TbJHUBdwOH28ocBu5VYS9wNiJO1NzXzMyuoRV79BExI+lB4BmKSySfiIhXJN1fbj8EHKG4tHKE4vLK+y637zVpiZmZdXTd3DBlZpayy11Hn/x89GZm1zsHvZlZ4hz0ZmaJ+1CO0UsaA/7ufe5+I/DuKlbnwybl9qXcNnD71rsPe/v+XkR0vAnpQxn0V0PS8HInJFKQcvtSbhu4fevdem6fh27MzBLnoDczS1yKQf/YWlfgGku5fSm3Ddy+9W7dti+5MXozM1ssxR69mZlVOOjNzBKXTNBL2ifpqKQRSQ+tdX2ulqTtkv5c0muSXpH0lXL9Zkl/Kukn5c91/WxESbmkH0n6TrmcTPvKJ609LenH5b/j51Jpn6T/UP53+bKkb0nqWe9tk/SEpJOSXq6sW7ZNkr5a5s1RSf98bWpdTxJBX3k27X5gF3CPpF1rW6urNgP8WkR8EtgLPFC26SHgexGxE/heubyefQV4rbKcUvu+Bnw3Im4H7qBo57pvn6StwL8H9kTEpyhmpr2b9d+23wX2ta3r2Kby/8W7gX9Q7vNfyxz6UEoi6Kk81zYipoDWs2nXrYg4ERE/LN+fpwiJrRTt+kZZ7BvAv1ibGl49SduAXwAer6xOon2SNgBfAL4OEBFTEXGGRNpHMcV5r6QG0EfxQKF13baI+EvgVNvq5dp0AHgqIiYj4g2KKdrv/EAq+j6kEvTLPbM2CZJ2AJ8BngNuLh/qQvnzprWr2VX7beDXgbnKulTa9zFgDPidcmjqcUn9JNC+iPh/wH8G3gJOUDxo6E9IoG0dLNemdZU5qQR97WfTrjeSbgD+EPjViDi31vVZLZJ+ETgZES+sdV2ukQawG3g0Ij4DXGT9DWV0VI5THwBuAz4K9Ev68trW6gO3rjInlaCv81zbdUdSkyLkvxkR3y5XvyNpS7l9C3Byrep3lT4P/JKkNymG2r4o6fdJp32jwGhEPFcuP00R/Cm07+eANyJiLCKmgW8DP0MabWu3XJvWVeakEvTJPZtWkijGd1+LiN+qbDoM/HL5/peB//VB1201RMRXI2JbROyg+Pf6s4j4Mum0723gmKRPlKu+BLxKGu17C9grqa/87/RLFOeQUmhbu+XadBi4W1K3pNuAncAP1qB+9UREEi+KZ9b+LfBT4DfWuj6r0J5/TPGn4EvAi+XrLuAjFGf/f1L+3LzWdV2Ftv5T4Dvl+2TaB3waGC7/Df8Y2JRK+4DfBH4MvAz8HtC93tsGfIvinMM0RY/9Vy7XJuA3yrw5Cuxf6/pf7uUpEMzMEpfK0I2ZmS3DQW9mljgHvZlZ4hz0ZmaJc9CbmSXOQW9mljgHvZlZ4v4/r9fKzsbET+4AAAAASUVORK5CYII=\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 378.465625 248.518125 \r\nL 378.465625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m17462d2560\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m17462d2560\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(48.502557 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.530346\" xlink:href=\"#m17462d2560\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(101.167846 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"163.376884\" xlink:href=\"#m17462d2560\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(157.014384 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"219.223423\" xlink:href=\"#m17462d2560\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <defs>\r\n       <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n      </defs>\r\n      <g transform=\"translate(212.860923 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"275.069962\" xlink:href=\"#m17462d2560\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n      </defs>\r\n      <g transform=\"translate(268.707462 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"330.916501\" xlink:href=\"#m17462d2560\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(321.372751 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m77e037a985\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"215.887175\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.00 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 219.686393)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"184.67349\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.01 -->\r\n      <g transform=\"translate(7.2 188.472708)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"153.459804\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.02 -->\r\n      <g transform=\"translate(7.2 157.259023)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"122.246119\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.03 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 126.045338)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"91.032434\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.04 -->\r\n      <g transform=\"translate(7.2 94.831653)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"59.818749\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.05 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 63.617968)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m77e037a985\" y=\"28.605064\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.06 -->\r\n      <g transform=\"translate(7.2 32.404283)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p3def8450b6)\" d=\"M 51.683807 17.083636 \r\nL 54.476134 171.994736 \r\nL 57.268461 209.676712 \r\nL 60.060788 212.667168 \r\nL 62.853115 212.929479 \r\nL 65.645442 212.654723 \r\nL 68.437768 212.245456 \r\nL 71.230095 211.885913 \r\nL 74.022422 211.412264 \r\nL 76.814749 210.812908 \r\nL 79.607076 210.322715 \r\nL 82.399403 209.948097 \r\nL 85.19173 209.601833 \r\nL 87.984057 208.91423 \r\nL 90.776384 208.592855 \r\nL 93.568711 208.564325 \r\nL 96.361038 208.658655 \r\nL 99.153365 208.850829 \r\nL 101.945692 209.124875 \r\nL 104.738019 209.47032 \r\nL 107.530346 209.760877 \r\nL 110.322673 210.079535 \r\nL 113.114999 210.383904 \r\nL 115.907326 210.68551 \r\nL 118.699653 210.976777 \r\nL 121.49198 211.252651 \r\nL 124.284307 211.252563 \r\nL 127.076634 211.173547 \r\nL 129.868961 211.420071 \r\nL 132.661288 211.634903 \r\nL 135.453615 211.858103 \r\nL 138.245942 212.091288 \r\nL 141.038269 212.303846 \r\nL 143.830596 212.491943 \r\nL 146.622923 212.692681 \r\nL 149.41525 212.864559 \r\nL 152.207577 212.99657 \r\nL 154.999904 213.166729 \r\nL 157.792231 213.304754 \r\nL 160.584557 213.453369 \r\nL 163.376884 213.615141 \r\nL 166.169211 213.7427 \r\nL 168.961538 213.861277 \r\nL 171.753865 213.992382 \r\nL 174.546192 214.099296 \r\nL 177.338519 214.178898 \r\nL 180.130846 214.215559 \r\nL 182.923173 214.24597 \r\nL 185.7155 214.272154 \r\nL 188.507827 214.305582 \r\nL 191.300154 214.346752 \r\nL 194.092481 214.391384 \r\nL 196.884808 214.425855 \r\nL 199.677135 214.458596 \r\nL 202.469462 214.461752 \r\nL 205.261788 214.498662 \r\nL 208.054115 214.530199 \r\nL 210.846442 214.540789 \r\nL 213.638769 214.564887 \r\nL 216.431096 214.592029 \r\nL 219.223423 214.624575 \r\nL 222.01575 214.63828 \r\nL 224.808077 214.656308 \r\nL 227.600404 214.678577 \r\nL 230.392731 214.696669 \r\nL 233.185058 214.70475 \r\nL 235.977385 214.718037 \r\nL 238.769712 214.734863 \r\nL 241.562039 214.743982 \r\nL 244.354366 214.751379 \r\nL 247.146693 214.722819 \r\nL 249.939019 214.720796 \r\nL 252.731346 214.727433 \r\nL 255.523673 214.731966 \r\nL 258.316 214.738003 \r\nL 261.108327 214.740556 \r\nL 263.900654 214.736952 \r\nL 266.692981 214.735839 \r\nL 269.485308 214.744123 \r\nL 272.277635 214.736427 \r\nL 275.069962 214.732059 \r\nL 277.862289 214.728732 \r\nL 280.654616 214.720694 \r\nL 283.446943 214.725589 \r\nL 286.23927 214.725657 \r\nL 289.031597 214.72569 \r\nL 291.823924 214.725452 \r\nL 294.616251 214.717528 \r\nL 297.408577 214.754224 \r\nL 300.200904 214.715824 \r\nL 302.993231 214.749968 \r\nL 305.785558 214.749017 \r\nL 308.577885 214.756364 \r\nL 311.370212 214.751661 \r\nL 314.162539 214.751791 \r\nL 316.954866 214.750866 \r\nL 319.747193 214.743536 \r\nL 322.53952 214.741797 \r\nL 325.331847 214.743046 \r\nL 328.124174 214.746604 \r\nL 330.916501 214.747196 \r\nL 333.708828 214.749049 \r\nL 336.501155 214.743142 \r\nL 339.293482 214.749166 \r\nL 342.085808 214.745652 \r\nL 344.878135 214.743591 \r\nL 347.670462 214.734048 \r\nL 350.462789 214.731554 \r\nL 353.255116 214.730782 \r\nL 356.047443 214.730635 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p3def8450b6\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "   85.24 546.1   14.2   92.94 621.2 ]]\nOutputs (missing):  [[ 12.42  80.6  486.26  14.11  90.01 624.88]]\nInput (missing):  [[ 11.3   73.93 389.4   12.58  87.16 185.2 ]]\nTarget (missing):  [[ 11.3   73.93 389.4   12.58  87.16 472.9 ]]\nOutputs (missing):  [[ 11.71  74.92 404.72  12.81  84.58 487.86]]\nInput (missing):  [[  6.98  43.79 143.5   13.37  50.41 185.2 ]]\nTarget (missing):  [[ 12.56  81.92 485.8   13.37  89.02 547.4 ]]\nOutputs (missing):  [[ 10.14  65.23 286.49  11.2   69.83 282.41]]\nInput (missing):  [[  6.98  94.25 648.2   16.21 108.4  185.2 ]]\nTarget (missing):  [[ 14.48  94.25 648.2   16.21 108.4  808.9 ]]\nOutputs (missing):  [[ 13.41  87.17 597.56  15.42 101.59 781.06]]\nInput (missing):  [[ 11.32  43.79 395.7    7.93  79.82 452.3 ]]\nTarget (missing):  [[ 11.32  71.76 395.7   12.08  79.82 452.3 ]]\nOutputs (missing):  [[ 10.68  67.94 307.94  11.5   74.58 333.76]]\nInput:  [[ 15.61 100.   758.6   17.91 115.9  988.6 ]]\nTarget:  [[ 15.61 100.   758.6   17.91 115.9  988.6 ]]\nOutputs:  [[  15.66  101.83  775.99   17.97  121.79 1088.07]]\nInput (missing):  [[  21.16  137.2  1404.      7.93  188.   2615.  ]]\nTarget (missing):  [[  21.16  137.2  1404.     29.17  188.   2615.  ]]\nOutputs (missing):  [[  22.14  146.4  1425.6    26.96  183.63 2133.76]]\nInput (missing):  [[ 16.17 106.3  143.5   16.97 113.1  861.5 ]]\nTarget (missing):  [[ 16.17 106.3  788.5   16.97 113.1  861.5 ]]\nOutputs (missing):  [[  15.02   97.88  731.6    17.45  115.13 1021.93]]\nInput (missing):  [[ 14.05  91.38 143.5   15.3  100.2  706.7 ]]\nTarget (missing):  [[ 14.05  91.38 600.4   15.3  100.2  706.7 ]]\nOutputs (missing):  [[ 13.65  88.48 597.1   15.56 102.35 803.72]]\nInput:  [[ 12.83  82.89 506.9   14.09  93.22 605.8 ]]\nTarget:  [[ 12.83  82.89 506.9   14.09  93.22 605.8 ]]\nOutputs:  [[ 13.08  84.27 532.26  14.6   97.36 694.93]]\nInput:  [[  8.89  58.79 244.     9.73  62.56 284.4 ]]\nTarget:  [[  8.89  58.79 244.     9.73  62.56 284.4 ]]\nOutputs:  [[ 10.09  64.17 253.07  10.79  68.57 249.19]]\nInput (missing):  [[  6.98  60.21 143.5   10.51  50.41 185.2 ]]\nTarget (missing):  [[  9.57  60.21 279.6   10.51  65.74 335.9 ]]\nOutputs (missing):  [[  9.64  61.68 236.05  10.49  65.14 203.94]]\nInput (missing): [[ 12.47  80.45 480.1    7.93  92.82 607.3 ]]\nTarget (missing):  [[ 12.47  80.45 480.1   14.06  92.82 607.3 ]]\nOutputs (missing):  [[ 12.79  82.49 518.4   14.42  94.61 673.13]]\nInput (missing):  [[ 13.    43.79 143.5    7.93  90.82 616.7 ]]\nTarget (missing):  [[ 13.    83.51 519.4   14.16  90.82 616.7 ]]\nOutputs (missing):  [[ 11.5   73.93 400.74  12.86  81.85 488.57]]\nInput (missing):  [[ 14.99  95.54 698.8    7.93  95.54 698.8 ]]\nTarget (missing):  [[ 14.99  95.54 698.8   14.99  95.54 698.8 ]]\nOutputs (missing):  [[ 14.48  94.3  687.31  16.82 110.19 949.75]]\nInput (missing):  [[ 10.65  68.01 143.5   12.25  77.98 455.7 ]]\nTarget (missing):  [[ 10.65  68.01 347.    12.25  77.98 455.7 ]]\nOutputs (missing):  [[ 11.35  72.61 370.51  12.39  80.69 436.5 ]]\nInput (missing):  [[  6.98  92.51 641.2   16.77 110.4  873.2 ]]\nTarget (missing):  [[ 14.34  92.51 641.2   16.77 110.4  873.2 ]]\nOutputs (missing):  [[ 14.37  94.09 702.93  16.84 111.22 938.93]]\nInput:  [[ 11.14  71.24 384.6   12.12  79.62 453.5 ]]\nTarget:  [[ 11.14  71.24 384.6   12.12  79.62 453.5 ]]\nOutputs:  [[ 11.72  75.1  404.89  12.86  84.29 491.31]]\nInput:  [[  18.08  117.4  1024.     19.76  129.1  1228.  ]]\nTarget:  [[  18.08  117.4  1024.     19.76  129.1  1228.  ]]\nOutputs:  [[  17.56  114.71  955.79   20.47  139.69 1378.02]]\nInput (missing):  [[   6.98  140.9  1546.     30.75  199.5  3143.  ]]\nTarget (missing):  [[  21.71  140.9  1546.     30.75  199.5  3143.  ]]\nOutputs (missing):  [[  24.36  163.72 1729.29   30.71  209.72 2524.32]]\nInput:  [[  8.22  53.27 203.9    9.09  58.08 249.8 ]]\nTarget:  [[  8.22  53.27 203.9    9.09  58.08 249.8 ]]\nOutputs:  [[  9.64  61.11 210.69  10.21  64.21 181.19]]\nInput (missing):  [[   6.98   43.79 1264.     24.22  156.1  1750.  ]]\nTarget (missing):  [[  20.26  132.4  1264.     24.22  156.1  1750.  ]]\nOutputs (missing):  [[  18.43  121.58 1074.37   22.02  149.15 1542.03]]\nInput (missing):  [[  6.98  76.53 143.5   13.67  87.54 583.  ]]\nTarget (missing):  [[ 11.93  76.53 438.6   13.67  87.54 583.  ]]\nOutputs (missing):  [[ 11.97  77.51 462.18  13.57  87.75 562.61]]\nInput (missing):  [[  6.98 111.   933.1    7.93  50.41 185.2 ]]\nTarget (missing):  [[  17.35  111.    933.1    19.85  128.2  1218.  ]]\nOutputs (missing):  [[  14.58   97.28  814.62   18.03  117.23 1051.79]]\nInput (missing):  [[ 10.57  66.82 143.5   10.94  50.41 185.2 ]]\nTarget (missing):  [[ 10.57  66.82 340.9   10.94  69.35 366.3 ]]\nOutputs (missing):  [[ 10.1   64.36 258.33  10.86  68.76 253.71]]\nInput (missing):  [[ 10.16  64.73 311.7    7.93  67.88 347.3 ]]\nTarget (missing):  [[ 10.16  64.73 311.7   10.65  67.88 347.3 ]]\nOutputs (missing):  [[ 10.71  68.29 313.26  11.58  74.85 342.94]]\nInput (missing):  [[   6.98  101.7   748.9    19.26  124.9  1156.  ]]\nTarget (missing):  [[  15.46  101.7   748.9    19.26  124.9  1156.  ]]\nOutputs (missing):  [[  15.89  104.68  859.5    18.95  126.24 1180.61]]\nInput (missing):  [[  8.73  55.27 143.5    7.93  64.01 317.  ]]\nTarget (missing):  [[  8.73  55.27 234.3   10.17  64.01 317.  ]]\nOutputs (missing):  [[  9.66  61.16 212.98  10.2   64.79 182.23]]\nInput (missing):  [[ 11.84  77.93 143.5   16.82 119.4  888.7 ]]\nTarget (missing):  [[ 11.84  77.93 440.6   16.82 119.4  888.7 ]]\nOutputs (missing):  [[ 14.4   93.47 666.54  16.5  109.62 913.77]]\nInput (missing):  [[ 11.46  43.79 403.1   12.68  82.69 489.8 ]]\nTarget (missing):  [[ 11.46  73.59 403.1   12.68  82.69 489.8 ]]\nOutputs (missing):  [[ 11.97  76.99 431.88  13.28  86.28 538.56]]\nInput (missing):  [[ 13.65  87.88 568.9   15.34  99.71 185.2 ]]\nTarget (missing):  [[ 13.65  87.88 568.9   15.34  99.71 706.2 ]]\nOutputs (missing):  [[ 13.18  84.96 545.44  14.77  98.46 715.22]]\nInput (missing):  [[ 12.2   78.01 457.9    7.93  50.41 583.1 ]]\nTarget (missing):  [[ 12.2   78.01 457.9   13.75  91.11 583.1 ]]\nOutputs (missing):  [[ 12.06  78.21 470.3   13.7   88.4  578.09]]\nInput:  [[ 14.25  96.42 645.7   17.67 119.1  959.5 ]]\nTarget:  [[ 14.25  96.42 645.7   17.67 119.1  959.5 ]]\nOutputs:  [[  15.36   99.74  747.67   17.56  119.07 1041.13]]\nInput (missing):  [[ 11.71  43.79 143.5   13.06  84.16 185.2 ]]\nTarget (missing):  [[ 11.71  75.03 420.3   13.06  84.16 516.4 ]]\nOutputs (missing):  [[ 11.53  74.18 398.37  12.85  81.93 486.58]]\nInput:  [[ 12.68  82.69 499.    17.09 111.8  888.3 ]]\nTarget:  [[ 12.68  82.69 499.    17.09 111.8  888.3 ]]\nOutputs:  [[ 14.51  93.99 666.94  16.47 110.77 912.67]]\nInput (missing):  [[ 13.62  87.19 143.5   15.35  97.58 185.2 ]]\nTarget (missing):  [[ 13.62  87.19 573.2   15.35  97.58 729.8 ]]\nOutputs (missing):  [[ 12.69  81.84 505.65  14.27  93.44 654.56]]\nInput (missing):  [[ 11.42  77.58 386.1   14.91  98.87 185.2 ]]\nTarget (missing):  [[ 11.42  77.58 386.1   14.91  98.87 567.7 ]]\nOutputs (missing):  [[ 12.52  80.42 481.61  13.87  92.24 611.64]]\nInput:  [[ 11.93  76.14 442.7   13.8   87.64 589.5 ]]\nTarget:  [[ 11.93  76.14 442.7   13.8   87.64 589.5 ]]\nOutputs:  [[ 12.62  81.23 489.26  14.03  92.81 627.38]]\nInput:  [[ 12.77  81.35 507.9   13.87  88.1  594.7 ]]\nTarget:  [[ 12.77  81.35 507.9   13.87  88.1  594.7 ]]\nOutputs:  [[ 12.87  82.84 511.61  14.32  95.19 662.71]]\nInput (missing):  [[ 10.49  66.86 143.5    7.93  70.76 375.4 ]]\nTarget (missing):  [[ 10.49  66.86 334.3   11.06  70.76 375.4 ]]\nOutputs (missing):  [[ 10.55  67.19 299.77  11.4   73.28 321.32]]\nInput (missing):  [[ 24.25 166.2  143.5   26.02 180.9  185.2 ]]\nTarget (missing):  [[  24.25  166.2  1761.     26.02  180.9  2073.  ]]\nOutputs (missing):  [[  19.14  126.13 1144.16   23.15  154.56 1685.28]]\nInput (missing):  [[ 14.95  43.79 689.5   16.25 107.1  809.7 ]]\nTarget (missing):  [[ 14.95  97.84 689.5   16.25 107.1  809.7 ]]\nOutputs (missing):  [[ 14.81  96.59 709.05  17.2  112.62 990.47]]\nInput (missing):  [[ 13.    87.5  519.8   15.49  50.41 739.3 ]]\nTarget (missing):  [[ 13.    87.5  519.8   15.49 106.2  739.3 ]]\nOutputs (missing):  [[ 13.24  86.63 595.2   15.39 100.07 764.74]]\nInput (missing):  [[  17.42  114.5   143.5    18.07  120.4  1021.  ]]\nTarget (missing):  [[  17.42  114.5   948.     18.07  120.4  1021.  ]]\nOutputs (missing):  [[  15.98  104.55  826.66   18.79  124.09 1176.78]]\nInput:  [[ 14.2   92.41 618.4   16.45 112.1  828.5 ]]\nTarget:  [[ 14.2   92.41 618.4   16.45 112.1  828.5 ]]\nOutputs:  [[ 14.7   95.27 686.26  16.72 112.78 942.55]]\nInput (missing):  [[  6.98  73.7  143.5   13.28  50.41 542.5 ]]\nTarget (missing):  [[ 11.66  73.7  421.    13.28  83.61 542.5 ]]\nOutputs (missing):  [[ 10.94  71.2  389.31  12.52  78.65 427.26]]\nInput (missing):  [[  17.47  116.1   984.6    23.14   50.41 1660.  ]]\nTarget (missing):  [[  17.47  116.1   984.6    23.14  155.3  1660.  ]]\nOutputs (missing):  [[  18.12  121.28 1116.29   22.45  148.45 1560.99]]\nInput (missing):  [[  20.94  138.9   143.5    25.58  165.3  2010.  ]]\nTarget (missing):  [[  20.94  138.9  1364.     25.58  165.3  2010.  ]]\nOutputs (missing):  [[  21.39  142.   1359.82   26.27  174.72 2039.99]]\nInput:  [[  16.13  108.1   798.8    20.96  136.8  1315.  ]]\nTarget:  [[  16.13  108.1   798.8    20.96  136.8  1315.  ]]\nOutputs:  [[  17.45  114.01  945.64   20.32  138.76 1361.31]]\nInput (missing):  [[ 13.7   87.76 143.5   14.96  95.78 686.5 ]]\nTarget (missing):  [[ 13.7   87.76 571.1   14.96  95.78 686.5 ]]\nOutputs (missing):  [[ 13.38  86.65 570.79  15.2   99.74 761.73]]\nInput (missing):  [[  6.98  96.03 651.     7.93 101.7  767.3 ]]\nTarget (missing):  [[ 14.41  96.03 651.    15.77 101.7  767.3 ]]\nOutputs (missing):  [[ 14.08  92.13 687.96  16.54 109.36 907.04]]\nInput (missing):  [[ 15.71 102.   143.5    7.93 114.3  922.8 ]]\nTarget (missing):  [[ 15.71 102.   761.7   17.5  114.3  922.8 ]]\nOutputs (missing):  [[ 14.12  91.87 659.61  16.41 107.11 903.07]]\nInput (missing):  [[ 16.14 104.3  800.    17.71  50.41 947.9 ]]\nTarget (missing):  [[ 16.14 104.3  800.    17.71 115.9  947.9 ]]\nOutputs (missing):  [[  15.37  101.46  811.94   18.33  121.01 1100.52]]\nInput (missing):  [[ 10.51  43.79 334.2    7.93  50.41 362.7 ]]\nTarget (missing):  [[ 10.51  66.85 334.2   10.93  70.1  362.7 ]]\nOutputs (missing):  [[  9.79  62.   221.66  10.34  65.83 197.31]]\nInput:  [[  19.45  126.5  1169.     25.7   163.1  1972.  ]]\nTarget:  [[  19.45  126.5  1169.     25.7   163.1  1972.  ]]\nOutputs:  [[  21.16  139.38 1301.69   25.26  173.79 1933.49]]\nInput:  [[  16.65  110.    904.6    26.46  177.   2215.  ]]\nTarget:  [[  16.65  110.    904.6    26.46  177.   2215.  ]]\nOutputs:  [[  21.64  143.01 1366.01   26.1   179.06 2025.52]]\nInput (missing):  [[  6.98  86.49 143.5   15.53  50.41 185.2 ]]\nTarget (missing):  [[ 13.34  86.49 520.    15.53  96.66 614.9 ]]\nOutputs (missing):  [[ 11.22  73.36 428.05  13.01  81.87 481.16]]\nInput:  [[ 13.01  82.01 526.4   14.    88.18 608.8 ]]\nTarget:  [[ 13.01  82.01 526.4   14.    88.18 608.8 ]]\nOutputs:  [[ 12.96  83.47 520.13  14.44  96.08 676.44]]\nInput (missing):  [[ 11.8   78.99 143.5   13.74  91.93 591.7 ]]\nTarget (missing):  [[ 11.8   78.99 432.    13.74  91.93 591.7 ]]\nOutputs (missing):  [[ 12.45  80.09 476.69  13.85  91.21 606.91]]\nInput:  [[ 12.54  81.25 476.3   13.57  86.67 552.  ]]\nTarget:  [[ 12.54  81.25 476.3   13.57  86.67 552.  ]]\nOutputs:  [[ 12.66  81.44 492.66  14.06  93.25 632.11]]\nInput (missing):  [[ 11.22  43.79 386.8   12.36  78.44 470.9 ]]\nTarget (missing):  [[ 11.22  70.79 386.8   12.36  78.44 470.9 ]]\nOutputs (missing):  [[ 11.71  75.2  406.26  12.93  83.8  497.29]]\nInput (missing):  [[ 10.75  68.26 355.3   11.95  50.41 185.2 ]]\nTarget (missing):  [[ 10.75  68.26 355.3   11.95  77.79 441.2 ]]\nOutputs (missing):  [[ 10.72  68.76 323.84  11.74  74.93 353.64]]\nInput (missing):  [[ 12.99  84.08 143.5   13.72  87.38 576.  ]]\nTarget (missing):  [[ 12.99  84.08 514.3   13.72  87.38 576.  ]]\nOutputs (missing):  [[ 12.55  80.86 488.36  14.04  91.92 627.64]]\nInput (missing):  [[  6.98  98.22 656.1   16.46  50.41 809.2 ]]\nTarget (missing):  [[ 14.69  98.22 656.1   16.46 114.1  809.2 ]]\nOutputs (missing):  [[ 13.93  92.84 732.33  17.05 109.59 933.67]]\nInput (missing):  [[  6.98  84.1  537.9    7.93  50.41 632.9 ]]\nTarget (missing):  [[ 13.21  84.1  537.9   14.35  91.29 632.9 ]]\nOutputs (missing):  [[ 12.51  82.38 570.38  14.87  95.28 694.89]]\nInput (missing):  [[ 11.04  70.92 373.2    7.93  79.93 471.4 ]]\nTarget (missing):  [[ 11.04  70.92 373.2   12.41  79.93 471.4 ]]\nOutputs (missing):  [[ 11.57  74.13 397.68  12.74  83.06 478.33]]\nInput (missing):  [[ 16.3  104.7  143.5   17.32 109.8  928.2 ]]\nTarget (missing):  [[ 16.3  104.7  819.8   17.32 109.8  928.2 ]]\nOutputs (missing):  [[  15.21   99.27  750.86   17.74  116.69 1055.07]]\nInput (missing):  [[ 13.64  43.79 575.3   14.85  94.11 683.4 ]]\nTarget (missing):  [[ 13.64  87.38 575.3   14.85  94.11 683.4 ]]\nOutputs (missing):  [[ 13.64  88.53 594.71  15.6  101.63 804.92]]\nInput (missing):  [[  15.75   43.79  761.3    19.56  125.9  1088.  ]]\nTarget (missing):  [[  15.75  102.6   761.3    19.56  125.9  1088.  ]]\nOutputs (missing):  [[  16.77  110.1   899.28   19.88  130.87 1300.04]]\nInput (missing): [[  18.81  120.9  1102.      7.93  129.    185.2 ]]\nTarget (missing):  [[  18.81  120.9  1102.     19.96  129.   1236.  ]]\nOutputs (missing):  [[  17.11  112.55  959.64   20.6   135.35 1388.82]]\nInput (missing):  [[ 14.92  96.45 686.9   17.18  50.41 906.6 ]]\nTarget (missing):  [[ 14.92  96.45 686.9   17.18 112.   906.6 ]]\nOutputs (missing):  [[ 14.58  95.99 731.8   17.25 113.19 976.94]]\nInput (missing):  [[  20.13  131.2  1261.      7.93  155.   1731.  ]]\nTarget (missing):  [[  20.13  131.2  1261.     23.69  155.   1731.  ]]\nOutputs (missing):  [[  20.05  132.4  1230.37   24.32  163.33 1823.55]]\nInput (missing):  [[ 13.66  89.46 575.3   15.14 101.4  185.2 ]]\nTarget (missing):  [[ 13.66  89.46 575.3   15.14 101.4  708.8 ]]\nOutputs (missing):  [[ 13.22  85.23 549.94  14.82  98.93 721.91]]\nInput (missing):  [[  6.98  59.6  271.2    7.93  68.73 359.4 ]]\nTarget (missing):  [[  9.4   59.6  271.2   10.85  68.73 359.4 ]]\nOutputs (missing):  [[ 10.21  65.12 275.91  11.06  70.2  278.47]]\nInput:  [[  19.4   127.2  1145.     23.79  152.4  1628.  ]]\nTarget:  [[  19.4   127.2  1145.     23.79  152.4  1628.  ]]\nOutputs:  [[  19.74  129.52 1160.27   23.29  160.35 1707.48]]\nInput:  [[ 12.58  79.83 489.    13.5   85.56 564.1 ]]\nTarget:  [[ 12.58  79.83 489.    13.5   85.56 564.1 ]]\nOutputs:  [[ 12.63  81.26 489.62  14.02  92.95 627.44]]\nInput (missing):  [[ 13.8   90.43 584.1   16.57  50.41 812.4 ]]\nTarget (missing):  [[ 13.8   90.43 584.1   16.57 110.3  812.4 ]]\nOutputs (missing):  [[ 13.79  90.5  651.25  16.16 105.43 852.41]]\nInput (missing):  [[  20.59  137.8  1320.      7.93  163.2  1760.  ]]\nTarget (missing):  [[  20.59  137.8  1320.     23.86  163.2  1760.  ]]\nOutputs (missing):  [[  20.74  137.08 1298.48   25.26  169.86 1932.93]]\nInput (missing):  [[  6.98  73.38 143.5   12.04  79.73 450.  ]]\nTarget (missing):  [[ 11.27  73.38 392.    12.04  79.73 450.  ]]\nOutputs (missing):  [[ 11.21  72.24 384.43  12.52  80.29 442.62]]\nInput:  [[  20.58  134.7  1290.     23.24  158.3  1656.  ]]\nTarget:  [[  20.58  134.7  1290.     23.24  158.3  1656.  ]]\nOutputs:  [[  20.17  132.41 1202.19   23.85  164.68 1773.33]]\nInput (missing):  [[ 11.89  76.39 433.8    7.93  85.09 522.9 ]]\nTarget (missing):  [[ 11.89  76.39 433.8   13.05  85.09 522.9 ]]\nOutputs (missing):  [[ 12.21  78.56 461.74  13.64  89.09 582.21]]\nInput (missing):  [[ 14.02  89.59 143.5   14.91  96.53 185.2 ]]\nTarget (missing):  [[ 14.02  89.59 606.5   14.91  96.53 688.9 ]]\nOutputs (missing):  [[ 12.65  81.62 503.28  14.24  93.1  650.82]]\nInput (missing):  [[ 12.25  78.18 466.5   14.17  92.74 185.2 ]]\nTarget (missing):  [[ 12.25  78.18 466.5   14.17  92.74 622.9 ]]\nOutputs (missing):  [[ 12.4   79.6  469.7   13.72  90.99 593.23]]\nInput (missing):  [[ 15.75 107.1  758.6   17.36  50.41 915.3 ]]\nTarget (missing):  [[ 15.75 107.1  758.6   17.36 119.4  915.3 ]]\nOutputs (missing):  [[  15.28  100.93  807.77   18.25  120.43 1090.42]]\nInput:  [[  16.69  107.1   857.6    19.18  127.3  1084.  ]]\nTarget:  [[  16.69  107.1   857.6    19.18  127.3  1084.  ]]\nOutputs:  [[  16.64  108.48  869.62   19.26  131.13 1238.47]]\nInput (missing):  [[ 12.9   83.74 512.2   14.48  97.17 185.2 ]]\nTarget (missing):  [[ 12.9   83.74 512.2   14.48  97.17 643.8 ]]\nOutputs (missing):  [[ 12.76  82.09 505.5   14.21  94.52 650.45]]\nInput (missing):  [[   6.98  109.3   886.3     7.93  130.7  1260.  ]]\nTarget (missing):  [[  16.78  109.3   886.3    20.05  130.7  1260.  ]]\nOutputs (missing):  [[  16.28  107.05  902.85   19.45  130.74 1246.52]]\nInput:  [[  18.45  120.2  1075.     22.52  145.6  1590.  ]]\nTarget:  [[  18.45  120.2  1075.     22.52  145.6  1590.  ]]\nOutputs:  [[  19.03  124.71 1093.12   22.37  153.63 1599.36]]\nInput (missing):  [[  16.5   106.6   838.1     7.93  117.2  1009.  ]]\nTarget (missing):  [[  16.5   106.6   838.1    18.13  117.2  1009.  ]]\nOutputs (missing):  [[  16.15  105.73  851.19   19.07  126.27 1212.63]]\nInput (missing):  [[  6.98  89.75 609.1    7.93  50.41 185.2 ]]\nTarget (missing):  [[ 14.06  89.75 609.1   14.92  96.42 684.5 ]]\nOutputs (missing):  [[ 12.5   82.29 571.89  14.86  95.4  695.9 ]]\nInput (missing):  [[ 11.34  43.79 391.2   12.47  79.15 185.2 ]]\nTarget (missing):  [[ 11.34  72.76 391.2   12.47  79.15 478.6 ]]\nOutputs (missing):  [[ 11.22  71.78 358.79  12.25  79.36 419.07]]\nInput (missing):  [[  27.22   43.79 2250.     33.12  220.8  3216.  ]]\nTarget (missing):  [[  27.22  182.1  2250.     33.12  220.8  3216.  ]]\nOutputs (missing):  [[  29.02  194.3  2077.08   36.42  245.18 3214.86]]\nInput (missing):  [[ 17.14  43.79 912.7   22.25 152.4  185.2 ]]\nTarget (missing):  [[  17.14  116.    912.7    22.25  152.4  1461.  ]]\nOutputs (missing):  [[  16.56  108.32  877.61   19.48  129.68 1258.29]]\nInput (missing):  [[  6.98  43.79 443.3   13.67  87.78 567.9 ]]\nTarget (missing):  [[ 12.    76.95 443.3   13.67  87.78 567.9 ]]\nOutputs (missing):  [[ 11.79  75.87 420.56  13.08  84.95 512.39]]\nInput (missing):  [[  9.76  61.68 290.9   10.67  50.41 185.2 ]]\nTarget (missing):  [[  9.76  61.68 290.9   10.67  68.03 349.9 ]]\nOutputs (missing):  [[ 10.13  64.63 263.83  10.93  69.12 260.73]]\nInput (missing):  [[ 15.73 102.8  143.5   17.01 112.5  185.2 ]]\nTarget (missing):  [[ 15.73 102.8  747.2   17.01 112.5  854.3 ]]\nOutputs (missing):  [[ 13.84  89.75 620.19  15.86 104.35 839.38]]\nInput (missing):  [[ 11.71  74.68 420.3    7.93  84.42 521.5 ]]\nTarget (missing):  [[ 11.71  74.68 420.3   13.01  84.42 521.5 ]]\nOutputs (missing):  [[ 12.06  77.5  446.38  13.42  87.68 557.16]]\nInput (missing):  [[ 14.58  97.41 644.8   17.62 122.4  185.2 ]]\nTarget (missing):  [[ 14.58  97.41 644.8   17.62 122.4  896.9 ]]\nOutputs (missing):  [[ 14.53  94.12 676.49  16.56 111.5  924.6 ]]\nInput: [[  9.29  59.96 257.8   10.57  67.84 326.6 ]]\nTarget:  [[  9.29  59.96 257.8   10.57  67.84 326.6 ]]\nOutputs:  [[ 10.51  66.97 291.8   11.32  72.58 311.06]]\nInput:  [[  16.02  102.7   797.8    19.19  123.8  1150.  ]]\nTarget:  [[  16.02  102.7   797.8    19.19  123.8  1150.  ]]\nOutputs:  [[  16.44  107.11  848.8    18.98  129.11 1205.57]]\nInput (missing):  [[  20.18   43.79 1245.     23.37  170.3  1623.  ]]\nTarget (missing):  [[  20.18  143.7  1245.     23.37  170.3  1623.  ]]\nOutputs (missing):  [[  20.73  137.22 1282.6    25.22  168.17 1920.41]]\nInput (missing):  [[  9.33  59.01 264.     7.93  62.86 295.8 ]]\nTarget (missing):  [[  9.33  59.01 264.     9.85  62.86 295.8 ]]\nOutputs (missing):  [[ 10.12  64.3  256.66  10.81  69.1  252.94]]\nInput (missing):  [[   6.98   43.79 1033.     20.6   135.1   185.2 ]]\nTarget (missing):  [[  18.22  120.3  1033.     20.6   135.1  1321.  ]]\nOutputs (missing):  [[ 14.47  93.73 663.47  16.41 110.52 906.61]]\nInput:  [[ 11.61  75.46 408.2   12.64  81.93 475.7 ]]\nTarget:  [[ 11.61  75.46 408.2   12.64  81.93 475.7 ]]\nOutputs:  [[ 12.03  77.19 433.95  13.26  87.24 537.92]]\nTest Loss: 0.005\n"
    }
   ],
   "source": [
    "# TEST THE NEURAL NETWORK\n",
    "test_result = test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './model3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following section is for reconstructing a brand new dataset from an input dataset that has missing values.\n",
    "# This new dataset can be used in some classifiers to see if the accuracy changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Autoencoder(\n  (enc1): Linear(in_features=6, out_features=8, bias=True)\n  (enc2): Linear(in_features=8, out_features=16, bias=True)\n  (dec2): Linear(in_features=16, out_features=8, bias=True)\n  (dec3): Linear(in_features=8, out_features=6, bias=True)\n)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = torch.load('model3')\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  12.0811,   77.681 ,  454.0099,   13.5096,   88.0846,  568.2144],\n       [  12.105 ,   78.5602,  471.5327,   13.732 ,   88.7148,  578.05  ],\n       [  11.0223,   70.3257,  338.9987,   11.9366,   77.7326,  384.5267],\n       [  11.6356,   75.0923,  425.4366,   13.072 ,   84.4054,  507.8375],\n       [  13.0098,   83.8226,  525.4422,   14.5173,   96.5448,  685.0456],\n       [  14.3698,   96.0113,  779.0604,   17.6984,  113.8315, 1004.1799],\n       [  11.9739,   77.4265,  459.0898,   13.5299,   87.6998,  560.4745],\n       [  25.2864,  169.5629, 1787.0174,   31.6979,  216.5094, 2646.7687],\n       [  16.0533,  104.9548,  829.031 ,   18.8009,  124.8826, 1179.3611],\n       [  13.7488,   90.2515,  652.556 ,   16.2752,  104.215 ,  871.6704],\n       [  10.5882,   67.9042,  318.0032,   11.6347,   73.9578,  341.062 ],\n       [  11.3913,   72.8765,  375.3387,   12.4472,   81.1848,  443.5127],\n       [  13.5383,   88.2401,  599.4205,   15.7371,  100.2126,  817.3313],\n       [  11.0318,   70.9149,  363.005 ,   12.2337,   78.3915,  411.4377],\n       [  15.3125,  100.0327,  757.7974,   17.8768,  117.3519, 1069.2893],\n       [  21.28  ,  140.0557, 1312.1845,   25.3822,  175.1667, 1950.902 ],\n       [  11.8654,   76.207 ,  420.5681,   13.1148,   85.3351,  519.4739],\n       [  14.7621,   95.7014,  690.5595,   16.7916,  113.2348,  950.3367],\n       [  12.8074,   82.7166,  521.0974,   14.4774,   94.6041,  679.283 ],\n       [  13.4207,   87.7967,  608.583 ,   15.5864,  101.7048,  788.7664],\n       [  11.8226,   76.5559,  445.1171,   13.4114,   85.6053,  545.9964],\n       [  11.9821,   76.8547,  429.4046,   13.19  ,   86.8034,  530.3723],\n       [  12.7087,   81.7274,  499.3692,   14.1299,   93.951 ,  641.0198],\n       [  12.4112,   79.9568,  481.2828,   13.9148,   90.9245,  614.327 ],\n       [  12.4058,   79.7299,  469.1586,   13.7394,   90.8221,  594.3849],\n       [  13.7299,   88.654 ,  598.8806,   15.489 ,  103.8234,  799.941 ],\n       [  12.0839,   77.551 ,  438.6314,   13.3212,   87.7341,  545.5122],\n       [  10.861 ,   69.3392,  324.3947,   11.77  ,   75.9059,  363.5249],\n       [  14.2674,   93.2966,  659.4738,   16.6491,  106.3201,  920.7087],\n       [  10.9068,   69.6234,  327.121 ,   11.81  ,   76.3125,  368.1827],\n       [  13.7288,   88.6672,  593.1891,   15.4407,  103.4774,  793.2002],\n       [  10.677 ,   68.0453,  307.7302,   11.5206,   74.3342,  335.2484],\n       [  12.5187,   80.8078,  488.7552,   14.0225,   91.893 ,  622.1843],\n       [  12.357 ,   79.4002,  464.0794,   13.6724,   90.3261,  586.4669],\n       [  11.4403,   73.7666,  403.9956,   12.7958,   82.3434,  475.2611],\n       [  12.6436,   81.3355,  490.9969,   14.0409,   93.0746,  629.5565],\n       [  17.1568,  113.6134,  999.9399,   20.8038,  139.2606, 1390.936 ],\n       [  12.2576,   79.52  ,  491.4131,   13.9658,   90.5522,  608.1544],\n       [  14.5541,   95.0152,  721.9873,   17.0218,  113.5447,  969.6251],\n       [  13.2315,   85.2857,  546.1987,   14.7903,   98.7663,  717.4763],\n       [  11.4686,   73.3969,  385.8539,   12.578 ,   82.087 ,  459.2665],\n       [  11.9003,   76.7689,  436.796 ,   13.4042,   85.3011,  549.6936],\n       [  14.6112,   94.6602,  677.325 ,   16.6   ,  111.893 ,  928.3807],\n       [  11.4002,   72.8293,  374.3238,   12.4042,   81.4904,  439.9371],\n       [  15.1515,   99.5663,  785.3453,   17.9435,  118.9973, 1064.8016],\n       [  24.1905,  160.2832, 1601.7782,   29.3715,  203.0904, 2407.3567],\n       [  15.6776,  102.0105,  781.4633,   18.0603,  121.8719, 1097.5112],\n       [  13.9549,   90.2075,  615.0559,   15.7425,  105.6349,  828.3509],\n       [  12.6296,   82.2233,  525.7304,   14.4621,   93.9138,  661.3583],\n       [  10.0941,   64.1666,  253.0654,   10.7919,   68.5735,  249.1875],\n       [  10.356 ,   65.8595,  274.0778,   11.0724,   71.1073,  282.492 ],\n       [  11.4029,   73.2104,  389.9718,   12.6928,   81.129 ,  469.7082],\n       [  12.6494,   81.6898,  511.4927,   14.3375,   93.2334,  663.1362],\n       [  14.3894,   93.3092,  659.3045,   16.3903,  109.4803,  902.2116],\n       [  11.3497,   72.611 ,  370.511 ,   12.3905,   80.6927,  436.5033],\n       [  14.1684,   93.1286,  689.3819,   16.6813,  109.1222,  911.787 ],\n       [  11.7222,   75.105 ,  404.8947,   12.8568,   84.2898,  491.3126],\n       [  16.5286,  107.8379,  868.9918,   19.2581,  130.1479, 1237.3653],\n       [  26.0398,  173.1538, 1791.6319,   31.9314,  221.3785, 2699.9746],\n       [   9.6391,   61.1103,  210.6901,   10.2129,   64.2056,  181.1938],\n       [  20.3276,  133.5026, 1214.9639,   24.046 ,  165.9867, 1795.2489],\n       [  11.1749,   71.3347,  356.3999,   12.1649,   79.3496,  411.6282],\n       [  17.1536,  111.9545,  916.4593,   19.9195,  135.8901, 1314.5011],\n       [  10.7814,   68.7198,  316.6025,   11.6357,   75.3735,  349.1008],\n       [  10.7475,   68.5463,  313.5062,   11.6127,   74.8858,  345.5131],\n       [  16.7414,  109.8972,  896.0229,   19.828 ,  130.6018, 1294.65  ],\n       [  10.1876,   64.8091,  261.3594,   10.9119,   69.4094,  262.9561],\n       [  14.4409,   93.4855,  661.3285,   16.3699,  110.3486,  901.9531],\n       [  11.5152,   74.3437,  412.4988,   12.9087,   83.0967,  487.7146],\n       [  13.9253,   90.4832,  622.8406,   15.9825,  104.381 ,  850.0578],\n       [  12.7614,   82.1135,  502.2453,   14.1879,   94.2658,  647.05  ],\n       [  15.3618,   99.7366,  747.6706,   17.5649,  119.0666, 1041.1291],\n       [  10.3566,   66.1721,  285.6865,   11.2901,   70.771 ,  304.7677],\n       [  13.5662,   89.1232,  634.7909,   15.9441,  103.2991,  824.4211],\n       [  13.1161,   84.5137,  538.6136,   14.6771,   97.791 ,  704.5246],\n       [  13.0149,   83.8588,  527.5517,   14.5383,   96.679 ,  687.7693],\n       [  12.6237,   81.2268,  489.2623,   14.0256,   92.8125,  627.3811],\n       [  12.5189,   81.4211,  512.9184,   14.2927,   92.7666,  642.5031],\n       [  10.8518,   69.4388,  328.4003,   11.8663,   75.5466,  372.7076],\n       [  21.0018,  139.4859, 1394.7904,   25.9536,  178.5027, 2005.0851],\n       [  14.386 ,   94.567 ,  710.0308,   16.9456,  111.3598,  943.4161],\n       [  13.2636,   85.4789,  553.9142,   14.868 ,   99.3788,  727.6132],\n       [  15.9794,  104.5509,  826.6642,   18.7886,  124.0903, 1176.7822],\n       [  14.7016,   95.2718,  686.2584,   16.7208,  112.7783,  942.5496],\n       [  12.2787,   78.8951,  456.7436,   13.5803,   89.5049,  575.3159],\n       [  19.3281,  126.7578, 1123.3118,   22.7797,  156.5235, 1647.5712],\n       [  20.6404,  137.8103, 1351.5486,   25.5865,  173.2471, 1938.427 ],\n       [  16.4874,  109.6893,  941.9137,   20.0912,  132.2582, 1294.689 ],\n       [  13.6316,   88.0179,  583.8189,   15.3162,  102.5108,  778.4829],\n       [  14.3959,   93.2262,  656.9055,   16.3263,  109.7709,  896.1472],\n       [  14.0274,   92.1909,  679.4691,   16.6687,  106.6814,  917.1504],\n       [  13.9326,   92.7871,  733.2609,   17.0498,  109.7183,  934.7137],\n       [  10.9614,   69.9965,  338.0447,   11.9248,   77.1792,  383.1034],\n       [  21.5868,  144.3482, 1399.2919,   27.1274,  174.2421, 2127.6167],\n       [  19.7043,  133.0184, 1306.2659,   25.0086,  164.5908, 1841.8946],\n       [  13.3518,   86.435 ,  575.9538,   15.2271,   99.8858,  766.8719],\n       [  12.644 ,   82.2785,  524.9543,   14.4585,   93.9612,  661.6646],\n       [  12.7441,   82.0242,  501.6166,   14.1836,   94.0737,  646.3085],\n       [  11.7577,   75.6681,  417.6652,   13.0441,   84.6493,  507.7232],\n       [  11.1536,   71.2949,  351.8052,   12.1476,   78.7158,  407.6244],\n       [  11.0438,   70.5477,  349.1141,   12.0615,   78.1442,  399.6307],\n       [  12.6255,   82.1532,  524.2079,   14.4369,   93.8913,  659.2421],\n       [  13.5382,   88.8105,  629.8285,   15.8874,  102.8982,  820.9802],\n       [  11.0693,   72.2142,  409.9154,   12.7676,   80.3036,  454.7746],\n       [  11.717 ,   75.2136,  406.5034,   12.9265,   83.8759,  497.2747],\n       [  14.3673,   94.5821,  714.3099,   17.1606,  109.8495,  973.5144],\n       [  13.553 ,   87.4801,  575.9543,   15.2081,  101.7538,  765.8785],\n       [  14.4863,   94.2507,  693.6265,   16.8535,  110.82  ,  955.6582],\n       [  17.9324,  118.1102, 1010.9493,   21.4581,  141.6014, 1482.6667],\n       [  15.3315,  100.1826,  759.5437,   17.9086,  117.4657, 1072.6597],\n       [  19.7176,  132.2634, 1275.2153,   24.5898,  164.1838, 1807.5942],\n       [  13.8703,   89.6183,  607.0936,   15.6267,  104.8787,  815.1205],\n       [  10.6492,   67.9118,  304.5292,   11.4989,   73.8687,  331.7793],\n       [  19.7365,  129.5162, 1160.2746,   23.295 ,  160.3494, 1707.4789],\n       [  12.6322,   81.2566,  489.6215,   14.023 ,   92.9541,  627.4364],\n       [  13.7678,   88.9296,  601.9989,   15.541 ,  104.1026,  805.6247],\n       [  19.9105,  132.2859, 1282.5385,   24.5172,  167.1505, 1829.9326],\n       [  11.7526,   75.3073,  407.9995,   12.8969,   84.6048,  496.0971],\n       [  19.6182,  130.5937, 1244.8469,   24.1367,  163.1896, 1774.9645],\n       [  12.3174,   79.1247,  460.6319,   13.6209,   89.9864,  580.6235],\n       [  12.7869,   83.2334,  549.702 ,   14.7346,   96.0006,  695.891 ],\n       [  12.0156,   77.5347,  454.759 ,   13.4955,   87.7643,  559.5827],\n       [  15.7496,  102.4085,  786.8408,   18.1088,  122.759 , 1104.306 ],\n       [  12.8041,   82.458 ,  524.8542,   14.4667,   95.2686,  680.4533],\n       [  12.4637,   80.9897,  495.3316,   14.2065,   90.7567,  634.4906],\n       [  15.7279,  105.8516,  935.6974,   19.7683,  127.8882, 1234.689 ],\n       [  18.5976,  122.3451, 1086.6528,   22.3065,  149.6483, 1590.465 ],\n       [  16.0278,  104.3045,  810.7228,   18.4542,  125.2459, 1143.9444],\n       [  13.4623,   87.7903,  621.3243,   15.6519,  103.0558,  805.7483],\n       [  11.8522,   76.0078,  417.0257,   13.0321,   85.4573,  511.3955],\n       [  24.8565,  164.3448, 1663.6378,   30.1859,  209.755 , 2512.7331],\n       [  17.9906,  119.048 , 1066.5882,   21.7625,  146.6804, 1506.4853],\n       [  12.0649,   78.2896,  467.4069,   13.6799,   88.2907,  571.9067],\n       [  10.4945,   66.8377,  290.1488,   11.2909,   72.4848,  307.9205],\n       [  13.0713,   84.3337,  543.2982,   14.7663,   97.3186,  713.6114],\n       [  12.2128,   78.6447,  455.2596,   13.6157,   88.4777,  576.8119],\n       [  14.9926,   97.5729,  736.4704,   17.4168,  115.7668, 1023.086 ],\n       [  10.5105,   66.967 ,  291.7962,   11.32  ,   72.5806,  311.0563],\n       [  16.0373,  104.7908,  836.9412,   18.8387,  125.4129, 1187.3012],\n       [  19.2039,  125.9586, 1128.5782,   22.7946,  156.0561, 1651.3698],\n       [  10.1993,   64.8548,  262.1921,   10.9129,   69.6077,  263.5543],\n       [  14.9299,   97.6663,  756.8965,   17.7741,  114.9037, 1060.2013],\n       [  11.9837,   77.0182,  439.6831,   13.3326,   86.9129,  546.8445]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_set = my_model(x_test.double())\n",
    "predicted_set = scaler.inverse_transform(predicted_set.detach().numpy())\n",
    "predicted_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_values = []\n",
    "predicted_values = []\n",
    "x_values = []\n",
    "\n",
    "\n",
    "for missing_data, full_data, predicted in zip(x_test, y_test, predicted_set):\n",
    "    if NAN in missing_data:\n",
    "        for i in range(len(missing_data)):\n",
    "            if missing_data[i] == NAN:\n",
    "                x_values.append(full_data[0].item())\n",
    "                real_values.append(full_data[i].item())\n",
    "                predicted_values.append(predicted[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "P-value for significance:  4.166242047350611e-15\nTTEST:  -8.275235217282392\nConclusion: Accept Null Hypothesis\n"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "from statsmodels.stats import weightstats as stets\n",
    "\n",
    "\n",
    "ttest, pval = stats.ttest_ind(real_values, predicted_values)\n",
    "print(\"P-value for significance: \", pval)\n",
    "print(\"TTEST: \", ttest)\n",
    "\n",
    "if pval.any()<0.05:\n",
    "    print(\"Conclusion: Reject Null Hypothesis\")\n",
    "else:\n",
    "    print(\"Conclusion: Accept Null Hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('breast/breast.csv')\n",
    "array = np.array(['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst'])\n",
    "filtered_data = dataset[array]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "scaled_set = scaler.fit_transform(filtered_data.to_numpy())\n",
    "scaled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = fill_nan(scaled_set, scaled_set.size*0.2)\n",
    "\n",
    "input_tensor = torch.from_numpy(missing_data)\n",
    "input_tensor = input_tensor.view(input_tensor.shape[0], NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.6767,  0.6652,  0.4957,  0.6209,  0.6213,  0.4340],\n        [ 0.6617,  0.6589,  0.4991,  0.6331,  0.5989,  0.4400],\n        [ 0.3974,  0.3961,  0.2622,  0.3637,  0.3270,  0.2225],\n        ...,\n        [ 0.4296,  0.4286,  0.3109,  0.4001,  0.3859,  0.2512],\n        [ 0.5644,  0.5569,  0.4080,  0.5235,  0.5057,  0.3541],\n        [ 0.1237,  0.1187,  0.0298,  0.0821,  0.0679, -0.0010]],\n       dtype=torch.float64, grad_fn=<AddmmBackward>)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = my_model(input_tensor.double())\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "new_dataset = scaler.inverse_transform(new_dataset.detach().numpy())\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dataset = filtered_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(0.9978552814938108, 0.0)\n(0.9453786462552797, 3.343434346388964e-278)\n"
    }
   ],
   "source": [
    "print(scipy.stats.pearsonr(real_dataset[:, 0], real_dataset[:, 1]))\n",
    "print(scipy.stats.pearsonr(real_dataset[:, 0], new_dataset[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(0.9873571700566124, 0.0)\n(0.9483294771934577, 7.439654388571332e-285)\n"
    }
   ],
   "source": [
    "print(scipy.stats.pearsonr(real_dataset[:, 0], real_dataset[:, 2]))\n",
    "print(scipy.stats.pearsonr(real_dataset[:, 0], new_dataset[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(0.9695389726112063, 0.0)\n(0.9484417182646606, 4.081794241280509e-285)\n"
    }
   ],
   "source": [
    "print(scipy.stats.pearsonr(real_dataset[:, 0], real_dataset[:, 3]))\n",
    "print(scipy.stats.pearsonr(real_dataset[:, 0], new_dataset[:, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(0.9651365139559875, 0.0)\n(0.9448805305620419, 4.079523599935882e-277)\n"
    }
   ],
   "source": [
    "print(scipy.stats.pearsonr(real_dataset[:, 0], real_dataset[:, 4]))\n",
    "print(scipy.stats.pearsonr(real_dataset[:, 0], new_dataset[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(0.9410824595860467, 3.767446784305406e-269)\n(0.9483678761118814, 6.059396608737617e-285)\n"
    }
   ],
   "source": [
    "print(scipy.stats.pearsonr(real_dataset[:, 0], real_dataset[:, 5]))\n",
    "print(scipy.stats.pearsonr(real_dataset[:, 0], new_dataset[:, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt('new_breast.csv', new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}