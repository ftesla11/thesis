{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbasecondad424485431ff4a8aa076a99cfa3fb48c",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy\n",
    "from distcorr import distcorr\n",
    "from fractions import gcd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(array, REPLACE_COUNT):\n",
    "    NAN = 0\n",
    "    array.flat[np.random.choice(array.size, int(REPLACE_COUNT), replace=False)] = NAN\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENABLE/DISABLE GPU\n",
    "# UNCOMMENT to.device() FOR TENSORS AND NEURAL NETWORKS TO ENABLE GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "np.set_printoptions(threshold=sys.maxsize, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.30010</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.16220</td>\n      <td>0.66560</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.08690</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.12380</td>\n      <td>0.18660</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.19740</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.14440</td>\n      <td>0.42450</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.24140</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.20980</td>\n      <td>0.86630</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.19800</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.13740</td>\n      <td>0.20500</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>926424</td>\n      <td>M</td>\n      <td>21.56</td>\n      <td>22.39</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>0.11100</td>\n      <td>0.11590</td>\n      <td>0.24390</td>\n      <td>0.13890</td>\n      <td>...</td>\n      <td>26.40</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n      <td>0.14100</td>\n      <td>0.21130</td>\n      <td>0.4107</td>\n      <td>0.2216</td>\n      <td>0.2060</td>\n      <td>0.07115</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>926682</td>\n      <td>M</td>\n      <td>20.13</td>\n      <td>28.25</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>0.09780</td>\n      <td>0.10340</td>\n      <td>0.14400</td>\n      <td>0.09791</td>\n      <td>...</td>\n      <td>38.25</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n      <td>0.11660</td>\n      <td>0.19220</td>\n      <td>0.3215</td>\n      <td>0.1628</td>\n      <td>0.2572</td>\n      <td>0.06637</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>926954</td>\n      <td>M</td>\n      <td>16.60</td>\n      <td>28.08</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>0.08455</td>\n      <td>0.10230</td>\n      <td>0.09251</td>\n      <td>0.05302</td>\n      <td>...</td>\n      <td>34.12</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n      <td>0.11390</td>\n      <td>0.30940</td>\n      <td>0.3403</td>\n      <td>0.1418</td>\n      <td>0.2218</td>\n      <td>0.07820</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>927241</td>\n      <td>M</td>\n      <td>20.60</td>\n      <td>29.33</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>0.11780</td>\n      <td>0.27700</td>\n      <td>0.35140</td>\n      <td>0.15200</td>\n      <td>...</td>\n      <td>39.42</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n      <td>0.16500</td>\n      <td>0.86810</td>\n      <td>0.9387</td>\n      <td>0.2650</td>\n      <td>0.4087</td>\n      <td>0.12400</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>92751</td>\n      <td>B</td>\n      <td>7.76</td>\n      <td>24.54</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>0.05263</td>\n      <td>0.04362</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>...</td>\n      <td>30.37</td>\n      <td>59.16</td>\n      <td>268.6</td>\n      <td>0.08996</td>\n      <td>0.06444</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.2871</td>\n      <td>0.07039</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 33 columns</p>\n</div>",
      "text/plain": "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0      842302         M        17.99         10.38          122.80     1001.0   \n1      842517         M        20.57         17.77          132.90     1326.0   \n2    84300903         M        19.69         21.25          130.00     1203.0   \n3    84348301         M        11.42         20.38           77.58      386.1   \n4    84358402         M        20.29         14.34          135.10     1297.0   \n..        ...       ...          ...           ...             ...        ...   \n564    926424         M        21.56         22.39          142.00     1479.0   \n565    926682         M        20.13         28.25          131.20     1261.0   \n566    926954         M        16.60         28.08          108.30      858.1   \n567    927241         M        20.60         29.33          140.10     1265.0   \n568     92751         B         7.76         24.54           47.92      181.0   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.11840           0.27760         0.30010              0.14710   \n1            0.08474           0.07864         0.08690              0.07017   \n2            0.10960           0.15990         0.19740              0.12790   \n3            0.14250           0.28390         0.24140              0.10520   \n4            0.10030           0.13280         0.19800              0.10430   \n..               ...               ...             ...                  ...   \n564          0.11100           0.11590         0.24390              0.13890   \n565          0.09780           0.10340         0.14400              0.09791   \n566          0.08455           0.10230         0.09251              0.05302   \n567          0.11780           0.27700         0.35140              0.15200   \n568          0.05263           0.04362         0.00000              0.00000   \n\n     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0    ...          17.33           184.60      2019.0           0.16220   \n1    ...          23.41           158.80      1956.0           0.12380   \n2    ...          25.53           152.50      1709.0           0.14440   \n3    ...          26.50            98.87       567.7           0.20980   \n4    ...          16.67           152.20      1575.0           0.13740   \n..   ...            ...              ...         ...               ...   \n564  ...          26.40           166.10      2027.0           0.14100   \n565  ...          38.25           155.00      1731.0           0.11660   \n566  ...          34.12           126.70      1124.0           0.11390   \n567  ...          39.42           184.60      1821.0           0.16500   \n568  ...          30.37            59.16       268.6           0.08996   \n\n     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0              0.66560           0.7119                0.2654          0.4601   \n1              0.18660           0.2416                0.1860          0.2750   \n2              0.42450           0.4504                0.2430          0.3613   \n3              0.86630           0.6869                0.2575          0.6638   \n4              0.20500           0.4000                0.1625          0.2364   \n..                 ...              ...                   ...             ...   \n564            0.21130           0.4107                0.2216          0.2060   \n565            0.19220           0.3215                0.1628          0.2572   \n566            0.30940           0.3403                0.1418          0.2218   \n567            0.86810           0.9387                0.2650          0.4087   \n568            0.06444           0.0000                0.0000          0.2871   \n\n     fractal_dimension_worst  Unnamed: 32  \n0                    0.11890          NaN  \n1                    0.08902          NaN  \n2                    0.08758          NaN  \n3                    0.17300          NaN  \n4                    0.07678          NaN  \n..                       ...          ...  \n564                  0.07115          NaN  \n565                  0.06637          NaN  \n566                  0.07820          NaN  \n567                  0.12400          NaN  \n568                  0.07039          NaN  \n\n[569 rows x 33 columns]"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('breast/breast.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>radius_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>25.380</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>24.990</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>23.570</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>14.910</td>\n      <td>98.87</td>\n      <td>567.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>22.540</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>25.450</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>23.690</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>18.980</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>25.740</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>9.456</td>\n      <td>59.16</td>\n      <td>268.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 6 columns</p>\n</div>",
      "text/plain": "     radius_mean  perimeter_mean  area_mean  radius_worst  perimeter_worst  \\\n0          17.99          122.80     1001.0        25.380           184.60   \n1          20.57          132.90     1326.0        24.990           158.80   \n2          19.69          130.00     1203.0        23.570           152.50   \n3          11.42           77.58      386.1        14.910            98.87   \n4          20.29          135.10     1297.0        22.540           152.20   \n..           ...             ...        ...           ...              ...   \n564        21.56          142.00     1479.0        25.450           166.10   \n565        20.13          131.20     1261.0        23.690           155.00   \n566        16.60          108.30      858.1        18.980           126.70   \n567        20.60          140.10     1265.0        25.740           184.60   \n568         7.76           47.92      181.0         9.456            59.16   \n\n     area_worst  \n0        2019.0  \n1        1956.0  \n2        1709.0  \n3         567.7  \n4        1575.0  \n..          ...  \n564      2027.0  \n565      1731.0  \n566      1124.0  \n567      1821.0  \n568       268.6  \n\n[569 rows x 6 columns]"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NARROW THE FEATURES\n",
    "array = np.array(['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst'])\n",
    "processed_data = dataset[array]\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(processed_data.columns)):\n",
    "#     for j in range(i+1, len(processed_data.columns)):\n",
    "#         corr, _ = pearsonr(processed_data[processed_data.columns[i]], processed_data[processed_data.columns[j]])\n",
    "#         print(\"PEARSONR: \", processed_data.columns[i], processed_data.columns[j], corr)\n",
    "#         print(\"DCORR: \", processed_data.columns[i], processed_data.columns[j], distcorr(processed_data[processed_data.columns[j]], processed_data[processed_data.columns[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(processed_data.columns)):\n",
    "#     for j in range(i+1, len(processed_data.columns)):\n",
    "#         processed_data.plot(x=processed_data.columns[i], y=processed_data.columns[j], style='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([  17.99,  122.8 , 1001.  ,   25.38,  184.6 , 2019.  ])"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO NUMPY\n",
    "numpy_data = processed_data.to_numpy()\n",
    "numpy_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZE THE DATA\n",
    "scaled_data = scaler.fit_transform(numpy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": " 0.4 , 0.37, 0.24],\n       [0.42, 0.41, 0.27, 0.44, 0.43, 0.27],\n       [0.58, 0.61, 0.42, 0.46, 0.5 , 0.28],\n       [0.42, 0.41, 0.27, 0.32, 0.31, 0.17],\n       [0.32, 0.34, 0.18, 0.25, 0.29, 0.13],\n       [0.36, 0.37, 0.22, 0.34, 0.37, 0.19],\n       [0.36, 0.35, 0.23, 0.4 , 0.36, 0.23],\n       [0.43, 0.44, 0.28, 0.46, 0.43, 0.28],\n       [0.61, 0.6 , 0.47, 0.69, 0.68, 0.54],\n       [0.31, 0.3 , 0.18, 0.26, 0.25, 0.13],\n       [0.29, 0.29, 0.16, 0.23, 0.23, 0.11],\n       [0.12, 0.11, 0.06, 0.08, 0.07, 0.03],\n       [0.4 , 0.41, 0.24, 0.36, 0.37, 0.2 ],\n       [0.67, 0.65, 0.53, 0.76, 0.69, 0.6 ],\n       [0.46, 0.46, 0.32, 0.66, 0.63, 0.5 ],\n       [0.48, 0.5 , 0.33, 0.51, 0.51, 0.31],\n       [0.36, 0.37, 0.21, 0.34, 0.36, 0.17],\n       [0.55, 0.54, 0.4 , 0.48, 0.45, 0.3 ],\n       [0.39, 0.41, 0.25, 0.44, 0.49, 0.27],\n       [0.5 , 0.49, 0.34, 0.43, 0.42, 0.26],\n       [0.55, 0.56, 0.4 , 0.54, 0.55, 0.36],\n       [0.23, 0.24, 0.13, 0.32, 0.34, 0.17],\n       [0.48, 0.48, 0.32, 0.46, 0.43, 0.28],\n       [0.58, 0.58, 0.43, 0.58, 0.55, 0.4 ],\n       [0.43, 0.44, 0.28, 0.44, 0.41, 0.26],\n       [0.46, 0.46, 0.31, 0.43, 0.41, 0.26],\n       [0.34, 0.34, 0.21, 0.28, 0.33, 0.15],\n       [0.29, 0.27, 0.16, 0.19, 0.17, 0.09],\n       [0.38, 0.36, 0.24, 0.25, 0.22, 0.13],\n       [0.31, 0.31, 0.18, 0.27, 0.28, 0.14],\n       [0.31, 0.29, 0.18, 0.28, 0.26, 0.15],\n       [0.19, 0.19, 0.1 , 0.17, 0.18, 0.08],\n       [0.57, 0.58, 0.41, 0.57, 0.63, 0.36],\n       [0.3 , 0.3 , 0.17, 0.34, 0.31, 0.18],\n       [0.29, 0.29, 0.16, 0.3 , 0.27, 0.14],\n       [0.55, 0.55, 0.4 , 0.53, 0.5 , 0.34],\n       [0.06, 0.05, 0.02, 0.04, 0.03, 0.01],\n       [0.29, 0.29, 0.17, 0.28, 0.26, 0.14],\n       [0.24, 0.24, 0.13, 0.21, 0.2 , 0.1 ],\n       [0.31, 0.3 , 0.18, 0.26, 0.24, 0.13],\n       [0.23, 0.21, 0.12, 0.18, 0.16, 0.08],\n       [0.32, 0.3 , 0.18, 0.24, 0.23, 0.12],\n       [0.23, 0.22, 0.12, 0.18, 0.17, 0.08],\n       [0.53, 0.53, 0.38, 0.45, 0.42, 0.28],\n       [0.38, 0.37, 0.24, 0.36, 0.34, 0.21],\n       [0.21, 0.2 , 0.11, 0.17, 0.16, 0.08],\n       [0.58, 0.56, 0.43, 0.65, 0.6 , 0.48],\n       [0.37, 0.36, 0.22, 0.35, 0.33, 0.2 ],\n       [0.29, 0.27, 0.16, 0.22, 0.2 , 0.11],\n       [0.08, 0.07, 0.03, 0.06, 0.05, 0.02],\n       [0.15, 0.14, 0.07, 0.11, 0.1 , 0.05],\n       [0.08, 0.08, 0.03, 0.06, 0.06, 0.02],\n       [0.34, 0.36, 0.21, 0.35, 0.34, 0.19],\n       [0.1 , 0.11, 0.05, 0.07, 0.08, 0.03],\n       [0.27, 0.27, 0.15, 0.33, 0.31, 0.17],\n       [0.37, 0.37, 0.22, 0.33, 0.32, 0.18],\n       [0.12, 0.11, 0.05, 0.09, 0.08, 0.04],\n       [0.2 , 0.19, 0.11, 0.16, 0.14, 0.07],\n       [0.1 , 0.1 , 0.05, 0.08, 0.08, 0.03],\n       [0.27, 0.26, 0.15, 0.2 , 0.18, 0.09],\n       [0.57, 0.55, 0.42, 0.6 , 0.58, 0.41],\n       [0.09, 0.1 , 0.04, 0.06, 0.06, 0.02],\n       [0.48, 0.49, 0.33, 0.55, 0.5 , 0.37],\n       [0.32, 0.32, 0.19, 0.31, 0.3 , 0.15],\n       [0.25, 0.24, 0.14, 0.22, 0.2 , 0.1 ],\n       [0.43, 0.42, 0.29, 0.42, 0.39, 0.26],\n       [0.31, 0.3 , 0.18, 0.22, 0.2 , 0.1 ],\n       [0.52, 0.53, 0.37, 0.51, 0.5 , 0.35],\n       [0.62, 0.69, 0.47, 0.55, 0.6 , 0.35],\n       [0.28, 0.27, 0.15, 0.22, 0.21, 0.11],\n       [0.21, 0.21, 0.11, 0.18, 0.17, 0.08],\n       [0.3 , 0.3 , 0.16, 0.27, 0.23, 0.11],\n       [0.86, 0.88, 0.74, 0.79, 0.8 , 0.58],\n       [0.57, 0.59, 0.42, 0.44, 0.45, 0.27],\n       [0.24, 0.23, 0.13, 0.2 , 0.19, 0.09],\n       [0.54, 0.53, 0.4 , 0.53, 0.51, 0.35],\n       [0.35, 0.35, 0.21, 0.29, 0.29, 0.15],\n       [0.57, 0.54, 0.4 , 0.59, 0.51, 0.35],\n       [0.25, 0.25, 0.14, 0.21, 0.2 , 0.1 ],\n       [0.36, 0.36, 0.22, 0.3 , 0.29, 0.15],\n       [0.36, 0.35, 0.22, 0.29, 0.26, 0.15],\n       [0.4 , 0.39, 0.25, 0.3 , 0.28, 0.16],\n       [0.3 , 0.28, 0.17, 0.3 , 0.27, 0.16],\n       [0.31, 0.3 , 0.17, 0.26, 0.23, 0.13],\n       [0.38, 0.39, 0.24, 0.37, 0.36, 0.21],\n       [0.63, 0.61, 0.48, 0.58, 0.53, 0.38],\n       [0.25, 0.23, 0.13, 0.17, 0.16, 0.08],\n       [0.13, 0.13, 0.06, 0.11, 0.09, 0.04],\n       [0.22, 0.21, 0.11, 0.18, 0.16, 0.08],\n       [0.35, 0.35, 0.21, 0.3 , 0.29, 0.16],\n       [0.31, 0.31, 0.19, 0.32, 0.29, 0.18],\n       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n       [0.25, 0.23, 0.13, 0.19, 0.17, 0.09],\n       [0.14, 0.14, 0.07, 0.1 , 0.11, 0.04],\n       [0.17, 0.16, 0.08, 0.13, 0.12, 0.05],\n       [0.29, 0.3 , 0.16, 0.3 , 0.28, 0.16],\n       [0.22, 0.22, 0.11, 0.19, 0.17, 0.08],\n       [0.25, 0.24, 0.14, 0.19, 0.18, 0.09],\n       [0.72, 0.75, 0.58, 0.73, 0.78, 0.53],\n       [0.21, 0.2 , 0.11, 0.18, 0.17, 0.08],\n       [0.13, 0.13, 0.06, 0.11, 0.11, 0.04],\n       [0.27, 0.27, 0.14, 0.19, 0.19, 0.08],\n       [0.34, 0.37, 0.21, 0.26, 0.28, 0.13],\n       [0.17, 0.17, 0.08, 0.11, 0.11, 0.05],\n       [0.08, 0.08, 0.04, 0.06, 0.07, 0.02],\n       [0.23, 0.23, 0.13, 0.2 , 0.18, 0.1 ],\n       [0.09, 0.1 , 0.04, 0.05, 0.06, 0.02],\n       [0.37, 0.38, 0.23, 0.39, 0.38, 0.22],\n       [0.42, 0.43, 0.27, 0.44, 0.4 , 0.27],\n       [0.52, 0.49, 0.36, 0.45, 0.39, 0.26],\n       [0.21, 0.2 , 0.11, 0.17, 0.17, 0.08],\n       [0.55, 0.54, 0.4 , 0.51, 0.47, 0.34],\n       [0.82, 0.85, 0.69, 0.64, 0.65, 0.46],\n       [0.36, 0.35, 0.21, 0.28, 0.26, 0.14],\n       [0.3 , 0.29, 0.17, 0.23, 0.21, 0.11],\n       [0.33, 0.31, 0.19, 0.27, 0.25, 0.13],\n       [0.31, 0.3 , 0.18, 0.32, 0.31, 0.16],\n       [0.57, 0.55, 0.42, 0.51, 0.49, 0.33],\n       [0.38, 0.39, 0.23, 0.29, 0.28, 0.14],\n       [0.61, 0.6 , 0.44, 0.52, 0.49, 0.35],\n       [0.25, 0.24, 0.13, 0.19, 0.2 , 0.09],\n       [0.4 , 0.4 , 0.26, 0.4 , 0.37, 0.24],\n       [0.43, 0.43, 0.28, 0.41, 0.39, 0.24],\n       [0.41, 0.4 , 0.26, 0.34, 0.32, 0.18],\n       [0.54, 0.53, 0.4 , 0.52, 0.47, 0.35],\n       [0.27, 0.26, 0.15, 0.23, 0.21, 0.12],\n       [0.22, 0.21, 0.12, 0.19, 0.18, 0.09],\n       [0.21, 0.2 , 0.11, 0.16, 0.15, 0.07],\n       [0.38, 0.37, 0.23, 0.38, 0.35, 0.19],\n       [0.2 , 0.2 , 0.1 , 0.14, 0.13, 0.06],\n       [0.13, 0.12, 0.06, 0.1 , 0.08, 0.04],\n       [0.43, 0.42, 0.28, 0.43, 0.39, 0.26],\n       [0.21, 0.21, 0.11, 0.17, 0.16, 0.08],\n       [0.28, 0.28, 0.16, 0.23, 0.23, 0.11],\n       [0.18, 0.17, 0.09, 0.14, 0.14, 0.06],\n       [0.23, 0.24, 0.12, 0.19, 0.18, 0.08],\n       [0.23, 0.24, 0.12, 0.21, 0.21, 0.1 ],\n       [0.38, 0.37, 0.23, 0.3 , 0.28, 0.15],\n       [0.35, 0.35, 0.21, 0.28, 0.29, 0.14],\n       [0.32, 0.31, 0.19, 0.26, 0.23, 0.13],\n       [0.28, 0.27, 0.16, 0.22, 0.2 , 0.11],\n       [0.06, 0.07, 0.03, 0.04, 0.04, 0.02],\n       [0.13, 0.14, 0.07, 0.11, 0.1 , 0.05],\n       [0.2 , 0.19, 0.1 , 0.14, 0.13, 0.06],\n       [0.29, 0.29, 0.17, 0.24, 0.24, 0.12],\n       [0.25, 0.24, 0.13, 0.2 , 0.18, 0.09],\n       [0.51, 0.51, 0.35, 0.45, 0.41, 0.27],\n       [0.47, 0.45, 0.31, 0.37, 0.35, 0.21],\n       [0.24, 0.23, 0.13, 0.19, 0.17, 0.09],\n       [0.19, 0.17, 0.09, 0.16, 0.14, 0.07],\n       [0.23, 0.22, 0.12, 0.19, 0.19, 0.09],\n       [0.58, 0.57, 0.43, 0.5 , 0.48, 0.32],\n       [0.6 , 0.6 , 0.45, 0.67, 0.62, 0.5 ],\n       [0.25, 0.25, 0.14, 0.2 , 0.18, 0.09],\n       [0.77, 0.75, 0.65, 0.71, 0.67, 0.55],\n       [0.38, 0.36, 0.23, 0.29, 0.26, 0.15],\n       [0.18, 0.17, 0.09, 0.13, 0.12, 0.06],\n       [0.46, 0.45, 0.32, 0.43, 0.4 , 0.26],\n       [0.5 , 0.5 , 0.36, 0.54, 0.52, 0.36],\n       [0.38, 0.36, 0.23, 0.29, 0.27, 0.15],\n       [0.25, 0.24, 0.14, 0.2 , 0.18, 0.09],\n       [0.31, 0.29, 0.18, 0.36, 0.33, 0.2 ],\n       [0.4 , 0.41, 0.25, 0.39, 0.37, 0.23],\n       [0.19, 0.18, 0.1 , 0.12, 0.11, 0.05],\n       [0.17, 0.16, 0.09, 0.13, 0.11, 0.05],\n       [0.08, 0.07, 0.04, 0.05, 0.04, 0.02],\n       [0.14, 0.14, 0.07, 0.12, 0.11, 0.05],\n       [0.45, 0.45, 0.29, 0.35, 0.36, 0.2 ],\n       [0.29, 0.26, 0.16, 0.22, 0.19, 0.1 ],\n       [0.28, 0.26, 0.15, 0.2 , 0.18, 0.09],\n       [0.96, 0.96, 0.89, 0.9 , 0.85, 0.74],\n       [0.67, 0.68, 0.5 , 0.67, 0.63, 0.47],\n       [0.41, 0.4 , 0.26, 0.43, 0.39, 0.27],\n       [0.21, 0.21, 0.11, 0.16, 0.14, 0.07],\n       [0.39, 0.38, 0.24, 0.35, 0.32, 0.19],\n       [0.15, 0.14, 0.07, 0.14, 0.12, 0.06],\n       [0.54, 0.52, 0.38, 0.48, 0.44, 0.3 ],\n       [0.22, 0.21, 0.12, 0.18, 0.17, 0.08],\n       [0.23, 0.22, 0.12, 0.17, 0.15, 0.07],\n       [0.25, 0.24, 0.14, 0.19, 0.18, 0.09],\n       [0.34, 0.35, 0.2 , 0.28, 0.28, 0.14],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.13, 0.12, 0.06, 0.07, 0.06, 0.03],\n       [0.25, 0.26, 0.14, 0.27, 0.26, 0.14],\n       [0.37, 0.39, 0.22, 0.29, 0.34, 0.15],\n       [0.28, 0.27, 0.16, 0.21, 0.2 , 0.1 ],\n       [0.32, 0.32, 0.19, 0.3 , 0.3 , 0.15],\n       [0.53, 0.51, 0.37, 0.42, 0.39, 0.26],\n       [0.58, 0.58, 0.43, 0.55, 0.58, 0.37],\n       [0.35, 0.35, 0.21, 0.37, 0.34, 0.21],\n       [0.25, 0.24, 0.13, 0.23, 0.21, 0.11],\n       [0.5 , 0.49, 0.34, 0.44, 0.44, 0.26],\n       [0.77, 0.8 , 0.65, 0.61, 0.63, 0.44],\n       [0.32, 0.33, 0.19, 0.4 , 0.39, 0.24],\n       [0.26, 0.26, 0.14, 0.25, 0.23, 0.12],\n       [0.39, 0.38, 0.24, 0.35, 0.34, 0.2 ],\n       [0.14, 0.13, 0.06, 0.09, 0.08, 0.04],\n       [0.47, 0.46, 0.32, 0.42, 0.4 , 0.25],\n       [0.29, 0.3 , 0.16, 0.24, 0.24, 0.11],\n       [0.39, 0.38, 0.25, 0.34, 0.32, 0.18],\n       [0.64, 0.63, 0.49, 0.54, 0.54, 0.36],\n       [0.23, 0.22, 0.12, 0.19, 0.17, 0.09],\n       [1.  , 1.  , 1.  , 0.72, 0.69, 0.57],\n       [0.49, 0.49, 0.34, 0.36, 0.35, 0.21],\n       [0.34, 0.34, 0.2 , 0.32, 0.32, 0.15],\n       [0.33, 0.33, 0.18, 0.28, 0.27, 0.14],\n       [0.23, 0.23, 0.12, 0.19, 0.18, 0.09],\n       [0.15, 0.15, 0.08, 0.13, 0.12, 0.05],\n       [0.61, 0.59, 0.46, 0.63, 0.6 , 0.45],\n       [0.59, 0.58, 0.46, 0.71, 0.65, 0.56],\n       [0.32, 0.3 , 0.18, 0.26, 0.25, 0.13],\n       [0.31, 0.31, 0.18, 0.25, 0.25, 0.12],\n       [0.15, 0.15, 0.07, 0.12, 0.11, 0.05],\n       [0.42, 0.41, 0.26, 0.41, 0.38, 0.22],\n       [0.3 , 0.28, 0.17, 0.26, 0.24, 0.13],\n       [0.35, 0.34, 0.21, 0.31, 0.3 , 0.17],\n       [0.16, 0.16, 0.08, 0.13, 0.11, 0.05],\n       [0.38, 0.37, 0.23, 0.3 , 0.32, 0.15],\n       [0.27, 0.26, 0.15, 0.22, 0.2 , 0.11],\n       [0.28, 0.29, 0.15, 0.26, 0.27, 0.13],\n       [0.48, 0.48, 0.32, 0.41, 0.41, 0.25],\n       [0.21, 0.19, 0.11, 0.15, 0.15, 0.07],\n       [0.2 , 0.19, 0.1 , 0.16, 0.14, 0.07],\n       [0.64, 0.63, 0.5 , 0.59, 0.56, 0.41],\n       [0.12, 0.11, 0.06, 0.09, 0.08, 0.04],\n       [0.33, 0.32, 0.2 , 0.26, 0.24, 0.13],\n       [0.77, 0.76, 0.65, 0.82, 0.77, 0.68],\n       [0.64, 0.61, 0.49, 0.58, 0.55, 0.38],\n       [0.34, 0.34, 0.2 , 0.28, 0.26, 0.14],\n       [0.5 , 0.48, 0.33, 0.52, 0.45, 0.3 ],\n       [0.32, 0.3 , 0.18, 0.25, 0.22, 0.12],\n       [0.26, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.2 , 0.21, 0.1 , 0.17, 0.18, 0.07],\n       [0.32, 0.31, 0.19, 0.25, 0.24, 0.13],\n       [0.59, 0.59, 0.43, 0.49, 0.47, 0.3 ],\n       [0.17, 0.16, 0.08, 0.13, 0.12, 0.05],\n       [0.29, 0.28, 0.17, 0.21, 0.19, 0.1 ],\n       [0.28, 0.28, 0.16, 0.23, 0.27, 0.11],\n       [0.17, 0.17, 0.09, 0.15, 0.14, 0.07],\n       [0.21, 0.21, 0.11, 0.17, 0.15, 0.08],\n       [0.66, 0.66, 0.52, 0.63, 0.57, 0.45],\n       [0.21, 0.2 , 0.11, 0.18, 0.16, 0.08],\n       [0.6 , 0.6 , 0.45, 0.62, 0.54, 0.43],\n       [0.49, 0.48, 0.33, 0.42, 0.4 , 0.25],\n       [0.59, 0.57, 0.43, 0.63, 0.56, 0.44],\n       [0.33, 0.33, 0.19, 0.3 , 0.29, 0.16],\n       [0.59, 0.62, 0.45, 0.61, 0.64, 0.43],\n       [0.39, 0.41, 0.24, 0.35, 0.35, 0.18],\n       [0.41, 0.46, 0.27, 0.42, 0.46, 0.26],\n       [0.4 , 0.41, 0.26, 0.38, 0.38, 0.21],\n       [0.63, 0.62, 0.49, 0.58, 0.56, 0.41],\n       [0.49, 0.46, 0.33, 0.42, 0.39, 0.25],\n       [0.49, 0.49, 0.34, 0.44, 0.44, 0.27],\n       [0.41, 0.39, 0.26, 0.36, 0.33, 0.2 ],\n       [0.48, 0.47, 0.33, 0.49, 0.45, 0.31],\n       [0.65, 0.64, 0.54, 0.87, 0.81, 0.8 ],\n       [0.17, 0.18, 0.09, 0.14, 0.14, 0.06],\n       [0.31, 0.3 , 0.18, 0.24, 0.24, 0.12],\n       [0.28, 0.27, 0.16, 0.21, 0.19, 0.1 ],\n       [0.18, 0.18, 0.09, 0.13, 0.13, 0.06],\n       [0.35, 0.32, 0.21, 0.25, 0.22, 0.12],\n       [0.2 , 0.2 , 0.1 , 0.16, 0.14, 0.07],\n       [0.7 , 0.72, 0.57, 0.72, 0.72, 0.54],\n       [0.13, 0.12, 0.06, 0.1 , 0.09, 0.04],\n       [0.52, 0.49, 0.36, 0.46, 0.42, 0.28],\n       [0.23, 0.22, 0.12, 0.16, 0.14, 0.07],\n       [0.21, 0.19, 0.11, 0.15, 0.13, 0.07],\n       [0.56, 0.53, 0.41, 0.43, 0.39, 0.26],\n       [0.31, 0.29, 0.18, 0.27, 0.24, 0.14],\n       [0.33, 0.31, 0.19, 0.25, 0.24, 0.12],\n       [0.58, 0.57, 0.42, 0.56, 0.54, 0.38],\n       [0.23, 0.21, 0.12, 0.19, 0.17, 0.09],\n       [0.59, 0.58, 0.42, 0.56, 0.51, 0.35],\n       [0.44, 0.45, 0.28, 0.38, 0.38, 0.21],\n       [0.28, 0.28, 0.16, 0.21, 0.21, 0.1 ],\n       [0.26, 0.25, 0.15, 0.2 , 0.18, 0.09],\n       [0.23, 0.24, 0.13, 0.19, 0.21, 0.09],\n       [0.28, 0.26, 0.16, 0.2 , 0.18, 0.1 ],\n       [0.2 , 0.21, 0.11, 0.14, 0.14, 0.06],\n       [0.21, 0.2 , 0.11, 0.16, 0.14, 0.07],\n       [0.35, 0.36, 0.22, 0.28, 0.26, 0.14],\n       [0.38, 0.37, 0.23, 0.3 , 0.29, 0.15],\n       [0.28, 0.27, 0.16, 0.21, 0.19, 0.1 ],\n       [0.23, 0.22, 0.12, 0.18, 0.17, 0.08],\n       [0.27, 0.26, 0.15, 0.2 , 0.19, 0.09],\n       [0.32, 0.31, 0.19, 0.24, 0.22, 0.12],\n       [0.19, 0.18, 0.09, 0.12, 0.11, 0.05],\n       [0.23, 0.22, 0.12, 0.19, 0.17, 0.09],\n       [0.34, 0.33, 0.21, 0.29, 0.28, 0.16],\n       [0.17, 0.16, 0.08, 0.11, 0.1 , 0.04],\n       [0.59, 0.59, 0.46, 0.64, 0.6 , 0.46],\n       [0.26, 0.25, 0.14, 0.2 , 0.19, 0.09],\n       [0.62, 0.63, 0.47, 0.56, 0.54, 0.37],\n       [0.17, 0.16, 0.08, 0.11, 0.1 , 0.05],\n       [0.21, 0.21, 0.11, 0.17, 0.16, 0.07],\n       [0.22, 0.21, 0.12, 0.16, 0.15, 0.07],\n       [0.29, 0.28, 0.17, 0.23, 0.21, 0.11],\n       [0.1 , 0.09, 0.04, 0.06, 0.05, 0.02],\n       [0.31, 0.29, 0.18, 0.25, 0.22, 0.13],\n       [0.29, 0.27, 0.16, 0.24, 0.22, 0.12],\n       [0.22, 0.21, 0.12, 0.17, 0.15, 0.07],\n       [0.36, 0.34, 0.22, 0.3 , 0.27, 0.16],\n       [0.27, 0.27, 0.15, 0.22, 0.21, 0.11],\n       [0.22, 0.21, 0.11, 0.16, 0.15, 0.07],\n       [0.08, 0.07, 0.03, 0.04, 0.03, 0.01],\n       [0.26, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.25, 0.23, 0.13, 0.18, 0.16, 0.08],\n       [0.53, 0.52, 0.37, 0.49, 0.45, 0.32],\n       [0.1 , 0.11, 0.04, 0.08, 0.09, 0.03],\n       [0.26, 0.24, 0.14, 0.18, 0.16, 0.08],\n       [0.15, 0.16, 0.08, 0.12, 0.11, 0.05],\n       [0.62, 0.6 , 0.48, 0.54, 0.5 , 0.36],\n       [0.28, 0.27, 0.15, 0.22, 0.21, 0.1 ],\n       [0.63, 0.64, 0.48, 0.62, 0.6 , 0.43],\n       [0.25, 0.24, 0.13, 0.21, 0.2 , 0.1 ],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.34, 0.32, 0.2 , 0.27, 0.24, 0.14],\n       [0.24, 0.22, 0.13, 0.18, 0.16, 0.08],\n       [0.44, 0.44, 0.28, 0.4 , 0.4 , 0.23],\n       [0.44, 0.44, 0.29, 0.35, 0.32, 0.19],\n       [0.43, 0.43, 0.28, 0.39, 0.37, 0.22],\n       [0.28, 0.28, 0.16, 0.23, 0.24, 0.11],\n       [0.2 , 0.19, 0.1 , 0.14, 0.13, 0.06],\n       [0.2 , 0.19, 0.1 , 0.17, 0.16, 0.08],\n       [0.25, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.48, 0.47, 0.33, 0.46, 0.46, 0.29],\n       [0.28, 0.28, 0.16, 0.21, 0.18, 0.1 ],\n       [0.56, 0.55, 0.4 , 0.59, 0.55, 0.41],\n       [0.15, 0.14, 0.07, 0.11, 0.11, 0.05],\n       [0.78, 0.77, 0.68, 0.81, 0.76, 0.67],\n       [0.35, 0.35, 0.21, 0.31, 0.3 , 0.17],\n       [0.12, 0.12, 0.06, 0.1 , 0.1 , 0.04],\n       [0.19, 0.19, 0.1 , 0.14, 0.15, 0.06],\n       [0.6 , 0.6 , 0.45, 0.53, 0.53, 0.33],\n       [0.22, 0.22, 0.12, 0.18, 0.17, 0.08],\n       [0.16, 0.15, 0.08, 0.1 , 0.1 , 0.04],\n       [0.24, 0.23, 0.13, 0.2 , 0.18, 0.09],\n       [0.37, 0.35, 0.22, 0.33, 0.32, 0.17],\n       [0.21, 0.2 , 0.11, 0.16, 0.15, 0.07],\n       [0.24, 0.23, 0.12, 0.17, 0.16, 0.08],\n       [0.22, 0.21, 0.12, 0.19, 0.17, 0.09],\n       [0.42, 0.44, 0.26, 0.34, 0.34, 0.18],\n       [0.89, 0.9 , 0.79, 0.9 , 0.89, 0.75],\n       [0.38, 0.37, 0.24, 0.38, 0.35, 0.21],\n       [0.2 , 0.19, 0.1 , 0.15, 0.15, 0.07],\n       [0.26, 0.26, 0.15, 0.19, 0.19, 0.09],\n       [0.29, 0.29, 0.16, 0.22, 0.22, 0.1 ],\n       [0.33, 0.31, 0.19, 0.26, 0.23, 0.13],\n       [0.09, 0.09, 0.04, 0.07, 0.07, 0.03],\n       [0.12, 0.11, 0.06, 0.15, 0.13, 0.06],\n       [0.26, 0.25, 0.15, 0.21, 0.18, 0.1 ],\n       [0.3 , 0.29, 0.17, 0.22, 0.21, 0.11],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.45, 0.43, 0.29, 0.36, 0.33, 0.2 ],\n       [0.3 , 0.29, 0.17, 0.24, 0.22, 0.12],\n       [0.64, 0.62, 0.49, 0.58, 0.55, 0.39],\n       [0.63, 0.62, 0.46, 0.58, 0.55, 0.37],\n       [0.25, 0.24, 0.13, 0.23, 0.22, 0.11],\n       [0.7 , 0.67, 0.59, 0.81, 0.74, 0.73],\n       [0.71, 0.71, 0.57, 0.7 , 0.72, 0.5 ],\n       [0.44, 0.45, 0.3 , 0.41, 0.39, 0.24],\n       [0.39, 0.37, 0.24, 0.29, 0.27, 0.16],\n       [0.68, 0.67, 0.53, 0.53, 0.51, 0.33],\n       [0.65, 0.63, 0.51, 0.62, 0.58, 0.43],\n       [0.32, 0.3 , 0.18, 0.25, 0.24, 0.12],\n       [0.43, 0.43, 0.27, 0.32, 0.31, 0.17],\n       [0.17, 0.18, 0.08, 0.1 , 0.13, 0.04],\n       [0.31, 0.29, 0.18, 0.24, 0.23, 0.12],\n       [0.32, 0.31, 0.19, 0.24, 0.24, 0.12],\n       [0.19, 0.2 , 0.09, 0.19, 0.21, 0.08],\n       [0.2 , 0.2 , 0.1 , 0.17, 0.17, 0.07],\n       [0.19, 0.19, 0.1 , 0.15, 0.15, 0.06],\n       [0.24, 0.24, 0.13, 0.17, 0.18, 0.07],\n       [0.26, 0.25, 0.14, 0.22, 0.22, 0.1 ],\n       [0.3 , 0.29, 0.17, 0.22, 0.23, 0.11],\n       [0.36, 0.35, 0.22, 0.28, 0.26, 0.14],\n       [0.25, 0.24, 0.14, 0.18, 0.19, 0.08],\n       [0.33, 0.31, 0.19, 0.27, 0.25, 0.14],\n       [0.2 , 0.2 , 0.11, 0.15, 0.15, 0.07],\n       [0.59, 0.59, 0.44, 0.46, 0.46, 0.28],\n       [0.16, 0.15, 0.08, 0.12, 0.11, 0.05],\n       [0.08, 0.08, 0.04, 0.08, 0.07, 0.03],\n       [0.4 , 0.41, 0.26, 0.47, 0.46, 0.29],\n       [0.69, 0.7 , 0.54, 0.65, 0.61, 0.47],\n       [0.24, 0.24, 0.13, 0.2 , 0.19, 0.09],\n       [0.34, 0.32, 0.2 , 0.25, 0.23, 0.12],\n       [0.31, 0.31, 0.18, 0.24, 0.23, 0.12],\n       [0.28, 0.27, 0.15, 0.21, 0.2 , 0.1 ],\n       [0.19, 0.18, 0.1 , 0.17, 0.15, 0.08],\n       [0.23, 0.22, 0.12, 0.2 , 0.18, 0.09],\n       [0.52, 0.56, 0.36, 0.46, 0.49, 0.27],\n       [0.23, 0.22, 0.13, 0.21, 0.19, 0.1 ],\n       [0.28, 0.28, 0.16, 0.22, 0.23, 0.11],\n       [0.28, 0.27, 0.15, 0.21, 0.2 , 0.1 ],\n       [0.25, 0.24, 0.14, 0.19, 0.17, 0.09],\n       [0.19, 0.18, 0.1 , 0.16, 0.16, 0.07],\n       [0.43, 0.42, 0.28, 0.35, 0.33, 0.19],\n       [0.28, 0.27, 0.16, 0.23, 0.21, 0.11],\n       [0.52, 0.51, 0.36, 0.47, 0.44, 0.29],\n       [0.25, 0.24, 0.14, 0.22, 0.19, 0.1 ],\n       [0.21, 0.2 , 0.11, 0.18, 0.17, 0.08],\n       [0.19, 0.19, 0.1 , 0.16, 0.15, 0.07],\n       [0.11, 0.11, 0.05, 0.07, 0.08, 0.03],\n       [0.38, 0.37, 0.23, 0.31, 0.3 , 0.17],\n       [0.39, 0.37, 0.24, 0.33, 0.3 , 0.18],\n       [0.23, 0.23, 0.12, 0.18, 0.17, 0.08],\n       [0.11, 0.11, 0.05, 0.1 , 0.09, 0.04],\n       [0.4 , 0.41, 0.28, 0.54, 0.53, 0.38],\n       [0.27, 0.26, 0.15, 0.2 , 0.19, 0.09],\n       [0.2 , 0.19, 0.1 , 0.16, 0.14, 0.07],\n       [0.22, 0.21, 0.11, 0.18, 0.18, 0.08],\n       [0.36, 0.38, 0.22, 0.3 , 0.32, 0.15],\n       [0.22, 0.22, 0.11, 0.17, 0.16, 0.07],\n       [0.32, 0.32, 0.18, 0.26, 0.25, 0.13],\n       [0.13, 0.13, 0.06, 0.12, 0.11, 0.05],\n       [0.14, 0.13, 0.07, 0.11, 0.1 , 0.05],\n       [0.17, 0.16, 0.08, 0.15, 0.15, 0.06],\n       [0.18, 0.17, 0.09, 0.17, 0.17, 0.07],\n       [0.2 , 0.18, 0.1 , 0.13, 0.12, 0.06],\n       [0.27, 0.26, 0.15, 0.21, 0.19, 0.1 ],\n       [0.37, 0.4 , 0.23, 0.3 , 0.37, 0.16],\n       [0.26, 0.26, 0.14, 0.18, 0.2 , 0.08],\n       [0.62, 0.62, 0.47, 0.5 , 0.48, 0.32],\n       [0.56, 0.55, 0.41, 0.52, 0.47, 0.35],\n       [0.37, 0.35, 0.22, 0.3 , 0.26, 0.15],\n       [0.33, 0.33, 0.19, 0.32, 0.32, 0.17],\n       [0.28, 0.27, 0.16, 0.23, 0.22, 0.11],\n       [0.33, 0.32, 0.2 , 0.27, 0.25, 0.14],\n       [0.33, 0.31, 0.19, 0.27, 0.25, 0.14],\n       [0.33, 0.32, 0.2 , 0.25, 0.23, 0.12],\n       [0.19, 0.19, 0.1 , 0.16, 0.2 , 0.07],\n       [0.49, 0.47, 0.33, 0.44, 0.41, 0.27],\n       [0.32, 0.31, 0.19, 0.26, 0.24, 0.13],\n       [0.17, 0.16, 0.08, 0.11, 0.09, 0.04],\n       [0.52, 0.51, 0.36, 0.44, 0.41, 0.27],\n       [0.24, 0.23, 0.13, 0.18, 0.17, 0.08],\n       [0.51, 0.51, 0.36, 0.48, 0.47, 0.31],\n       [0.37, 0.36, 0.23, 0.3 , 0.28, 0.16],\n       [0.36, 0.35, 0.22, 0.3 , 0.29, 0.16],\n       [0.67, 0.65, 0.53, 0.63, 0.59, 0.45],\n       [0.23, 0.23, 0.12, 0.17, 0.16, 0.08],\n       [0.6 , 0.58, 0.44, 0.48, 0.45, 0.3 ],\n       [0.24, 0.23, 0.13, 0.18, 0.17, 0.08],\n       [0.36, 0.35, 0.21, 0.28, 0.26, 0.14],\n       [0.27, 0.25, 0.15, 0.23, 0.21, 0.11]])"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SPLIT INTO TRAIN/TEST SETS (0.8 / 0.2)\n",
    "trainset = scaled_data[:455, :]\n",
    "testset = scaled_data[455:, :]\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_train = trainset.copy()\n",
    "\n",
    "missing_data_train = fill_nan(trainset, trainset.size*0.2)\n",
    "\n",
    "full_data_test = testset.copy()\n",
    "\n",
    "missing_data_test = fill_nan(testset, testset.size*0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.  , 0.62, 0.5 , 0.61, 0.  , 0.44])"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.64, 0.62, 0.5 , 0.61, 0.54, 0.44])"
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.enc1 = nn.Linear(in_features=6, out_features=4)\n",
    "        self.enc2 = nn.Linear(in_features=4, out_features=3)\n",
    "        self.enc3 = nn.Linear(in_features=3, out_features=2)\n",
    "\n",
    "        self.dec1 = nn.Linear(in_features=2, out_features=3)\n",
    "        self.dec2 = nn.Linear(in_features=3, out_features=4)\n",
    "        self.dec3 = nn.Linear(in_features=4, out_features=6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.enc1(x))\n",
    "        x = F.leaky_relu(self.enc2(x))\n",
    "        x = F.leaky_relu(self.enc3(x))\n",
    "        x = F.leaky_relu(self.dec1(x))\n",
    "        x = F.leaky_relu(self.dec2(x))\n",
    "        x = self.dec3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A SEED FOR CONSISTENT WEIGHT INITIALIZATIONS - FOR TESTING PURPOSES\n",
    "random.seed(1)\n",
    "torch.manual_seed(random.randint(1, 10))\n",
    "net = Autoencoder().double()\n",
    "#net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = -1\n",
    "NUM_FEATURES = 6\n",
    "BATCH_SIZE_TEST = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([455, 6])"
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = torch.from_numpy(missing_data_train)\n",
    "#x_train = x_train.to(device)\n",
    "x_train = x_train.view(BATCH_SIZE, NUM_FEATURES)\n",
    "\n",
    "y_train = torch.from_numpy(full_data_train)\n",
    "#y_train = y_train.to(device)\n",
    "y_train = y_train.view(BATCH_SIZE, NUM_FEATURES)\n",
    "\n",
    "x_test = torch.from_numpy(missing_data_test)\n",
    "#x_test = x_test.to(device)\n",
    "x_test = x_test.view(BATCH_SIZE_TEST, NUM_FEATURES)\n",
    "\n",
    "y_test = torch.from_numpy(full_data_test)\n",
    "#y_test = y_test.to(device)\n",
    "y_test = y_test.view(BATCH_SIZE_TEST, NUM_FEATURES)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    train_loss = []\n",
    "    torch.set_printoptions(precision=2, sci_mode=True)\n",
    "    np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # running_loss: LOSS OF THE PREDICTED MISSING VALUE ONLY\n",
    "        # overall_loss: LOSS OF ALL RECONSTRUCTED VALUES\n",
    "\n",
    "        running_loss = 0.0\n",
    "        overall_loss = 0.0\n",
    "        count = 0\n",
    "        for missing_data, full_data in zip(x_train, y_train):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(missing_data.double())\n",
    "\n",
    "            # LEARN FROM LOSS OF ALL RECONSTRUCTED VALUES\n",
    "            loss = criterion(outputs, full_data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            overall_loss += loss.item()\n",
    "            \n",
    "            # COMPUTE LOSS OF PREDICTED MISSING VALUE\n",
    "            if NAN in missing_data:\n",
    "                for index in range(len(missing_data)):\n",
    "                    if missing_data[index] == NAN:\n",
    "                        predicted_loss = criterion(outputs[index], full_data[index])\n",
    "                        running_loss += predicted_loss.item()\n",
    "                        count += 1\n",
    "            \n",
    "            # PRINT ALL VALUES ON LAST EPOCH FOR TESTING PURPOSES\n",
    "            if epoch == NUM_EPOCHS-1:\n",
    "                if missing_data.detach().numpy().all() == full_data.detach().numpy().all():\n",
    "                    print(\"Input: \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                    print(\"Target: \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                    print(\"Outputs: \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "                else:\n",
    "                    print(\"Input (missing): \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                    print(\"Target (missing): \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                    print(\"Outputs (missing): \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "        \n",
    "      #  loss = running_loss / count\n",
    "        overall_loss = overall_loss / len(x_train)\n",
    "        train_loss.append(loss)\n",
    "\n",
    "        print('Epoch {} of {}, Train Loss: {:.5f}, Overall: {:.5f}'\n",
    "             .format(epoch+1, NUM_EPOCHS, loss, overall_loss))\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(net):\n",
    "\n",
    "    net.eval()\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_loss = []\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for missing_data, full_data in zip(x_test, y_test):\n",
    "            outputs = net(missing_data.double())\n",
    "            if NAN in missing_data:\n",
    "                for index in range(len(missing_data)):\n",
    "                    if missing_data[index] == NAN:\n",
    "                        predicted_loss = criterion(outputs[index], full_data[index])\n",
    "                        running_loss += predicted_loss.item()\n",
    "                        count += 1\n",
    "            \n",
    "            if missing_data.detach().numpy().all() == full_data.detach().numpy().all():\n",
    "                print(\"Input: \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                print(\"Target: \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                print(\"Outputs: \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "            else:\n",
    "                print(\"Input (missing): \", scaler.inverse_transform(missing_data.reshape(-1,6)))\n",
    "                print(\"Target (missing): \", scaler.inverse_transform(full_data.reshape(-1,6)))\n",
    "                print(\"Outputs (missing): \", scaler.inverse_transform(outputs.reshape(-1,6).detach().numpy()))\n",
    "\n",
    "        loss = running_loss / count\n",
    "        test_loss.append(loss)\n",
    "        print('Test Loss: {:.3f}'.format(loss))\n",
    "\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "17.36 119.4  915.3 ]]\nOutputs:  [[  15.94  104.38  843.47   18.67  123.51 1174.54]]\nInput (missing):  [[   6.98  174.2  2010.     33.13  229.3  3234.  ]]\nTarget (missing):  [[  25.73  174.2  2010.     33.13  229.3  3234.  ]]\nOutputs (missing):  [[  24.02  157.8  1588.78   30.1   200.08 2454.34]]\nInput (missing):  [[  15.08   98.    143.5    18.51   50.41 1050.  ]]\nTarget (missing):  [[  15.08   98.    716.6    18.51  121.2  1050.  ]]\nOutputs (missing):  [[ 13.24  85.47 568.99  14.91  97.27 735.98]]\nInput (missing):  [[  6.98  71.24 384.6   12.12  79.62 453.5 ]]\nTarget (missing):  [[ 11.14  71.24 384.6   12.12  79.62 453.5 ]]\nOutputs (missing):  [[ 11.45  73.02 388.39  12.43  79.99 447.55]]\nInput (missing):  [[ 12.56  81.92 143.5   13.37  89.02 547.4 ]]\nTarget (missing):  [[ 12.56  81.92 485.8   13.37  89.02 547.4 ]]\nOutputs (missing):  [[ 12.04  77.08 447.25  13.25  85.74 543.58]]\nInput (missing):  [[ 13.05  85.09 512.    14.19  50.41 591.2 ]]\nTarget (missing):  [[ 13.05  85.09 512.    14.19  94.22 591.2 ]]\nOutputs (missing):  [[ 12.45  79.95 488.8   13.83  89.8  611.46]]\nInput (missing):  [[ 13.87  88.52 593.7   15.11  50.41 694.4 ]]\nTarget (missing):  [[ 13.87  88.52 593.7   15.11  96.74 694.4 ]]\nOutputs (missing):  [[ 13.09  84.4  553.06  14.72  96.06 715.67]]\nInput (missing):  [[  8.88  43.79 241.     9.98  65.27 302.  ]]\nTarget (missing):  [[  8.88  56.74 241.     9.98  65.27 302.  ]]\nOutputs (missing):  [[ 10.05  63.24 246.18  10.49  66.56 222.32]]\nInput (missing):  [[  9.44  43.79 278.6    7.93  75.79 439.6 ]]\nTarget (missing):  [[  9.44  59.82 278.6   12.02  75.79 439.6 ]]\nOutputs (missing):  [[ 10.53  66.57 294.49  11.16  71.25 300.66]]\nInput (missing):  [[  6.98  79.42 491.9   13.72  50.41 585.7 ]]\nTarget (missing):  [[ 12.54  79.42 491.9   13.72  86.82 585.7 ]]\nOutputs (missing):  [[ 11.79  75.36 422.16  12.93  83.6  507.35]]\nInput (missing):  [[ 13.3   85.24 143.5   14.2   92.94 185.2 ]]\nTarget (missing):  [[ 13.3   85.24 546.1   14.2   92.94 621.2 ]]\nOutputs (missing):  [[ 11.64  74.32 407.29  12.73  82.21 484.49]]\nInput:  [[ 12.76  81.87 496.6   13.75  87.82 579.7 ]]\nTarget:  [[ 12.76  81.87 496.6   13.75  87.82 579.7 ]]\nOutputs:  [[ 13.1   84.48 554.86  14.77  96.46 722.76]]\nInput:  [[  16.5   106.6   838.1    18.13  117.2  1009.  ]]\nTarget:  [[  16.5   106.6   838.1    18.13  117.2  1009.  ]]\nOutputs:  [[  16.56  108.51  903.     19.59  130.05 1284.14]]\nInput (missing):  [[ 13.4   85.48 552.4   14.73  50.41 185.2 ]]\nTarget (missing):  [[ 13.4   85.48 552.4   14.73  93.76 663.5 ]]\nOutputs (missing):  [[ 11.92  76.24 435.65  13.12  84.98 530.94]]\nInput (missing):  [[  20.44  133.8  1293.     24.31  161.2   185.2 ]]\nTarget (missing):  [[  20.44  133.8  1293.     24.31  161.2  1780.  ]]\nOutputs (missing):  [[  18.16  119.65 1064.2    21.82  145.6  1543.86]]\nInput (missing):  [[   6.98  133.7  1234.     24.19  160.   1671.  ]]\nTarget (missing):  [[  20.2   133.7  1234.     24.19  160.   1671.  ]]\nOutputs (missing):  [[  19.78  130.24 1211.65   24.1   160.84 1798.79]]\nInput (missing):  [[ 12.21  43.79 143.5   14.29  93.85 624.6 ]]\nTarget (missing):  [[ 12.21  78.31 458.4   14.29  93.85 624.6 ]]\nOutputs (missing):  [[ 11.88  75.95 431.69  13.06  84.51 522.44]]\nInput:  [[  21.71  140.9  1546.     30.75  199.5  3143.  ]]\nTarget:  [[  21.71  140.9  1546.     30.75  199.5  3143.  ]]\nOutputs:  [[  24.4   159.96 1618.77   30.67  204.05 2520.85]]\nInput:  [[  22.01  147.2  1482.     27.66  195.   2227.  ]]\nTarget:  [[  22.01  147.2  1482.     27.66  195.   2227.  ]]\nOutputs:  [[  23.61  155.1  1555.08   29.56  196.89 2404.24]]\nInput (missing):  [[  16.35  109.    143.5     7.93   50.41 1165.  ]]\nTarget (missing):  [[  16.35  109.    840.4    19.38  129.3  1165.  ]]\nOutputs (missing):  [[ 13.38  86.35 583.66  15.16  99.13 769.  ]]\nInput (missing):  [[ 15.19  97.65 711.8   16.2  104.5  185.2 ]]\nTarget (missing):  [[ 15.19  97.65 711.8   16.2  104.5  819.1 ]]\nOutputs (missing):  [[ 14.15  91.76 662.51  16.24 106.74 897.2 ]]\nInput (missing):  [[  21.37   43.79 1386.     22.69   50.41  185.2 ]]\nTarget (missing):  [[  21.37  141.3  1386.     22.69  152.1  1535.  ]]\nOutputs (missing):  [[  14.81   96.35  729.55   17.17  113.19 1005.72]]\nInput (missing):  [[  20.64  134.8  1335.      7.93  166.8  1946.  ]]\nTarget (missing):  [[  20.64  134.8  1335.     25.37  166.8  1946.  ]]\nOutputs (missing):  [[  20.89  137.58 1317.08   25.71  171.62 1985.11]]\nInput (missing):  [[  6.98  87.84 143.5   14.84  50.41 185.2 ]]\nTarget (missing):  [[ 13.69  87.84 579.1   14.84  99.16 670.6 ]]\nOutputs (missing):  [[ 10.96  69.57 342.65  11.78  75.65 378.27]]\nInput (missing):  [[ 16.17  43.79 143.5   16.97 113.1  185.2 ]]\nTarget (missing):  [[ 16.17 106.3  788.5   16.97 113.1  861.5 ]]\nOutputs (missing):  [[ 12.45  79.97 494.13  13.86  90.17 621.51]]\nInput (missing):  [[ 10.57  70.15 338.3    7.93  76.51 185.2 ]]\nTarget (missing):  [[ 10.57  70.15 338.3   10.85  76.51 351.9 ]]\nOutputs (missing):  [[ 11.61  74.1  409.46  12.66  81.89 482.7 ]]\nInput (missing):  [[ 13.46  43.79 562.1    7.93  97.11 680.6 ]]\nTarget (missing):  [[ 13.46  85.89 562.1   14.69  97.11 680.6 ]]\nOutputs (missing):  [[ 13.46  87.02 597.12  15.24  99.89 783.99]]\nInput (missing):  [[ 13.66  88.27 580.6    7.93  97.96 657.  ]]\nTarget (missing):  [[ 13.66  88.27 580.6   14.54  97.96 657.  ]]\nOutputs (missing):  [[ 14.48  94.17 701.11  16.66 109.85 950.28]]\nInput (missing):  [[ 11.08  43.79 361.6   13.24  50.41 508.1 ]]\nTarget (missing):  [[ 11.08  73.3  361.6   13.24  91.76 508.1 ]]\nOutputs (missing):  [[ 12.09  77.55 460.18  13.31  86.52 558.79]]\nInput (missing):  [[ 11.27  73.16 386.3    7.93  84.93 476.1 ]]\nTarget (missing):  [[ 11.27  73.16 386.3   12.84  84.93 476.1 ]]\nOutputs (missing):  [[ 12.98  83.77 550.33  14.54  95.2  703.09]]\nInput (missing):  [[ 11.04  70.67 372.7   12.09  79.73 185.2 ]]\nTarget (missing):  [[ 11.04  70.67 372.7   12.09  79.73 447.1 ]]\nOutputs (missing):  [[ 12.57  80.88 508.26  13.95  91.14 633.83]]\nInput:  [[ 12.05  78.75 447.8   12.57  87.36 488.4 ]]\nTarget:  [[ 12.05  78.75 447.8   12.57  87.36 488.4 ]]\nOutputs:  [[ 13.86  89.9  638.97  15.75 103.75 844.1 ]]\nInput:  [[ 12.39  80.64 462.9   14.18  95.23 600.5 ]]\nTarget:  [[ 12.39  80.64 462.9   14.18  95.23 600.5 ]]\nOutputs:  [[ 14.49  94.32 702.94  16.63 109.93 946.34]]\nInput:  [[ 13.28  85.79 541.8   14.24  96.59 623.7 ]]\nTarget:  [[ 13.28  85.79 541.8   14.24  96.59 623.7 ]]\nOutputs:  [[  14.93   97.37  746.83   17.24  114.2  1016.36]]\nInput (missing):  [[  6.98  93.97 664.7   15.79 102.2  758.2 ]]\nTarget (missing):  [[ 14.6   93.97 664.7   15.79 102.2  758.2 ]]\nOutputs (missing):  [[  15.25   99.66  779.51   17.68  117.39 1068.01]]\nInput:  [[ 12.21  78.78 462.    13.13  87.65 529.9 ]]\nTarget:  [[ 12.21  78.78 462.    13.13  87.65 529.9 ]]\nOutputs:  [[ 13.91  90.3  643.21  15.8  104.27 846.11]]\nInput (missing):  [[  6.98  88.37 596.6    7.93  99.66 745.3 ]]\nTarget (missing):  [[ 13.88  88.37 596.6   15.51  99.66 745.3 ]]\nOutputs (missing):  [[ 14.08  91.52 660.26  16.03 105.94 872.19]]\nInput (missing):  [[  6.98  73.38 392.     7.93  79.73 450.  ]]\nTarget (missing):  [[ 11.27  73.38 392.    12.04  79.73 450.  ]]\nOutputs (missing):  [[ 12.21  78.5  470.6   13.41  87.68 563.92]]\nInput:  [[  19.55  128.9  1174.     20.82  142.   1313.  ]]\nTarget:  [[  19.55  128.9  1174.     20.82  142.   1313.  ]]\nOutputs:  [[  20.18  133.29 1258.72   24.59  164.88 1858.99]]\nInput (missing):  [[ 10.26  43.79 321.6    7.93  73.23 394.5 ]]\nTarget (missing):  [[ 10.26  65.75 321.6   11.38  73.23 394.5 ]]\nOutputs (missing):  [[ 11.38  72.73 385.67  12.23  79.5  422.85]]\nInput (missing):  [[  8.73  43.79 234.3   10.17  50.41 185.2 ]]\nTarget (missing):  [[  8.73  55.27 234.3   10.17  64.01 317.  ]]\nOutputs (missing):  [[ 10.26  64.96 272.36  10.66  68.58 237.62]]\nInput (missing):  [[  15.49  102.4   744.7    21.2    50.41 1359.  ]]\nTarget (missing):  [[  15.49  102.4   744.7    21.2   142.1  1359.  ]]\nOutputs (missing):  [[  16.55  108.75  908.3    19.43  129.8  1265.07]]\nInput (missing):  [[  21.61  144.4  1407.      7.93  172.   2081.  ]]\nTarget (missing):  [[  21.61  144.4  1407.     26.23  172.   2081.  ]]\nOutputs (missing):  [[  21.56  142.08 1377.25   26.52  177.58 2067.32]]\nInput:  [[ 12.1   78.07 446.2   13.56  88.33 559.5 ]]\nTarget:  [[ 12.1   78.07 446.2   13.56  88.33 559.5 ]]\nOutputs:  [[ 13.3   86.16 579.38  14.9   98.23 732.82]]\nInput (missing):  [[  6.98  89.75 609.1    7.93  50.41 185.2 ]]\nTarget (missing):  [[ 14.06  89.75 609.1   14.92  96.42 684.5 ]]\nOutputs (missing):  [[ 11.39  72.89 386.22  12.24  79.68 420.39]]\nInput (missing):  [[  6.98  43.79 558.1   14.8   97.33 675.2 ]]\nTarget (missing):  [[ 13.51  88.1  558.1   14.8   97.33 675.2 ]]\nOutputs (missing):  [[ 12.83  82.89 531.24  14.25  93.65 654.51]]\nInput (missing):  [[  6.98  83.05 508.3   13.74  90.72 591.  ]]\nTarget (missing):  [[ 12.8   83.05 508.3   13.74  90.72 591.  ]]\nOutputs (missing):  [[ 13.03  84.3  551.27  14.53  95.6  686.61]]\nInput (missing):  [[  6.98  43.79 378.2   12.68  80.79 496.7 ]]\nTarget (missing):  [[ 11.06  70.31 378.2   12.68  80.79 496.7 ]]\nOutputs (missing): [[ 11.47  73.47 393.42  12.35  80.43 430.97]]\nInput (missing):  [[ 11.8   75.26 431.9    7.93  50.41 562.  ]]\nTarget (missing):  [[ 11.8   75.26 431.9   13.45  86.   562.  ]]\nOutputs (missing):  [[ 11.77  75.54 423.13  12.77  83.32 479.02]]\nInput:  [[  17.91  124.4   994.     20.8   149.6  1304.  ]]\nTarget:  [[  17.91  124.4   994.     20.8   149.6  1304.  ]]\nOutputs:  [[  18.88  124.68 1133.26   22.71  152.27 1637.67]]\nInput (missing):  [[  6.98  76.14 442.7   13.8   87.64 589.5 ]]\nTarget (missing):  [[ 11.93  76.14 442.7   13.8   87.64 589.5 ]]\nOutputs (missing):  [[ 12.55  80.99 501.53  13.86  90.93 605.7 ]]\nInput (missing):  [[ 12.96  84.18 525.2   14.13  50.41 185.2 ]]\nTarget (missing):  [[ 12.96  84.18 525.2   14.13  96.31 621.9 ]]\nOutputs (missing):  [[ 11.91  76.52 435.93  12.96  84.69 499.84]]\nInput (missing):  [[  6.98  83.18 507.6   13.86  89.69 580.9 ]]\nTarget (missing):  [[ 12.94  83.18 507.6   13.86  89.69 580.9 ]]\nOutputs (missing):  [[ 12.8   82.76 526.05  14.21  93.4  645.41]]\nInput (missing):  [[ 12.34  78.29 143.5   13.18  84.11 533.1 ]]\nTarget (missing):  [[ 12.34  78.29 469.1   13.18  84.11 533.1 ]]\nOutputs (missing):  [[ 12.05  77.53 449.54  13.16  86.1  521.73]]\nInput (missing):  [[ 10.94  70.39 370.    12.4   82.76 185.2 ]]\nTarget (missing):  [[ 10.94  70.39 370.    12.4   82.76 472.4 ]]\nOutputs (missing):  [[ 11.49  73.69 393.41  12.39  80.73 430.9 ]]\nInput (missing):  [[  6.98 104.3  800.    17.71  50.41 947.9 ]]\nTarget (missing):  [[ 16.14 104.3  800.    17.71 115.9  947.9 ]]\nOutputs (missing):  [[ 14.16  92.25 662.62  16.1  106.65 865.84]]\nInput (missing):  [[ 12.85  43.79 514.5    7.93  91.63 645.8 ]]\nTarget (missing):  [[ 12.85  82.63 514.5   14.4   91.63 645.8 ]]\nOutputs (missing):  [[ 12.23  78.85 467.63  13.42  87.92 550.55]]\nInput (missing):  [[  17.99  117.8   991.7    21.08   50.41 1349.  ]]\nTarget (missing):  [[  17.99  117.8   991.7    21.08  138.1  1349.  ]]\nOutputs (missing):  [[  16.95  111.69  944.28   19.99  133.78 1320.3 ]]\nInput (missing):  [[ 12.27  43.79 466.1   14.1   50.41 610.2 ]]\nTarget (missing):  [[ 12.27  78.41 466.1   14.1   89.   610.2 ]]\nOutputs (missing):  [[ 11.76  75.57 419.2   12.75  83.3  471.83]]\nInput (missing):  [[ 11.36  72.49 399.8   13.05  50.41 521.3 ]]\nTarget (missing):  [[ 11.36  72.49 399.8   13.05  85.07 521.3 ]]\nOutputs (missing):  [[ 11.81  75.88 423.47  12.82  83.72 478.73]]\nInput (missing):  [[ 11.04  70.92 373.2    7.93  79.93 471.4 ]]\nTarget (missing):  [[ 11.04  70.92 373.2   12.41  79.93 471.4 ]]\nOutputs (missing):  [[ 11.73  75.31 414.89  12.71  82.93 465.11]]\nInput (missing):  [[  6.98  59.75 268.8    9.96  66.61 301.  ]]\nTarget (missing):  [[  9.4   59.75 268.8    9.96  66.61 301.  ]]\nOutputs (missing):  [[ 10.49  66.7  289.78  10.99  70.92 263.54]]\nInput (missing):  [[ 14.99  97.53 693.7   16.76  50.41 867.1 ]]\nTarget (missing):  [[ 14.99  97.53 693.7   16.76 110.2  867.1 ]]\nOutputs (missing):  [[ 14.33  93.48 678.56  16.35 108.33 891.81]]\nInput (missing):  [[ 15.13  96.71 719.5   17.26 110.1  185.2 ]]\nTarget (missing):  [[ 15.13  96.71 719.5   17.26 110.1  931.4 ]]\nOutputs (missing):  [[ 14.15  92.22 660.22  16.11 106.59 862.65]]\nInput:  [[ 11.89  76.39 433.8   13.05  85.09 522.9 ]]\nTarget:  [[ 11.89  76.39 433.8   13.05  85.09 522.9 ]]\nOutputs:  [[ 12.7   82.09 513.05  14.08  92.44 625.32]]\nInput (missing):  [[  9.4   43.79 143.5   10.85  68.73 359.4 ]]\nTarget (missing):  [[  9.4   59.6  271.2   10.85  68.73 359.4 ]]\nOutputs (missing):  [[ 10.37  65.82 276.93  10.83  69.74 244.59]]\nInput (missing):  [[  6.98 102.9  803.1   23.17 157.1  185.2 ]]\nTarget (missing):  [[  15.5   102.9   803.1    23.17  157.1  1748.  ]]\nOutputs (missing):  [[  15.11   98.86  756.51   17.45  115.87 1019.19]]\nInput (missing):  [[ 12.7   80.88 495.     7.93  50.41 566.9 ]]\nTarget (missing):  [[ 12.7   80.88 495.    13.65  88.12 566.9 ]]\nOutputs (missing):  [[ 12.05  77.56 447.54  13.2   86.27 523.38]]\nInput:  [[ 11.16  70.95 380.3   12.36  79.26 458.  ]]\nTarget:  [[ 11.16  70.95 380.3   12.36  79.26 458.  ]]\nOutputs:  [[ 12.16  78.31 458.52  13.37  87.42 543.46]]\nInput:  [[ 11.57  74.2  409.7   13.07  86.43 520.5 ]]\nTarget:  [[ 11.57  74.2  409.7   13.07  86.43 520.5 ]]\nOutputs:  [[ 12.66  81.8  509.29  14.08  92.38 627.6 ]]\nInput (missing):  [[ 14.69  98.22 656.1   16.46 114.1  185.2 ]]\nTarget (missing):  [[ 14.69  98.22 656.1   16.46 114.1  809.2 ]]\nOutputs (missing):  [[ 14.1   91.81 654.71  16.11 106.47 864.4 ]]\nInput (missing):  [[ 11.61  75.46 143.5   12.64  81.93 475.7 ]]\nTarget (missing):  [[ 11.61  75.46 408.2   12.64  81.93 475.7 ]]\nOutputs (missing):  [[ 11.85  76.13 427.05  12.98  84.66 498.94]]\nInput:  [[ 13.66  89.46 575.3   15.14 101.4  708.8 ]]\nTarget:  [[ 13.66  89.46 575.3   15.14 101.4  708.8 ]]\nOutputs:  [[ 14.39  93.81 683.43  16.53 109.42 913.99]]\nInput:  [[  9.74  61.93 289.7   11.21  71.79 380.9 ]]\nTarget:  [[  9.74  61.93 289.7   11.21  71.79 380.9 ]]\nOutputs:  [[ 11.27  72.08 367.98  12.19  79.15 406.62]]\nInput:  [[ 10.03  63.19 307.3   11.11  69.92 376.3 ]]\nTarget:  [[ 10.03  63.19 307.3   11.11  69.92 376.3 ]]\nOutputs:  [[ 11.29  72.23 369.97  12.23  79.42 411.36]]\nInput (missing):  [[ 10.48  67.49 333.6    7.93  81.41 440.4 ]]\nTarget (missing):  [[ 10.48  67.49 333.6   12.13  81.41 440.4 ]]\nOutputs (missing):  [[ 11.52  73.86 393.63  12.57  81.77 451.08]]\nInput (missing):  [[ 10.8   43.79 143.5   12.76  83.69 489.5 ]]\nTarget (missing):  [[ 10.8   68.79 359.9   12.76  83.69 489.5 ]]\nOutputs (missing):  [[ 11.17  71.37 357.76  12.08  78.39 394.92]]\nInput (missing):  [[ 11.13  70.47 381.1    7.93  74.35 421.1 ]]\nTarget (missing):  [[ 11.13  70.47 381.1   11.68  74.35 421.1 ]]\nOutputs (missing):  [[ 11.52  73.83 393.56  12.59  81.92 454.5 ]]\nInput (missing):  [[  6.98  80.98 501.3   13.82  88.87 586.8 ]]\nTarget (missing):  [[ 12.72  80.98 501.3   13.82  88.87 586.8 ]]\nOutputs (missing):  [[ 12.7   82.09 513.71  14.25  93.54 649.7 ]]\nInput:  [[ 14.9  102.1  685.    16.35 125.4  832.7 ]]\nTarget:  [[ 14.9  102.1  685.    16.35 125.4  832.7 ]]\nOutputs:  [[  15.63  102.45  809.08   18.33  122.   1127.07]]\nInput (missing):  [[ 12.4   81.47 143.5   12.88  89.61 515.8 ]]\nTarget (missing):  [[ 12.4   81.47 467.8   12.88  89.61 515.8 ]]\nOutputs (missing):  [[ 12.06  77.64 449.26  13.38  87.46 548.02]]\nInput (missing):  [[   6.98  133.8  1250.     22.03   50.41  185.2 ]]\nTarget (missing):  [[  20.18  133.8  1250.     22.03  146.   1479.  ]]\nOutputs (missing):  [[ 14.55  94.98 700.5   16.85 111.71 953.39]]\nInput (missing):  [[  18.82   43.79 1110.      7.93  145.3  1603.  ]]\nTarget (missing):  [[  18.82  123.7  1110.     22.66  145.3  1603.  ]]\nOutputs (missing):  [[  17.1   112.78  958.53   20.39  136.53 1368.35]]\nInput (missing):  [[ 14.86  94.89 673.7    7.93  50.41 777.5 ]]\nTarget (missing):  [[ 14.86  94.89 673.7   16.31 102.3  777.5 ]]\nOutputs (missing):  [[ 13.25  85.97 569.86  15.03  99.12 741.7 ]]\nInput (missing): [[ 13.98  43.79 599.5   17.04 113.9  869.3 ]]\nTarget (missing):  [[ 13.98  91.12 599.5   17.04 113.9  869.3 ]]\nOutputs (missing):  [[ 14.24  92.82 669.23  16.39 108.64 900.82]]\nInput (missing):  [[ 12.87  82.67 143.5   14.45  95.14 626.9 ]]\nTarget (missing):  [[ 12.87  82.67 509.2   14.45  95.14 626.9 ]]\nOutputs (missing):  [[ 12.75  82.48 519.12  14.32  94.2  658.57]]\nInput (missing):  [[ 14.04  89.78 143.5    7.93 101.2  750.  ]]\nTarget (missing):  [[ 14.04  89.78 611.2   15.66 101.2  750.  ]]\nOutputs (missing):  [[ 12.85  83.14 528.5   14.45  95.11 673.16]]\nInput (missing):  [[ 13.85  88.68 143.5   15.63 100.9  185.2 ]]\nTarget (missing):  [[ 13.85  88.68 592.6   15.63 100.9  749.1 ]]\nOutputs (missing):  [[ 12.36  79.75 479.18  13.77  90.37 593.17]]\nInput (missing):  [[  6.98  89.59 606.5   14.91  96.53 185.2 ]]\nTarget (missing):  [[ 14.02  89.59 606.5   14.91  96.53 688.9 ]]\nOutputs (missing):  [[ 12.8   82.82 523.55  14.38  94.63 663.93]]\nInput:  [[ 10.97  71.73 371.5   12.36  90.14 476.4 ]]\nTarget:  [[ 10.97  71.73 371.5   12.36  90.14 476.4 ]]\nOutputs:  [[ 12.57  81.19 499.8   14.05  92.32 624.8 ]]\nInput (missing):  [[  17.27   43.79  928.8    20.38  132.8  1284.  ]]\nTarget (missing):  [[  17.27  112.4   928.8    20.38  132.8  1284.  ]]\nOutputs (missing):  [[  17.2   113.5   967.77   20.5   137.37 1377.7 ]]\nInput (missing):  [[ 13.78  88.37 585.9    7.93  97.9  185.2 ]]\nTarget (missing):  [[ 13.78  88.37 585.9   15.27  97.9  706.6 ]]\nOutputs (missing):  [[ 12.93  83.68 535.51  14.54  95.78 681.07]]\nInput:  [[ 10.57  66.82 340.9   10.94  69.35 366.3 ]]\nTarget:  [[ 10.57  66.82 340.9   10.94  69.35 366.3 ]]\nOutputs:  [[ 11.73  75.36 414.83  12.87  84.16 485.89]]\nInput (missing):  [[  18.03  117.5   143.5    20.38   50.41 1292.  ]]\nTarget (missing):  [[  18.03  117.5   990.     20.38  133.3  1292.  ]]\nOutputs (missing):  [[  15.36  100.61  780.5    17.92  119.35 1074.06]]\nInput (missing):  [[ 11.99  77.61 441.3   12.98  84.48 185.2 ]]\nTarget (missing):  [[ 11.99  77.61 441.3   12.98  84.48 513.9 ]]\nOutputs (missing):  [[ 12.5   80.64 491.14  13.92  91.45 607.13]]\nInput (missing):  [[  17.75  117.3   981.6    21.53   50.41 1437.  ]]\nTarget (missing):  [[  17.75  117.3   981.6    21.53  145.4  1437.  ]]\nOutputs (missing):  [[  17.92  118.44 1038.47   21.47  144.1  1487.48]]\nInput (missing):  [[ 14.8   95.88 143.5   16.43 105.9  829.5 ]]\nTarget (missing):  [[ 14.8   95.88 674.8   16.43 105.9  829.5 ]]\nOutputs (missing):  [[ 14.51  94.66 693.77  16.71 110.9  931.76]]\nInput (missing):  [[ 14.53  43.79 659.7    7.93 108.1  830.5 ]]\nTarget (missing):  [[ 14.53  94.25 659.7   16.3  108.1  830.5 ]]\nOutputs (missing):  [[ 14.04  91.36 645.73  16.05 106.25 853.44]]\nInput (missing):  [[  21.1   138.1  1384.     25.68  168.2   185.2 ]]\nTarget (missing):  [[  21.1   138.1  1384.     25.68  168.2  2022.  ]]\nOutputs (missing):  [[  19.57  129.22 1186.99   23.77  159.46 1742.79]]\nInput (missing):  [[  6.98  76.83 432.    12.79  83.51 507.2 ]]\nTarget (missing):  [[ 11.87  76.83 432.    12.79  83.51 507.2 ]]\nOutputs (missing):  [[ 12.78  82.58 518.13  14.28  93.89 646.14]]\nInput (missing): [[  19.59  127.7   143.5    21.44  139.8  1421.  ]]\nTarget (missing):  [[  19.59  127.7  1191.     21.44  139.8  1421.  ]]\nOutputs (missing):  [[  18.1   119.65 1054.62   21.68  145.51 1509.26]]\nInput:  [[ 12.    76.77 442.5   13.09  85.07 523.7 ]]\nTarget:  [[ 12.    76.77 442.5   13.09  85.07 523.7 ]]\nOutputs:  [[ 13.45  87.19 584.74  15.19 100.16 750.87]]\nInput (missing):  [[  6.98  93.86 143.5    7.93 103.1  749.9 ]]\nTarget (missing):  [[ 14.53  93.86 644.2   15.8  103.1  749.9 ]]\nOutputs (missing):  [[ 12.92  83.52 531.57  14.44  94.95 663.67]]\nInput (missing):  [[ 12.62  80.62 143.5   14.34  91.62 633.5 ]]\nTarget (missing):  [[ 12.62  80.62 492.9   14.34  91.62 633.5 ]]\nOutputs (missing):  [[ 13.34  86.45 573.96  15.02  98.94 730.26]]\nEpoch 100 of 100, Train Loss: 0.00108, Overall: 0.00463\n"
    }
   ],
   "source": [
    "# TRAIN THE NEURAL NETWORK\n",
    "results = train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1748cd2bcf8>]"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 391.190625 248.518125\" width=\"391.190625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 391.190625 248.518125 \r\nL 391.190625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 49.190625 224.64 \r\nL 383.990625 224.64 \r\nL 383.990625 7.2 \r\nL 49.190625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"ma63d9f4777\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.408807\" xlink:href=\"#ma63d9f4777\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(61.227557 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"126.523835\" xlink:href=\"#ma63d9f4777\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(120.161335 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"188.638862\" xlink:href=\"#ma63d9f4777\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(182.276362 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.75389\" xlink:href=\"#ma63d9f4777\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <defs>\r\n       <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n      </defs>\r\n      <g transform=\"translate(244.39139 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"312.868918\" xlink:href=\"#ma63d9f4777\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <defs>\r\n       <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n      </defs>\r\n      <g transform=\"translate(306.506418 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"374.983946\" xlink:href=\"#ma63d9f4777\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(368.621446 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m7185164301\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#m7185164301\" y=\"217.418722\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.0000 -->\r\n      <defs>\r\n       <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n      </defs>\r\n      <g transform=\"translate(7.2 221.217941)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#m7185164301\" y=\"179.99369\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.0005 -->\r\n      <g transform=\"translate(7.2 183.792909)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#m7185164301\" y=\"142.568658\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.0010 -->\r\n      <g transform=\"translate(7.2 146.367877)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#m7185164301\" y=\"105.143626\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.0015 -->\r\n      <g transform=\"translate(7.2 108.942845)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#m7185164301\" y=\"67.718594\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.0020 -->\r\n      <g transform=\"translate(7.2 71.517812)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"49.190625\" xlink:href=\"#m7185164301\" y=\"30.293561\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.0025 -->\r\n      <g transform=\"translate(7.2 34.09278)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#pbef40aa8b4)\" d=\"M 64.408807 41.626001 \r\nL 70.62031 17.083636 \r\nL 76.831812 68.0588 \r\nL 83.043315 152.144698 \r\nL 89.254818 214.756364 \r\nL 95.466321 213.350526 \r\nL 101.677824 213.097092 \r\nL 107.889326 212.84683 \r\nL 114.100829 212.949194 \r\nL 120.312332 212.875432 \r\nL 126.523835 212.808889 \r\nL 132.735337 212.685039 \r\nL 138.94684 212.697604 \r\nL 145.158343 212.986322 \r\nL 151.369846 212.99414 \r\nL 157.581349 212.964682 \r\nL 163.792851 212.916241 \r\nL 170.004354 212.897001 \r\nL 176.215857 212.813143 \r\nL 182.42736 212.789335 \r\nL 188.638862 212.807164 \r\nL 194.850365 212.91673 \r\nL 201.061868 213.019195 \r\nL 207.273371 213.078856 \r\nL 213.484874 213.15585 \r\nL 219.696376 213.182017 \r\nL 225.907879 212.591997 \r\nL 232.119382 212.348741 \r\nL 238.330885 212.075177 \r\nL 244.542388 211.889983 \r\nL 250.75389 209.866375 \r\nL 256.965393 209.496782 \r\nL 263.176896 209.455052 \r\nL 269.388399 209.467769 \r\nL 275.599901 209.096391 \r\nL 281.811404 208.911455 \r\nL 288.022907 208.858796 \r\nL 294.23441 208.692018 \r\nL 300.445913 208.545516 \r\nL 306.657415 208.58423 \r\nL 312.868918 208.70463 \r\nL 319.080421 208.653969 \r\nL 325.291924 209.897411 \r\nL 331.503426 209.947947 \r\nL 337.714929 210.066428 \r\nL 343.926432 210.081942 \r\nL 350.137935 210.316369 \r\nL 356.349438 210.503036 \r\nL 362.56094 210.595168 \r\nL 368.772443 210.658116 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 49.190625 224.64 \r\nL 49.190625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 383.990625 224.64 \r\nL 383.990625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 49.190625 224.64 \r\nL 383.990625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 49.190625 7.2 \r\nL 383.990625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pbef40aa8b4\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"49.190625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[170279234.30305684,\n 138486134.61194178,\n 110773168.49276383,\n 88453608.27910532,\n 70731948.64458226,\n 56723724.97336765,\n 45653600.96831522,\n 36879183.13999028,\n 29793215.741121653,\n 23813477.911298532,\n 18732942.649670172,\n 14439353.859978395,\n 10891050.2468269,\n 8102343.64095194,\n 5960953.678186786,\n 4365876.044024943,\n 3236494.3921400844,\n 2488403.9228668,\n 2032144.7433381414,\n 1760479.5041925116,\n 1395694.6248402463,\n 244925.31745750207,\n 83840.74366943064,\n 65736.26907693066,\n 59701.30568325996,\n 54306.840197102916,\n 49385.774551097005,\n 44765.81866709603,\n 40372.665517638896,\n 36355.42702802669,\n 32650.590218158955,\n 28753.968907201146,\n 24614.899725488634,\n 21795.670647818377,\n 19436.020001090215,\n 17221.80849605999,\n 15218.129236173016,\n 13373.11880461031,\n 11688.519846144862,\n 10157.745595875918,\n 8783.786599250332,\n 7555.624498783478,\n 6472.573663091766,\n 5527.3120353833965,\n 4706.698978034632,\n 4003.790964164612,\n 3410.8958791798527,\n 2914.893940231815,\n 2506.5459052187384,\n 2170.6471489412747,\n 1894.7754587897714,\n 1662.8241992300468,\n 1464.7938745098654,\n 1290.981664619817,\n 1421.530617982809,\n 1020.9079493164932,\n 889.264905571258,\n 789.8663288007529,\n 694.1195479778476,\n 591.869069788189,\n 606.6896106181321,\n 431.5541777876043,\n 416.01903662996915,\n 331.64043982943883,\n 297.38183621368546,\n 247.12622685303745,\n 316.36184050183886,\n 206.95437618981057,\n 219.0932262893644,\n 141.73699909910647,\n 154.12678675997822,\n 114.44530122107736,\n 128.97019901669884,\n 98.24316641404191,\n 140.8806562632804,\n 123.36939156219302,\n 127.0665416824586,\n 73.98371007945067,\n 73.50576989114866,\n 60.57900905670126,\n 80.1912578916098,\n 67.4964218219123,\n 79.5433829735034,\n 52.84969452989648,\n 44.78036986625206,\n 61.235971527045145,\n 37.837457261956764,\n 52.160191583111306,\n 52.67331713551785,\n 48.12168033324893,\n 38.708047462978044,\n 28.192881445567725,\n 27.443975884864518,\n 25.055674814643247,\n 34.01331036648525,\n 22.90736795058646,\n 10713.520825627113,\n 26.311727585792365,\n 107.97460259628139,\n 22.52183146168827,\n 19.705086268904616,\n 17.499245302251133,\n 15.150342798077714,\n 13.90913007159154,\n 11.570452125269172,\n 9.675541372163346,\n 7.246648401160422,\n 6.185985943906438,\n 4.536957483381999,\n 2.9902378735180895,\n 1.9396827304020496,\n 1.156937232928115,\n 0.6851509760374059,\n 0.8782324597045948,\n 0.7105080074337763,\n 0.5699233545142157,\n 0.7682509363628427,\n 0.49286162838514314,\n 0.6533796972420645,\n 0.6190319583716152,\n 0.4968810851397818,\n 0.43233508065381865,\n 0.3831084865980117,\n 0.34088198324090113,\n 0.30096054580404386,\n 0.2614737804446815,\n 0.22274988458852327,\n 0.241982572455114,\n 0.19447742261839385,\n 0.15087259690861946,\n 0.1216342453196307,\n 0.09643069859268191,\n 0.0807192864026076,\n 0.0700402843509539,\n 0.06282125424549936,\n 0.0579270726208952,\n 0.05415677966075565,\n 0.05094088256632528,\n 0.04809451452728983,\n 0.04555049482811279,\n 0.04335464781349128,\n 0.041549406041124254,\n 0.04005559349571461,\n 0.03885331007641598,\n 0.03783672371580738,\n 0.03713968575659718,\n 0.036675371702815776,\n 0.036209400113194505,\n 0.03598800585881639,\n 0.05080354788335784,\n 13.862940554417651,\n 0.0345389821256089,\n 0.0342027777633129,\n 0.03404082994369872,\n 0.03395691833221939,\n 0.03382288987806701,\n 0.03368981932940562,\n 0.03351709938602752,\n 0.033385830901376035,\n 0.03325871524280557,\n 0.03315744789649393,\n 0.03319353599412516,\n 0.03298149069069863,\n 0.033101434848845215,\n 0.0328243879115753,\n 0.03294302002835518,\n 0.03267614328326468,\n 0.03261471833844814,\n 0.032506101548100595,\n 0.03243398558318741,\n 0.0325264942591829,\n 0.032349657836575035,\n 0.03208964122804354,\n 0.03217616908778655,\n 0.031818684290187624,\n 0.031898996803408346,\n 0.03183642883495726,\n 0.03168168006443081,\n 0.031609435542847834,\n 0.03146342355881625,\n 0.031223376258238494,\n 0.03152813262177323,\n 0.3623889102947419,\n 0.03367205028186594,\n 0.03181392434762366,\n 0.03165456805294978,\n 0.031632049351206365,\n 0.03119833159003369,\n 0.03119259349233981,\n 0.030751249975912304,\n 0.030768502381911325,\n 0.0304114994332376,\n 0.030536191713658928,\n 10.609197339277639,\n 0.06952730632202965,\n 0.03170415003789929,\n 0.02969336459516238,\n 0.02936659129129793,\n 0.029396941437462493,\n 0.029404308190429634]"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " 100.4  734.6 ]]\nOutputs (missing):  [[ 13.31  85.88 544.95  14.49  95.61 640.56]]\nInput:  [[ 11.6   73.88 412.7   12.77  82.68 495.1 ]]\nTarget:  [[ 11.6   73.88 412.7   12.77  82.68 495.1 ]]\nOutputs:  [[ 11.58  74.25 423.85  12.56  82.27 494.49]]\nInput (missing):  [[  6.98  84.28 537.3   14.9   95.1  687.6 ]]\nTarget (missing):  [[ 13.17  84.28 537.3   14.9   95.1  687.6 ]]\nOutputs (missing):  [[ 12.24  78.67 469.9   13.3   87.34 550.04]]\nInput (missing):  [[ 13.24  86.87 143.5   15.44 115.   733.5 ]]\nTarget (missing):  [[ 13.24  86.87 542.9   15.44 115.   733.5 ]]\nOutputs (missing):  [[ 12.99  83.72 522.51  14.13  93.14 613.52]]\nInput (missing):  [[ 13.14  85.98 536.9   14.8   50.41 689.1 ]]\nTarget (missing):  [[ 13.14  85.98 536.9   14.8  100.9  689.1 ]]\nOutputs (missing):  [[ 12.37  79.56 479.2   13.44  88.36 561.32]]\nInput (missing):  [[  9.67  43.79 286.3   11.15  71.11 380.2 ]]\nTarget (missing):  [[  9.67  61.06 286.3   11.15  71.11 380.2 ]]\nOutputs (missing):  [[  9.39  59.54 270.78  10.12  65.4  309.81]]\nInput:  [[  17.6   119.    980.5    21.57  143.6  1437.  ]]\nTarget:  [[  17.6   119.    980.5    21.57  143.6  1437.  ]]\nOutputs:  [[  18.11  118.67 1007.11   21.27  140.72 1382.62]]\nInput (missing):  [[  6.98  76.38 408.8   13.36  88.14 528.1 ]]\nTarget (missing):  [[ 11.62  76.38 408.8   13.36  88.14 528.1 ]]\nOutputs (missing):  [[ 11.08  70.89 388.92  12.01  78.42 452.32]]\nInput (missing):  [[  9.67  61.49 143.5   11.14  70.88 385.2 ]]\nTarget (missing):  [[  9.67  61.49 289.1   11.14  70.88 385.2 ]]\nOutputs (missing):  [[  9.55  60.59 281.71  10.3   66.6  322.97]]\nInput (missing):  [[ 12.04  43.79 449.9   13.6   87.24 185.2 ]]\nTarget (missing):  [[ 12.04  76.85 449.9   13.6   87.24 567.6 ]]\nOutputs (missing):  [[ 10.62  67.77 356.4   11.49  74.83 413.12]]\nInput:  [[ 14.92  96.45 686.9   17.18 112.   906.6 ]]\nTarget:  [[ 14.92  96.45 686.9   17.18 112.   906.6 ]]\nOutputs:  [[ 14.97  97.21 702.48  16.83 111.12 891.69]]\nInput (missing):  [[  6.98  77.42 465.4   13.45  85.08 558.9 ]]\nTarget (missing):  [[ 12.27  77.42 465.4   13.45  85.08 558.9 ]]\nOutputs (missing):  [[ 11.25  72.   400.49  12.19  79.69 466.29]]\nInput (missing):  [[  6.98  70.41 358.9   11.94  80.78 433.1 ]]\nTarget (missing):  [[ 10.88  70.41 358.9   11.94  80.78 433.1 ]]\nOutputs (missing):  [[ 10.29  65.54 333.19  11.12  72.28 385.07]]\nInput (missing):  [[ 12.83  82.89 506.9   14.09  93.22 185.2 ]]\nTarget (missing):  [[ 12.83  82.89 506.9   14.09  93.22 605.8 ]]\nOutputs (missing):  [[ 12.24  78.71 470.32  13.3   87.39 550.53]]\nInput (missing):  [[ 14.2   92.41 618.4   16.45  50.41 828.5 ]]\nTarget (missing):  [[ 14.2   92.41 618.4   16.45 112.1  828.5 ]]\nOutputs (missing):  [[ 13.38  86.35 550.02  14.57  96.16 647.  ]]\nInput:  [[ 13.9   88.97 599.4   15.14 101.2  718.9 ]]\nTarget:  [[ 13.9   88.97 599.4   15.14 101.2  718.9 ]]\nOutputs:  [[ 13.84  89.51 594.4   15.23 100.52 718.22]]\nInput (missing):  [[ 11.49  73.99 404.9   12.4   82.04 185.2 ]]\nTarget (missing):  [[ 11.49  73.99 404.9   12.4   82.04 467.6 ]]\nOutputs (missing):  [[ 11.02  70.46 384.37  11.93  77.92 446.83]]\nInput (missing):  [[  6.98 109.8  815.8   17.39 122.1  939.7 ]]\nTarget (missing):  [[ 16.25 109.8  815.8   17.39 122.1  939.7 ]]\nOutputs (missing):  [[ 14.67  95.18 673.91  16.4  108.32 845.82]]\nInput:  [[ 12.16  78.29 455.3   13.34  88.83 547.4 ]]\nTarget:  [[ 12.16  78.29 455.3   13.34  88.83 547.4 ]]\nOutputs:  [[ 12.21  78.46 467.68  13.26  87.1  547.38]]\nInput:  [[ 13.9   88.73 602.9   16.41 104.4  830.5 ]]\nTarget:  [[ 13.9   88.73 602.9   16.41 104.4  830.5 ]]\nOutputs:  [[ 14.17  91.74 625.69  15.69 103.59 768.44]]\nInput (missing):  [[ 13.47  87.32 143.5   14.83  94.94 660.2 ]]\nTarget (missing):  [[ 13.47  87.32 546.3   14.83  94.94 660.2 ]]\nOutputs (missing):  [[ 12.41  79.82 481.89  13.49  88.66 564.52]]\nInput (missing):  [[ 13.7   87.76 143.5   14.96  50.41 686.5 ]]\nTarget (missing):  [[ 13.7   87.76 571.1   14.96  95.78 686.5 ]]\nOutputs (missing): [[ 11.54  73.95 420.81  12.51  81.93 490.87]]\nInput (missing):  [[ 15.73 102.8  143.5   17.01 112.5  854.3 ]]\nTarget (missing):  [[ 15.73 102.8  747.2   17.01 112.5  854.3 ]]\nOutputs (missing):  [[ 14.06  90.97 614.83  15.53 102.52 751.  ]]\nInput:  [[ 12.45  82.85 476.7   13.78  97.82 580.6 ]]\nTarget:  [[ 12.45  82.85 476.7   13.78  97.82 580.6 ]]\nOutputs:  [[ 12.75  82.13 505.9   13.87  91.31 593.48]]\nInput (missing):  [[ 14.64  94.21 666.    16.46  50.41 831.  ]]\nTarget (missing):  [[ 14.64  94.21 666.    16.46 106.   831.  ]]\nOutputs (missing):  [[ 13.58  87.75 569.63  14.86  98.09 678.47]]\nInput:  [[  19.44  128.1  1167.     23.96  153.9  1740.  ]]\nTarget:  [[  19.44  128.1  1167.     23.96  153.9  1740.  ]]\nOutputs:  [[  19.49  128.52 1188.04   23.24  155.17 1697.04]]\nInput:  [[ 11.68  75.49 420.5   13.32  86.57 549.8 ]]\nTarget:  [[ 11.68  75.49 420.5   13.32  86.57 549.8 ]]\nOutputs:  [[ 11.9   76.41 446.41  12.92  84.75 521.71]]\nInput:  [[  16.69  107.1   857.6    19.18  127.3  1084.  ]]\nTarget:  [[  16.69  107.1   857.6    19.18  127.3  1084.  ]]\nOutputs:  [[  16.51  107.73  849.97   19.01  125.58 1128.41]]\nInput (missing):  [[  6.98  78.18 466.5   14.17  92.74 622.9 ]]\nTarget (missing):  [[ 12.25  78.18 466.5   14.17  92.74 622.9 ]]\nOutputs (missing):  [[ 11.63  74.6  427.51  12.62  82.67 498.89]]\nInput (missing):  [[   6.98  114.6   992.1    19.82  127.1  1210.  ]]\nTarget (missing):  [[  17.85  114.6   992.1    19.82  127.1  1210.  ]]\nOutputs (missing):  [[  15.81  102.97  783.24   18.02  119.04 1021.31]]\nInput (missing): [[  18.01  118.4  1007.     21.53  143.4   185.2 ]]\nTarget (missing):  [[  18.01  118.4  1007.     21.53  143.4  1426.  ]]\nOutputs (missing):  [[  16.72  109.17  870.19   19.31  127.57 1160.86]]\nInput:  [[ 12.46  78.83 477.3   13.19  83.24 534.  ]]\nTarget:  [[ 12.46  78.83 477.3   13.19  83.24 534.  ]]\nOutputs:  [[ 12.17  78.2  464.96  13.22  86.8  544.1 ]]\nInput (missing):  [[ 13.16  43.79 538.7   14.5   95.29 648.3 ]]\nTarget (missing):  [[ 13.16  84.06 538.7   14.5   95.29 648.3 ]]\nOutputs (missing):  [[ 12.03  77.28 455.43  13.06  85.75 532.64]]\nInput:  [[ 14.87  96.12 680.9   16.01 103.9  783.6 ]]\nTarget:  [[ 14.87  96.12 680.9   16.01 103.9  783.6 ]]\nOutputs:  [[ 14.53  94.2  660.19  16.2  106.97 823.82]]\nInput (missing):  [[ 12.65  82.69 485.6   14.38  50.41 633.7 ]]\nTarget (missing):  [[ 12.65  82.69 485.6   14.38  95.29 633.7 ]]\nOutputs (missing):  [[ 11.92  76.52 447.55  12.94  84.88 523.13]]\nInput:  [[ 12.47  80.45 480.1   14.06  92.82 607.3 ]]\nTarget:  [[ 12.47  80.45 480.1   14.06  92.82 607.3 ]]\nOutputs:  [[ 12.66  81.51 499.51  13.77  90.61 585.79]]\nInput (missing):  [[   6.98  121.3  1068.     22.75  146.4  1600.  ]]\nTarget (missing):  [[  18.49  121.3  1068.     22.75  146.4  1600.  ]]\nOutputs (missing):  [[  17.24  112.73  920.24   20.05  132.48 1241.19]]\nInput (missing):  [[  20.59   43.79  143.5    23.86  163.2  1760.  ]]\nTarget (missing):  [[  20.59  137.8  1320.     23.86  163.2  1760.  ]]\nOutputs (missing): [[  16.06  104.66  807.04   18.37  121.37 1059.53]]\nInput:  [[ 15.04  98.73 689.4   16.76 109.7  856.9 ]]\nTarget:  [[ 15.04  98.73 689.4   16.76 109.7  856.9 ]]\nOutputs:  [[ 14.9   96.74 695.83  16.73 110.47 881.02]]\nInput:  [[ 13.82  92.33 595.9   16.01 106.   788.  ]]\nTarget:  [[ 13.82  92.33 595.9   16.01 106.   788.  ]]\nOutputs:  [[ 14.16  91.7  625.08  15.68 103.53 767.45]]\nInput (missing):  [[ 12.54  81.25 143.5   13.57  86.67 552.  ]]\nTarget (missing):  [[ 12.54  81.25 476.3   13.57  86.67 552.  ]]\nOutputs (missing):  [[ 11.55  74.08 422.12  12.53  82.08 492.4 ]]\nInput:  [[  23.09  152.1  1682.     30.79  211.5  2782.  ]]\nTarget:  [[  23.09  152.1  1682.     30.79  211.5  2782.  ]]\nOutputs:  [[  23.77  159.04 1748.79   29.35  199.96 2671.52]]\nInput (missing):  [[  9.27  61.49 248.7   10.28  69.05 185.2 ]]\nTarget (missing):  [[  9.27  61.49 248.7   10.28  69.05 300.2 ]]\nOutputs (missing):  [[  9.29  58.87 263.72  10.01  64.62 301.25]]\nInput:  [[  9.68  64.12 272.5   10.6   69.47 328.1 ]]\nTarget:  [[  9.68  64.12 272.5   10.6   69.47 328.1 ]]\nOutputs:  [[  9.77  62.06 297.01  10.54  68.29 341.43]]\nInput (missing):  [[  6.98  79.47 453.1   13.16  50.41 515.3 ]]\nTarget (missing):  [[ 12.22  79.47 453.1   13.16  85.13 515.3 ]]\nOutputs (missing): [[ 10.41  66.35 341.67  11.25  73.21 395.34]]\nInput (missing):  [[ 11.06  43.79 366.5   11.69  76.08 411.1 ]]\nTarget (missing):  [[ 11.06  71.25 366.5   11.69  76.08 411.1 ]]\nOutputs (missing):  [[ 10.07  64.09 318.14  10.88  70.62 366.96]]\nInput (missing):  [[ 16.3  104.7  819.8    7.93 109.8  185.2 ]]\nTarget (missing):  [[ 16.3  104.7  819.8   17.32 109.8  928.2 ]]\nOutputs (missing):  [[ 13.74  88.82 584.69  15.08  99.57 702.61]]\nInput:  [[ 15.46 103.8  731.3   17.11 117.7  909.4 ]]\nTarget:  [[ 15.46 103.8  731.3   17.11 117.7  909.4 ]]\nOutputs:  [[ 15.4  100.18 744.1   17.44 115.2  958.49]]\nInput (missing):  [[ 11.74  76.31 143.5   12.45  81.25 473.8 ]]\nTarget (missing):  [[ 11.74  76.31 426.    12.45  81.25 473.8 ]]\nOutputs (missing):  [[ 10.88  69.57 375.13  11.79  76.9  435.69]]\nInput (missing):  [[  6.98  94.66 680.7   15.61  50.41 760.2 ]]\nTarget (missing):  [[ 14.81  94.66 680.7   15.61 101.7  760.2 ]]\nOutputs (missing):  [[ 12.12  77.91 461.98  13.17  86.47 540.52]]\nInput (missing):  [[ 13.4   43.79 556.7   16.41 113.3  844.4 ]]\nTarget (missing):  [[ 13.4   88.64 556.7   16.41 113.3  844.4 ]]\nOutputs (missing):  [[ 13.06  84.23 527.81  14.22  93.72 619.98]]\nInput (missing):  [[  6.98  94.29 658.8    7.93 108.5  862.  ]]\nTarget (missing):  [[ 14.58  94.29 658.8   16.76 108.5  862.  ]]\nOutputs (missing):  [[ 12.47  80.23 486.11  13.55  89.13 569.53]]\nInput:  [[ 15.05  97.26 701.9   17.58 113.8  967.  ]]\nTarget:  [[ 15.05  97.26 701.9   17.58 113.8  967.  ]]\nOutputs:  [[ 15.18  98.68 723.01  17.13 113.13 924.64]]\nInput:  [[ 11.34  72.76 391.2   12.47  79.15 478.6 ]]\nTarget:  [[ 11.34  72.76 391.2   12.47  79.15 478.6 ]]\nOutputs:  [[ 11.3   72.39 404.54  12.25  80.14 471.19]]\nInput (missing):  [[  18.31   43.79 1052.     21.86  142.2  1493.  ]]\nTarget (missing):[[  18.31  120.8  1052.     21.86  142.2  1493.  ]]\nOutputs (missing):  [[  16.69  108.94  866.99   19.26  127.25 1155.75]]\nInput:  [[  19.89  130.5  1214.     23.73  160.5  1646.  ]]\nTarget:  [[  19.89  130.5  1214.     23.73  160.5  1646.  ]]\nOutputs:  [[  19.65  129.68 1209.35   23.48  156.88 1734.07]]\nInput (missing):  [[ 12.88  43.79 493.1   15.05  50.41 185.2 ]]\nTarget (missing):  [[ 12.88  84.45 493.1   15.05  99.31 674.7 ]]\nOutputs (missing):  [[ 10.25  65.33 331.06  11.08  72.04 382.59]]\nInput (missing):  [[ 12.75  43.79 493.8   14.45  50.41 624.1 ]]\nTarget (missing):  [[ 12.75  82.51 493.8   14.45  93.63 624.1 ]]\nOutputs (missing):  [[ 10.81  69.07 370.06  11.7   76.33 429.66]]\nInput (missing):  [[  9.29  59.96 143.5   10.57  67.84 326.6 ]]\nTarget (missing):  [[  9.29  59.96 257.8   10.57  67.84 326.6 ]]\nOutputs (missing):  [[  9.21  58.3  257.83   9.92  63.97 294.16]]\nInput (missing):  [[  24.63  165.5  1841.      7.93  205.7  2642.  ]]\nTarget (missing):  [[  24.63  165.5  1841.     29.92  205.7  2642.  ]]\nOutputs (missing):  [[  22.23  148.   1545.98   27.14  183.76 2319.08]]\nInput:  [[ 11.26  71.3  388.1   11.93  76.38 435.9 ]]\nTarget:  [[ 11.26  71.3  388.1   11.93  76.38 435.9 ]]\nOutputs:  [[ 11.04  70.63 386.21  11.96  78.12 449.07]]\nInput (missing):  [[ 13.71  88.73 571.    15.11  99.43 185.2 ]]\nTarget (missing):  [[ 13.71  88.73 571.    15.11  99.43 701.9 ]]\nOutputs (missing):  [[ 13.    83.83 523.65  14.15  93.27 614.89]]\nInput (missing):  [[  9.85  63.   143.5   11.24  74.32 376.5 ]]\nTarget (missing):  [[  9.85  63.   293.2   11.24  74.32 376.5 ]]\nOutputs (missing):  [[  9.7   61.62 292.35  10.47  67.78 335.81]]\nInput (missing):  [[  8.57  43.79 221.3    9.47  50.41 275.6 ]]\nTarget (missing):  [[  8.57  54.53 221.3    9.47  63.3  275.6 ]]\nOutputs (missing):  [[  8.04  50.45 176.32   8.62  54.98 196.05]]\nInput (missing): [[ 13.46  87.44 143.5   15.35 101.9  185.2 ]]\nTarget (missing):  [[ 13.46  87.44 551.1   15.35 101.9  719.8 ]]\nOutputs (missing):  [[ 11.92  76.55 447.76  12.94  84.9  523.31]]\nInput:  [[ 12.34  78.94 468.5   13.61  87.22 564.9 ]]\nTarget:  [[ 12.34  78.94 468.5   13.61  87.22 564.9 ]]\nOutputs:  [[ 12.32  79.2  475.45  13.38  87.95 556.75]]\nInput (missing):  [[ 13.94  43.79 594.2    7.93  94.52 653.3 ]]\nTarget (missing):  [[ 13.94  90.31 594.2   14.62  94.52 653.3 ]]\nOutputs (missing):  [[ 11.42  73.2  412.98  12.39  81.07 481.37]]\nInput (missing):  [[ 12.07  43.79 445.2    7.93  86.92 549.9 ]]\nTarget (missing):  [[ 12.07  77.83 445.2   13.45  86.92 549.9 ]]\nOutputs (missing):  [[ 10.39  66.27 340.84  11.24  73.12 394.32]]\nInput (missing):  [[ 11.75  75.89 422.9   13.5   88.52 185.2 ]]\nTarget (missing):  [[ 11.75  75.89 422.9   13.5   88.52 552.3 ]]\nOutputs (missing):  [[ 11.45  73.39 414.94  12.42  81.29 483.72]]\nInput (missing):  [[  6.98  43.79 416.2   13.35  87.   550.6 ]]\nTarget (missing):  [[ 11.67  75.21 416.2   13.35  87.   550.6 ]]\nOutputs (missing):  [[ 10.15  64.64 323.87  10.97  71.25 373.86]]\nInput:  [[ 13.68  87.76 575.5   15.85 101.6  773.4 ]]\nTarget:  [[ 13.68  87.76 575.5   15.85 101.6  773.4 ]]\nOutputs:  [[ 13.88  89.79 598.24  15.28 100.89 724.38]]\nInput (missing):  [[  20.47  134.7  1299.     23.23  152.    185.2 ]]\nTarget (missing):  [[  20.47  134.7  1299.     23.23  152.   1645.  ]]\nOutputs (missing):  [[  18.31  120.13 1033.85   21.56  142.86 1429.1 ]]\nInput (missing):  [[ 10.96  70.79 365.6    7.93  50.41 185.2 ]]\nTarget (missing):  [[ 10.96  70.79 365.6   11.62  76.43 407.5 ]]\nOutputs (missing):  [[  9.44  59.83 273.73  10.17  65.73 313.33]]\nInput (missing):  [[  20.55  137.8   143.5    24.3   160.2  1809.  ]]\nTarget (missing):  [[  20.55  137.8  1308.     24.3   160.2  1809.  ]]\nOutputs (missing):  [[  18.26  119.74 1026.81   21.49  142.3  1416.87]]\nInput (missing):  [[ 14.27  43.79 629.8   15.29 104.3  728.3 ]]\nTarget (missing):  [[ 14.27  93.77 629.8   15.29 104.3  728.3 ]]\nOutputs (missing):  [[ 12.88  83.   515.    14.01  92.31 604.52]]\nInput (missing):  [[ 11.69  76.37 406.4   12.98  50.41 487.7 ]]\nTarget (missing):  [[ 11.69  76.37 406.4   12.98  86.12 487.7 ]]\nOutputs (missing):  [[ 10.96  70.06 380.28  11.87  77.46 441.94]]\nInput (missing):  [[  7.73  47.98 178.8    7.93  57.17 248.  ]]\nTarget (missing):  [[  7.73  47.98 178.8    9.08  57.17 248.  ]]\nOutputs (missing):  [[  7.83  49.   161.27   8.38  53.31 177.98]]\nInput:  [[  7.69  48.34 170.4    8.68  54.49 223.6 ]]\nTarget:  [[  7.69  48.34 170.4    8.68  54.49 223.6 ]]\nOutputs:  [[  7.79  48.78 159.05   8.34  53.07 175.34]]\nInput (missing):  [[ 11.54  74.65 143.5   12.26  78.78 457.8 ]]\nTarget (missing):  [[ 11.54  74.65 402.9   12.26  78.78 457.8 ]]\nOutputs (missing):  [[ 10.7   68.31 362.    11.58  75.45 419.85]]\nInput:  [[ 14.47  95.81 656.4   16.22 113.5  808.9 ]]\nTarget:  [[ 14.47  95.81 656.4   16.22 113.5  808.9 ]]\nOutputs:  [[ 14.64  94.94 670.6   16.35 107.99 840.52]]\nInput:  [[ 14.74  94.7  668.6   16.51 107.4  826.4 ]]\nTarget:  [[ 14.74  94.7  668.6   16.51 107.4  826.4 ]]\nOutputs:  [[ 14.62  94.81 668.78  16.33 107.81 837.6 ]]\nInput (missing):  [[ 13.21  43.79 538.4   14.37  92.48 629.6 ]]\nTarget (missing):  [[ 13.21  84.88 538.4   14.37  92.48 629.6 ]]\nOutputs (missing):  [[ 11.93  76.61 448.48  12.95  84.98 524.25]]\nInput (missing):  [[  6.98  89.77 584.8   15.05  99.17 185.2 ]]\nTarget (missing):  [[ 13.87  89.77 584.8   15.05  99.17 688.6 ]]\nOutputs (missing):  [[ 11.88  76.24 444.59  12.89  84.56 519.46]]\nInput (missing):  [[  6.98  87.19 573.2    7.93  97.58 729.8 ]]\nTarget (missing):  [[ 13.62  87.19 573.2   15.35  97.58 729.8 ]]\nOutputs (missing):  [[ 11.6   74.41 425.53  12.59  82.46 496.45]]\nInput (missing):  [[ 10.32  65.31 324.9    7.93  71.12 384.9 ]]\nTarget (missing):  [[ 10.32  65.31 324.9   11.25  71.12 384.9 ]]\nOutputs (missing):  [[  9.82  62.38 300.32  10.6   68.66 345.4 ]]\nInput (missing):  [[ 10.26  65.85 320.8   10.83  50.41 357.4 ]]\nTarget (missing):  [[ 10.26  65.85 320.8   10.83  71.08 357.4 ]]\nOutputs (missing):  [[  9.7   61.59 292.13  10.46  67.75 335.56]]\nInput (missing):  [[  6.98  43.79 285.7   10.93  69.1  185.2 ]]\nTarget (missing):  [[  9.68  61.05 285.7   10.93  69.1  364.2 ]]\nOutputs (missing):  [[  8.55  53.9  212.03   9.19  58.92 238.89]]\nInput:  [[ 10.82  68.89 361.6   13.03  83.9  505.6 ]]\nTarget:  [[ 10.82  68.89 361.6   13.03  83.9  505.6 ]]\nOutputs:  [[ 11.24  71.99 400.33  12.19  79.68 466.1 ]]\nInput:  [[ 10.86  68.51 360.5   11.66  74.08 412.3 ]]\nTarget:  [[ 10.86  68.51 360.5   11.66  74.08 412.3 ]]\nOutputs:  [[ 10.7   68.32 362.1   11.58  75.46 419.98]]\nInput:  [[ 11.13  71.49 378.4   12.02  77.8  436.6 ]]\nTarget:  [[ 11.13  71.49 378.4   12.02  77.8  436.6 ]]\nOutputs:  [[ 11.04  70.65 386.38  11.97  78.14 449.27]]\nInput:  [[ 12.77  81.35 507.9   13.87  88.1  594.7 ]]\nTarget:  [[ 12.77  81.35 507.9   13.87  88.1  594.7 ]]\nOutputs:  [[ 12.66  81.52 499.62  13.77  90.62 585.92]]\nInput:  [[  9.33  59.01 264.     9.85  62.86 295.8 ]]\nTarget:  [[  9.33  59.01 264.     9.85  62.86 295.8 ]]\nOutputs:  [[  9.24  58.52 260.15   9.96  64.23 296.95]]\nInput (missing):  [[ 12.88  43.79 514.3   13.89  88.84 595.7 ]]\nTarget (missing):  [[ 12.88  82.5  514.3   13.89  88.84 595.7 ]]\nOutputs (missing):  [[ 11.62  74.49 426.47  12.6   82.55 497.69]]\nInput:  [[ 10.29  65.67 321.4   10.84  69.57 357.6 ]]\nTarget:  [[ 10.29  65.67 321.4   10.84  69.57 357.6 ]]\nOutputs:  [[ 10.12  64.46 321.94  10.94  71.04 371.52]]\nInput (missing):  [[ 10.16  64.73 311.7   10.65  50.41 347.3 ]]\nTarget (missing):  [[ 10.16  64.73 311.7   10.65  67.88 347.3 ]]\nOutputs (missing):  [[  9.59  60.83 284.24  10.34  66.88 326.04]]\nInput (missing):  [[  9.42  43.79 271.3    7.93  50.41 185.2 ]]\nTarget (missing):  [[  9.42  59.26 271.3   10.49  66.5  330.6 ]]\nOutputs (missing):  [[  7.96  49.92 170.75   8.53  54.36 189.35]]\nInput (missing):  [[  6.98  96.39 657.1   15.48 105.9  733.5 ]]\nTarget (missing):  [[ 14.59  96.39 657.1   15.48 105.9  733.5 ]]\nOutputs (missing):  [[ 13.28  85.7  543.02  14.46  95.4  638.25]]\nInput (missing):  [[ 11.51  74.52 143.5   12.48  82.28 474.2 ]]\nTarget (missing):  [[ 11.51  74.52 403.5   12.48  82.28 474.2 ]]\nOutputs (missing):  [[ 10.82  69.13 370.54  11.71  76.39 430.16]]\nInput (missing):  [[  6.98  91.38 600.4   15.3  100.2  185.2 ]]\nTarget (missing):  [[ 14.05  91.38 600.4   15.3  100.2  706.7 ]]\nOutputs (missing):  [[ 12.02  77.2  454.6   13.05  85.66 531.54]]\nInput (missing):  [[  6.98  43.79 386.    11.92  50.41 439.6 ]]\nTarget (missing):  [[ 11.2   70.67 386.    11.92  75.19 439.6 ]]\nOutputs (missing):  [[  8.91  56.29 236.98   9.59  61.67 269.04]]\nInput (missing): [[ 15.22 103.4  716.9    7.93 128.7  915.  ]]\nTarget (missing):  [[ 15.22 103.4  716.9   17.52 128.7  915.  ]]\nOutputs (missing):  [[ 14.56  94.39 662.84  16.24 107.23 828.04]]\nInput (missing):  [[   6.98  143.   1347.     24.29  179.1  1819.  ]]\nTarget (missing):  [[  20.92  143.   1347.     24.29  179.1  1819.  ]]\nOutputs (missing):  [[  19.11  125.78 1137.82   22.7   151.16 1609.77]]\nInput:  [[  21.56  142.   1479.     25.45  166.1  2027.  ]]\nTarget:  [[  21.56  142.   1479.     25.45  166.1  2027.  ]]\nOutputs:  [[  21.15  140.31 1404.68   25.61  172.48 2073.53]]\nInput (missing):  [[  20.13  131.2  1261.      7.93   50.41 1731.  ]]\nTarget (missing):  [[  20.13  131.2  1261.     23.69  155.   1731.  ]]\nOutputs (missing):  [[  16.6   108.34  858.58   19.13  126.43 1142.23]]\nInput (missing):  [[  16.6   108.3   143.5    18.98  126.7  1124.  ]]\nTarget (missing):  [[  16.6   108.3   858.1    18.98  126.7  1124.  ]]\nOutputs (missing):  [[ 15.09  98.02 713.84  16.99 112.23 909.91]]\nInput:  [[  20.6   140.1  1265.     25.74  184.6  1821.  ]]\nTarget:  [[  20.6   140.1  1265.     25.74  184.6  1821.  ]]\nOutputs:  [[  20.72  137.3  1349.38   25.    168.06 1977.42]]\nInput:  [[  7.76  47.92 181.     9.46  59.16 268.6 ]]\nTarget:  [[  7.76  47.92 181.     9.46  59.16 268.6 ]]\nOutputs:  [[  8.17  51.33 185.41   8.76  55.99 206.9 ]]\nTest Loss: 0.006\n"
    }
   ],
   "source": [
    "# TEST THE NEURAL NETWORK\n",
    "test_result = test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './breast_autoencoder3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following section is for reconstructing a brand new dataset from an input dataset that has missing values.\n",
    "# This new dataset can be used in some classifiers to see if the accuracy changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>radius_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>17.99</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>25.380</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20.57</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>24.990</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>19.69</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>23.570</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.42</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>14.910</td>\n      <td>98.87</td>\n      <td>567.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.29</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>22.540</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>21.56</td>\n      <td>142.00</td>\n      <td>1479.0</td>\n      <td>25.450</td>\n      <td>166.10</td>\n      <td>2027.0</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>20.13</td>\n      <td>131.20</td>\n      <td>1261.0</td>\n      <td>23.690</td>\n      <td>155.00</td>\n      <td>1731.0</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>16.60</td>\n      <td>108.30</td>\n      <td>858.1</td>\n      <td>18.980</td>\n      <td>126.70</td>\n      <td>1124.0</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>20.60</td>\n      <td>140.10</td>\n      <td>1265.0</td>\n      <td>25.740</td>\n      <td>184.60</td>\n      <td>1821.0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>7.76</td>\n      <td>47.92</td>\n      <td>181.0</td>\n      <td>9.456</td>\n      <td>59.16</td>\n      <td>268.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 6 columns</p>\n</div>",
      "text/plain": "     radius_mean  perimeter_mean  area_mean  radius_worst  perimeter_worst  \\\n0          17.99          122.80     1001.0        25.380           184.60   \n1          20.57          132.90     1326.0        24.990           158.80   \n2          19.69          130.00     1203.0        23.570           152.50   \n3          11.42           77.58      386.1        14.910            98.87   \n4          20.29          135.10     1297.0        22.540           152.20   \n..           ...             ...        ...           ...              ...   \n564        21.56          142.00     1479.0        25.450           166.10   \n565        20.13          131.20     1261.0        23.690           155.00   \n566        16.60          108.30      858.1        18.980           126.70   \n567        20.60          140.10     1265.0        25.740           184.60   \n568         7.76           47.92      181.0         9.456            59.16   \n\n     area_worst  \n0        2019.0  \n1        1956.0  \n2        1709.0  \n3         567.7  \n4        1575.0  \n..          ...  \n564      2027.0  \n565      1731.0  \n566      1124.0  \n567      1821.0  \n568       268.6  \n\n[569 rows x 6 columns]"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('breast/breast.csv')\n",
    "array = np.array(['radius_mean', 'perimeter_mean', 'area_mean', 'radius_worst', 'perimeter_worst', 'area_worst'])\n",
    "filtered_data = dataset[array]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.6067, 0.5937, 0.4609, 0.6332, 0.5971, 0.4482],\n       [0.5939, 0.5819, 0.4579, 0.7104, 0.6464, 0.5633],\n       [0.3156, 0.3047, 0.1804, 0.2636, 0.2455, 0.128 ],\n       [0.3114, 0.3096, 0.1772, 0.2508, 0.2525, 0.1232],\n       [0.1514, 0.1474, 0.0719, 0.1153, 0.1072, 0.0468],\n       [0.415 , 0.4064, 0.2621, 0.4137, 0.376 , 0.2219],\n       [0.2976, 0.2817, 0.1709, 0.2565, 0.2412, 0.1287],\n       [0.3483, 0.3367, 0.2111, 0.3145, 0.2988, 0.1691],\n       [0.1637, 0.1578, 0.0789, 0.1277, 0.1148, 0.0517],\n       [0.3795, 0.3708, 0.2295, 0.3017, 0.3177, 0.1531],\n       [0.2669, 0.2596, 0.1497, 0.2231, 0.2005, 0.1078],\n       [0.2768, 0.2866, 0.1526, 0.2586, 0.2734, 0.128 ],\n       [0.4765, 0.481 , 0.3188, 0.4148, 0.4138, 0.2467],\n       [0.2054, 0.1933, 0.107 , 0.1476, 0.1465, 0.0656],\n       [0.2006, 0.1866, 0.1032, 0.1576, 0.1396, 0.0702],\n       [0.6403, 0.6261, 0.4986, 0.5884, 0.5592, 0.4146],\n       [0.1224, 0.1135, 0.0577, 0.0918, 0.0763, 0.037 ],\n       [0.3336, 0.3179, 0.1951, 0.2633, 0.2384, 0.1303],\n       [0.7681, 0.7581, 0.6475, 0.8211, 0.7749, 0.678 ],\n       [0.6389, 0.613 , 0.4931, 0.5795, 0.5543, 0.3846],\n       [0.3426, 0.3369, 0.2038, 0.2782, 0.2594, 0.1423],\n       [0.496 , 0.481 , 0.3296, 0.5187, 0.4522, 0.3005],\n       [0.3152, 0.3012, 0.1832, 0.2462, 0.2176, 0.1224],\n       [0.2574, 0.2406, 0.1413, 0.1875, 0.1665, 0.088 ],\n       [0.2044, 0.2083, 0.1043, 0.1654, 0.183 , 0.0707],\n       [0.3204, 0.3092, 0.1894, 0.2519, 0.237 , 0.128 ],\n       [0.5878, 0.5895, 0.4291, 0.4881, 0.4706, 0.3027],\n       [0.1656, 0.1585, 0.0824, 0.1263, 0.1159, 0.0535],\n       [0.2943, 0.2788, 0.1689, 0.2138, 0.1886, 0.1024],\n       [0.2797, 0.2844, 0.1564, 0.2298, 0.2719, 0.1116],\n       [0.1736, 0.1674, 0.0863, 0.1537, 0.1373, 0.0665],\n       [0.2148, 0.2079, 0.1115, 0.1679, 0.1518, 0.0754],\n       [0.6607, 0.6572, 0.5177, 0.6279, 0.5722, 0.4485],\n       [0.2139, 0.2038, 0.1119, 0.1793, 0.1629, 0.0796],\n       [0.6034, 0.6006, 0.4507, 0.6172, 0.5448, 0.4296],\n       [0.4884, 0.4783, 0.3329, 0.424 , 0.4009, 0.2548],\n       [0.5901, 0.5716, 0.435 , 0.6322, 0.5612, 0.4391],\n       [0.3303, 0.3292, 0.1947, 0.301 , 0.2873, 0.1575],\n       [0.5949, 0.6206, 0.4511, 0.609 , 0.6384, 0.4278],\n       [0.3947, 0.4105, 0.2417, 0.3486, 0.3456, 0.1828],\n       [0.4108, 0.4589, 0.2672, 0.424 , 0.4646, 0.2558],\n       [0.4046, 0.414 , 0.2551, 0.3757, 0.378 , 0.2089],\n       [0.6308, 0.6158, 0.4855, 0.5834, 0.5572, 0.4077],\n       [0.4907, 0.4644, 0.3349, 0.424 , 0.3874, 0.2538],\n       [0.4879, 0.4879, 0.3412, 0.4433, 0.4357, 0.2728],\n       [0.4084, 0.3884, 0.2609, 0.355 , 0.3262, 0.1975],\n       [0.4832, 0.4686, 0.3329, 0.4856, 0.4487, 0.3074],\n       [0.6507, 0.6351, 0.541 , 0.8737, 0.8147, 0.798 ],\n       [0.1713, 0.1761, 0.0861, 0.1405, 0.1388, 0.0589],\n       [0.3128, 0.2997, 0.1771, 0.2444, 0.2353, 0.1171],\n       [0.2787, 0.2667, 0.1564, 0.2124, 0.1935, 0.1013],\n       [0.1765, 0.1777, 0.0854, 0.1338, 0.13  , 0.0553],\n       [0.3459, 0.3214, 0.2075, 0.2483, 0.2193, 0.1227],\n       [0.2039, 0.1965, 0.1037, 0.1562, 0.1388, 0.0669],\n       [0.699 , 0.7153, 0.5716, 0.7207, 0.7246, 0.5404],\n       [0.1307, 0.1224, 0.0621, 0.1003, 0.0881, 0.0418],\n       [0.5182, 0.4935, 0.3628, 0.4621, 0.4218, 0.2789],\n       [0.2323, 0.224 , 0.1239, 0.159 , 0.1447, 0.0706],\n       [0.2058, 0.1935, 0.1074, 0.1519, 0.1343, 0.067 ],\n       [0.5598, 0.5329, 0.4066, 0.428 , 0.3914, 0.2583],\n       [0.3128, 0.2933, 0.1819, 0.2693, 0.2415, 0.1361],\n       [0.3251, 0.3123, 0.1883, 0.2508, 0.2389, 0.1192],\n       [0.5764, 0.5695, 0.4218, 0.5617, 0.5448, 0.3782],\n       [0.2252, 0.2104, 0.1204, 0.1914, 0.1708, 0.0857],\n       [0.5878, 0.5764, 0.4248, 0.5642, 0.5079, 0.3546],\n       [0.4382, 0.4492, 0.2806, 0.3778, 0.3809, 0.2079],\n       [0.2797, 0.2784, 0.1583, 0.2124, 0.2077, 0.1009],\n       [0.265 , 0.249 , 0.1466, 0.1982, 0.1751, 0.0931],\n       [0.2347, 0.2355, 0.1262, 0.1889, 0.2081, 0.0887],\n       [0.2797, 0.2633, 0.158 , 0.2024, 0.1842, 0.0963],\n       [0.2025, 0.2068, 0.1063, 0.1398, 0.1388, 0.062 ],\n       [0.2077, 0.1961, 0.1071, 0.1576, 0.1438, 0.0674],\n       [0.3516, 0.361 , 0.2153, 0.2789, 0.2554, 0.1431],\n       [0.3776, 0.3679, 0.2307, 0.296 , 0.2923, 0.1535],\n       [0.2825, 0.2719, 0.157 , 0.2067, 0.1912, 0.0984],\n       [0.2304, 0.2194, 0.1227, 0.1825, 0.169 , 0.0817],\n       [0.2716, 0.2625, 0.1479, 0.1982, 0.1899, 0.0906],\n       [0.3213, 0.3059, 0.1863, 0.2398, 0.2179, 0.117 ],\n       [0.186 , 0.1752, 0.0934, 0.1224, 0.1096, 0.0509],\n       [0.2262, 0.2157, 0.122 , 0.1932, 0.1728, 0.0905],\n       [0.3445, 0.3278, 0.2077, 0.2949, 0.2759, 0.1559],\n       [0.167 , 0.1594, 0.0809, 0.1067, 0.0981, 0.0436],\n       [0.5939, 0.5923, 0.4554, 0.6403, 0.6011, 0.4591],\n       [0.2593, 0.2532, 0.139 , 0.1967, 0.1879, 0.09  ],\n       [0.6204, 0.6282, 0.4681, 0.5603, 0.5398, 0.3713],\n       [0.1661, 0.1594, 0.0809, 0.1113, 0.1013, 0.0467],\n       [0.212 , 0.2059, 0.1101, 0.169 , 0.1608, 0.0749],\n       [0.2186, 0.2104, 0.1161, 0.1604, 0.1543, 0.0716],\n       [0.2943, 0.2783, 0.167 , 0.2305, 0.2071, 0.111 ],\n       [0.0956, 0.0869, 0.0436, 0.0629, 0.0522, 0.0247],\n       [0.3085, 0.2895, 0.1793, 0.2504, 0.2245, 0.1262],\n       [0.2872, 0.269 , 0.1642, 0.2419, 0.2169, 0.1197],\n       [0.2233, 0.211 , 0.1167, 0.1665, 0.1519, 0.0732],\n       [0.3611, 0.3378, 0.2212, 0.3035, 0.2654, 0.1611],\n       [0.2735, 0.266 , 0.153 , 0.2227, 0.2073, 0.1066],\n       [0.2158, 0.2069, 0.1127, 0.1569, 0.1535, 0.0695],\n       [0.0765, 0.0712, 0.033 , 0.0364, 0.0311, 0.0135],\n       [0.2607, 0.2446, 0.1434, 0.1925, 0.1697, 0.0882],\n       [0.2461, 0.2312, 0.1348, 0.175 , 0.1553, 0.0806],\n       [0.5319, 0.5177, 0.3748, 0.4948, 0.4507, 0.3195],\n       [0.0975, 0.1125, 0.0428, 0.0758, 0.0907, 0.0275],\n       [0.2579, 0.2406, 0.1416, 0.1768, 0.1561, 0.0813],\n       [0.1547, 0.1571, 0.0766, 0.1192, 0.1052, 0.0504],\n       [0.6237, 0.6033, 0.4795, 0.5382, 0.497 , 0.3617],\n       [0.2782, 0.2697, 0.1533, 0.2174, 0.2111, 0.1018],\n       [0.6323, 0.6365, 0.4753, 0.6179, 0.6011, 0.4308],\n       [0.247 , 0.2365, 0.1334, 0.207 , 0.2027, 0.0978],\n       [0.2693, 0.2589, 0.1469, 0.2056, 0.1907, 0.0957],\n       [0.3374, 0.3195, 0.2006, 0.2704, 0.239 , 0.1388],\n       [0.239 , 0.2232, 0.1283, 0.1829, 0.161 , 0.0831],\n       [0.4396, 0.4361, 0.2843, 0.4038, 0.3954, 0.23  ],\n       [0.4392, 0.4403, 0.2898, 0.3486, 0.3152, 0.1942],\n       [0.4283, 0.4285, 0.2756, 0.3853, 0.368 , 0.2175],\n       [0.2839, 0.2815, 0.1572, 0.2309, 0.243 , 0.1104],\n       [0.2006, 0.1945, 0.1034, 0.1441, 0.132 , 0.0617],\n       [0.202 , 0.1907, 0.1046, 0.1718, 0.1577, 0.0756],\n       [0.2517, 0.2356, 0.1361, 0.1928, 0.1699, 0.0883],\n       [0.477 , 0.47  , 0.3288, 0.4646, 0.4621, 0.2892],\n       [0.2844, 0.2784, 0.1573, 0.206 , 0.1841, 0.096 ],\n       [0.558 , 0.5467, 0.4023, 0.5909, 0.5513, 0.4148],\n       [0.1453, 0.1425, 0.071 , 0.1149, 0.1074, 0.0489],\n       [0.7823, 0.7692, 0.6802, 0.809 , 0.757 , 0.6687],\n       [0.3521, 0.348 , 0.2111, 0.3109, 0.3038, 0.1664],\n       [0.1242, 0.1234, 0.0581, 0.1003, 0.1038, 0.0414],\n       [0.1931, 0.1914, 0.0977, 0.1419, 0.1462, 0.0626],\n       [0.601 , 0.5951, 0.4456, 0.5272, 0.5338, 0.333 ],\n       [0.2238, 0.2159, 0.1174, 0.1825, 0.1681, 0.0814],\n       [0.1552, 0.1549, 0.0755, 0.1049, 0.102 , 0.0422],\n       [0.2404, 0.2271, 0.128 , 0.2031, 0.1799, 0.0928],\n       [0.3682, 0.353 , 0.2228, 0.3323, 0.3177, 0.171 ],\n       [0.2125, 0.202 , 0.1099, 0.1629, 0.1457, 0.0714],\n       [0.2352, 0.2311, 0.1201, 0.1736, 0.1628, 0.0764],\n       [0.2214, 0.2067, 0.1177, 0.1903, 0.1653, 0.0878],\n       [0.415 , 0.4375, 0.2609, 0.3355, 0.3436, 0.1794],\n       [0.8874, 0.9012, 0.7917, 0.8965, 0.8909, 0.7493],\n       [0.3833, 0.3746, 0.2431, 0.3764, 0.3526, 0.2125],\n       [0.1968, 0.1897, 0.1023, 0.1491, 0.1455, 0.0659],\n       [0.264 , 0.2635, 0.1452, 0.1935, 0.1923, 0.089 ],\n       [0.2872, 0.2854, 0.1563, 0.2227, 0.2182, 0.0998],\n       [0.326 , 0.3091, 0.191 , 0.2554, 0.2307, 0.1251],\n       [0.0898, 0.0895, 0.0414, 0.073 , 0.074 , 0.0287],\n       [0.1162, 0.1108, 0.0573, 0.1455, 0.1264, 0.0625],\n       [0.2631, 0.2462, 0.1478, 0.206 , 0.1813, 0.0984],\n       [0.2991, 0.2864, 0.1708, 0.2231, 0.2118, 0.1072],\n       [0.2735, 0.2631, 0.1498, 0.207 , 0.1863, 0.097 ],\n       [0.4505, 0.434 , 0.2946, 0.3629, 0.3326, 0.2025],\n       [0.3038, 0.2881, 0.1734, 0.2419, 0.2159, 0.1176],\n       [0.637 , 0.622 , 0.4876, 0.5827, 0.5518, 0.392 ],\n       [0.6256, 0.6213, 0.4626, 0.5784, 0.5458, 0.3652],\n       [0.2475, 0.2385, 0.1336, 0.2263, 0.2163, 0.108 ],\n       [0.6971, 0.6711, 0.5949, 0.8118, 0.7425, 0.7269],\n       [0.7113, 0.7146, 0.5678, 0.7019, 0.7201, 0.5018],\n       [0.4434, 0.4506, 0.2956, 0.4073, 0.3929, 0.2408],\n       [0.3885, 0.3722, 0.2411, 0.2942, 0.2694, 0.1558],\n       [0.681 , 0.6738, 0.527 , 0.5251, 0.5064, 0.3317],\n       [0.6465, 0.6289, 0.5054, 0.6204, 0.5797, 0.4328],\n       [0.3175, 0.3044, 0.1848, 0.2458, 0.2428, 0.1193],\n       [0.4349, 0.432 , 0.2736, 0.3216, 0.3122, 0.1662],\n       [0.1699, 0.1822, 0.0826, 0.1039, 0.13  , 0.041 ],\n       [0.3066, 0.2909, 0.1776, 0.2405, 0.2326, 0.1218],\n       [0.3161, 0.3074, 0.1854, 0.2351, 0.2368, 0.116 ],\n       [0.194 , 0.2039, 0.0925, 0.1889, 0.2059, 0.0794],\n       [0.203 , 0.203 , 0.103 , 0.1747, 0.1719, 0.0715],\n       [0.1921, 0.1858, 0.0972, 0.148 , 0.146 , 0.0644],\n       [0.2399, 0.2416, 0.1291, 0.1651, 0.184 , 0.0745],\n       [0.256 , 0.2546, 0.1355, 0.2223, 0.2232, 0.1021],\n       [0.2981, 0.2902, 0.169 , 0.2245, 0.23  , 0.1078],\n       [0.3606, 0.3468, 0.2211, 0.2796, 0.2579, 0.1408],\n       [0.2475, 0.2418, 0.1351, 0.185 , 0.1855, 0.0847],\n       [0.3265, 0.3081, 0.1922, 0.2697, 0.2453, 0.1377],\n       [0.203 , 0.2045, 0.1054, 0.1462, 0.146 , 0.0651],\n       [0.5949, 0.5881, 0.4371, 0.4586, 0.4561, 0.2772],\n       [0.1552, 0.1518, 0.0755, 0.1227, 0.1137, 0.0514],\n       [0.083 , 0.0793, 0.0385, 0.0797, 0.0677, 0.0324],\n       [0.4027, 0.405 , 0.255 , 0.4721, 0.4566, 0.2885],\n       [0.6924, 0.6953, 0.5359, 0.651 , 0.6056, 0.4659],\n       [0.2423, 0.2369, 0.1284, 0.2003, 0.1889, 0.092 ],\n       [0.335 , 0.3176, 0.1975, 0.2487, 0.2291, 0.1227],\n       [0.309 , 0.3062, 0.1759, 0.2444, 0.2337, 0.1204],\n       [0.2754, 0.2713, 0.1547, 0.2067, 0.2008, 0.0997],\n       [0.1931, 0.1833, 0.0996, 0.169 , 0.1513, 0.0766],\n       [0.2281, 0.2175, 0.1223, 0.1964, 0.1772, 0.0926],\n       [0.5173, 0.557 , 0.3608, 0.4578, 0.494 , 0.275 ],\n       [0.2342, 0.2236, 0.1269, 0.2088, 0.1854, 0.0994],\n       [0.283 , 0.2791, 0.1619, 0.2206, 0.2286, 0.1073],\n       [0.282 , 0.2722, 0.1544, 0.211 , 0.1956, 0.0973],\n       [0.2536, 0.2384, 0.1381, 0.1868, 0.1678, 0.0855],\n       [0.1874, 0.1838, 0.0961, 0.159 , 0.1611, 0.0706],\n       [0.4335, 0.4181, 0.2785, 0.3479, 0.3262, 0.1875],\n       [0.2778, 0.2684, 0.1574, 0.2302, 0.2053, 0.1132],\n       [0.521 , 0.5114, 0.3598, 0.4678, 0.4367, 0.286 ],\n       [0.2503, 0.2392, 0.1368, 0.2195, 0.1922, 0.1045],\n       [0.2073, 0.1983, 0.1087, 0.1821, 0.1726, 0.0826],\n       [0.1921, 0.1875, 0.0974, 0.1594, 0.147 , 0.0703],\n       [0.1143, 0.1103, 0.0531, 0.0724, 0.0807, 0.0285],\n       [0.3791, 0.3714, 0.2334, 0.3141, 0.2978, 0.1676],\n       [0.3857, 0.3657, 0.2443, 0.3319, 0.2973, 0.1834],\n       [0.2323, 0.2253, 0.1231, 0.1821, 0.1727, 0.083 ],\n       [0.1147, 0.1093, 0.0542, 0.1039, 0.0912, 0.0428],\n       [0.4032, 0.4085, 0.2798, 0.5422, 0.5314, 0.3841],\n       [0.2707, 0.2563, 0.1491, 0.2035, 0.1878, 0.0938],\n       [0.1978, 0.1877, 0.1004, 0.1576, 0.1437, 0.067 ],\n       [0.2172, 0.2101, 0.1129, 0.1829, 0.1794, 0.0824],\n       [0.3649, 0.3761, 0.2174, 0.3035, 0.3172, 0.1534],\n       [0.2191, 0.2189, 0.1123, 0.1676, 0.157 , 0.0714],\n       [0.3161, 0.3156, 0.1832, 0.2565, 0.2539, 0.1287],\n       [0.1307, 0.1254, 0.062 , 0.1167, 0.1065, 0.0481],\n       [0.1443, 0.1341, 0.0695, 0.1131, 0.0972, 0.047 ],\n       [0.1656, 0.1638, 0.0806, 0.1494, 0.1544, 0.0627],\n       [0.1807, 0.1728, 0.0918, 0.1718, 0.1657, 0.0748],\n       [0.1964, 0.1844, 0.1008, 0.1334, 0.1192, 0.058 ],\n       [0.2716, 0.257 , 0.1518, 0.2095, 0.1915, 0.0987],\n       [0.3748, 0.4029, 0.2297, 0.2995, 0.3735, 0.1591],\n       [0.2565, 0.2604, 0.1376, 0.1761, 0.1952, 0.0813],\n       [0.6247, 0.622 , 0.4694, 0.5016, 0.4761, 0.318 ],\n       [0.5603, 0.5522, 0.41  , 0.524 , 0.4726, 0.3485],\n       [0.3729, 0.3531, 0.2249, 0.2981, 0.2584, 0.1456],\n       [0.3313, 0.3271, 0.1934, 0.3241, 0.3162, 0.1681],\n       [0.2787, 0.2687, 0.1551, 0.2319, 0.2228, 0.1086],\n       [0.3341, 0.3178, 0.1984, 0.275 , 0.253 , 0.1388],\n       [0.3251, 0.3102, 0.1905, 0.2739, 0.2515, 0.1386],\n       [0.3331, 0.3165, 0.1964, 0.2483, 0.2297, 0.1238],\n       [0.1888, 0.1931, 0.0967, 0.1576, 0.1979, 0.0716],\n       [0.487 , 0.4741, 0.3331, 0.4429, 0.4103, 0.2701],\n       [0.3218, 0.3081, 0.1877, 0.2611, 0.2365, 0.1281],\n       [0.1699, 0.1591, 0.0837, 0.1071, 0.0943, 0.0445],\n       [0.5229, 0.5094, 0.3591, 0.4429, 0.4128, 0.272 ],\n       [0.2371, 0.2337, 0.1263, 0.1797, 0.1697, 0.0808],\n       [0.5097, 0.508 , 0.3555, 0.4838, 0.4731, 0.3077],\n       [0.3701, 0.36  , 0.2254, 0.3024, 0.2764, 0.1584],\n       [0.3573, 0.3487, 0.219 , 0.2978, 0.2873, 0.1586],\n       [0.6682, 0.6517, 0.5262, 0.6314, 0.5866, 0.4514],\n       [0.2314, 0.2283, 0.1224, 0.1729, 0.1648, 0.0791],\n       [0.5968, 0.5798, 0.4443, 0.4806, 0.4452, 0.3037],\n       [0.2375, 0.2279, 0.1268, 0.1836, 0.1726, 0.0832],\n       [0.3573, 0.346 , 0.2124, 0.28  , 0.2624, 0.1388],\n       [0.2669, 0.2545, 0.1482, 0.228 , 0.2052, 0.1102],\n       [0.3029, 0.294 , 0.1755, 0.2533, 0.2305, 0.1279],\n       [0.22  , 0.2148, 0.1152, 0.1846, 0.1774, 0.0842],\n       [0.2948, 0.2786, 0.1673, 0.2284, 0.2036, 0.11  ],\n       [0.2849, 0.2683, 0.1598, 0.228 , 0.2025, 0.109 ],\n       [0.1313, 0.1236, 0.0625, 0.0975, 0.0878, 0.0405],\n       [0.478 , 0.4658, 0.334 , 0.5347, 0.5064, 0.3595],\n       [0.9673, 0.9889, 1.    , 1.    , 1.    , 1.    ],\n       [0.3511, 0.3349, 0.2132, 0.2657, 0.249 , 0.135 ],\n       [0.2186, 0.2079, 0.1142, 0.1722, 0.1607, 0.0762],\n       [0.2929, 0.2798, 0.167 , 0.248 , 0.2226, 0.1235],\n       [0.2962, 0.2977, 0.1694, 0.2672, 0.3217, 0.1348],\n       [0.2915, 0.2915, 0.1669, 0.2444, 0.2515, 0.1238],\n       [0.1272, 0.1193, 0.0606, 0.1145, 0.1031, 0.0479],\n       [0.5026, 0.5197, 0.355 , 0.4852, 0.4641, 0.3077],\n       [0.2196, 0.2252, 0.1125, 0.1932, 0.1879, 0.0843],\n       [0.1271, 0.1223, 0.0618, 0.1142, 0.1019, 0.0492],\n       [0.2394, 0.2285, 0.13  , 0.2017, 0.1834, 0.094 ],\n       [0.3757, 0.3639, 0.2305, 0.3291, 0.3067, 0.1773],\n       [0.2503, 0.2324, 0.1365, 0.1964, 0.1727, 0.0918],\n       [0.1845, 0.184 , 0.0914, 0.1427, 0.1513, 0.0609],\n       [0.2768, 0.2702, 0.1541, 0.2191, 0.2132, 0.1034],\n       [0.3417, 0.336 , 0.2014, 0.3031, 0.3072, 0.1581],\n       [0.3275, 0.3122, 0.1934, 0.2565, 0.253 , 0.1312],\n       [0.2134, 0.2087, 0.1109, 0.159 , 0.1575, 0.0694],\n       [0.4387, 0.4562, 0.2852, 0.3365, 0.357 , 0.1854],\n       [0.2451, 0.2384, 0.1323, 0.1925, 0.1913, 0.089 ],\n       [0.3275, 0.3106, 0.1949, 0.3017, 0.2689, 0.1586],\n       [0.3071, 0.3008, 0.1709, 0.2455, 0.2218, 0.1167],\n       [0.318 , 0.3038, 0.1814, 0.2501, 0.226 , 0.1232],\n       [0.4141, 0.4078, 0.2561, 0.323 , 0.3092, 0.1644],\n       [0.2588, 0.2699, 0.1413, 0.2081, 0.2361, 0.0972],\n       [0.3625, 0.3484, 0.2216, 0.3035, 0.2769, 0.1587],\n       [0.5897, 0.5826, 0.4341, 0.5703, 0.5154, 0.3821],\n       [0.2224, 0.2191, 0.1175, 0.1917, 0.1801, 0.0896],\n       [0.4595, 0.4375, 0.3029, 0.4002, 0.3829, 0.2209],\n       [0.2494, 0.2376, 0.137 , 0.222 , 0.2108, 0.1076],\n       [0.5144, 0.4893, 0.36  , 0.423 , 0.3819, 0.2519],\n       [0.522 , 0.5156, 0.3663, 0.4838, 0.4631, 0.305 ],\n       [0.2593, 0.2421, 0.1416, 0.1871, 0.1635, 0.0857],\n       [0.2924, 0.2783, 0.1676, 0.2337, 0.2235, 0.1138],\n       [0.3734, 0.3616, 0.228 , 0.2874, 0.2664, 0.1471],\n       [0.2683, 0.2688, 0.1451, 0.2295, 0.2235, 0.1102],\n       [0.2598, 0.2533, 0.1428, 0.2181, 0.2112, 0.1037],\n       [0.5447, 0.5356, 0.3922, 0.5272, 0.4781, 0.3477],\n       [0.6441, 0.6496, 0.499 , 0.5667, 0.5617, 0.387 ],\n       [0.3814, 0.3797, 0.2316, 0.3141, 0.2953, 0.1651],\n       [0.3237, 0.3354, 0.1919, 0.2874, 0.2769, 0.1482],\n       [0.2631, 0.2589, 0.1412, 0.2006, 0.1806, 0.0901],\n       [0.7624, 0.7485, 0.6526, 0.8132, 0.8023, 0.6382],\n       [0.1082, 0.1223, 0.0446, 0.0836, 0.0928, 0.0283],\n       [0.1275, 0.1405, 0.0547, 0.095 , 0.0949, 0.0351],\n       [0.248 , 0.2466, 0.1313, 0.1861, 0.1729, 0.0811],\n       [0.1931, 0.1898, 0.0946, 0.1338, 0.1278, 0.0555],\n       [0.4411, 0.4209, 0.2869, 0.334 , 0.2958, 0.1826],\n       [0.4013, 0.4147, 0.2493, 0.3266, 0.3351, 0.178 ],\n       [0.2252, 0.2247, 0.1198, 0.1608, 0.1536, 0.0709],\n       [0.3705, 0.3515, 0.2279, 0.2732, 0.2554, 0.1413],\n       [0.3038, 0.3099, 0.1753, 0.3017, 0.3132, 0.162 ],\n       [0.3596, 0.349 , 0.2186, 0.3141, 0.2893, 0.1663],\n       [0.3819, 0.3695, 0.2369, 0.3433, 0.3157, 0.1921],\n       [0.2063, 0.2002, 0.1051, 0.1615, 0.1431, 0.0721],\n       [0.5362, 0.5322, 0.3854, 0.4956, 0.4571, 0.3214],\n       [0.611 , 0.5992, 0.4541, 0.5621, 0.5483, 0.359 ],\n       [0.2792, 0.281 , 0.1483, 0.2533, 0.2435, 0.1203],\n       [0.273 , 0.2676, 0.1486, 0.2319, 0.2152, 0.1079],\n       [0.1095, 0.1117, 0.0485, 0.0939, 0.0868, 0.0348],\n       [0.8353, 0.8411, 0.72  , 0.7823, 0.7734, 0.6038],\n       [0.2025, 0.1901, 0.1038, 0.1423, 0.1293, 0.0616],\n       [0.3185, 0.3106, 0.1813, 0.2554, 0.2441, 0.127 ],\n       [0.1356, 0.1327, 0.0635, 0.1178, 0.1191, 0.047 ],\n       [0.0753, 0.0742, 0.033 , 0.0549, 0.0642, 0.0222],\n       [0.3066, 0.3016, 0.1729, 0.264 , 0.2564, 0.1314],\n       [0.2536, 0.2429, 0.1379, 0.2021, 0.1833, 0.0933],\n       [0.3294, 0.3215, 0.1912, 0.238 , 0.2197, 0.115 ],\n       [0.2409, 0.2352, 0.128 , 0.1964, 0.1818, 0.0896],\n       [0.2257, 0.2218, 0.1185, 0.1982, 0.1898, 0.0902],\n       [0.2219, 0.2171, 0.1157, 0.1928, 0.1822, 0.0898],\n       [0.3171, 0.3038, 0.1832, 0.2818, 0.2549, 0.1446],\n       [0.6384, 0.6282, 0.4901, 0.5443, 0.506 , 0.3588],\n       [0.1883, 0.1866, 0.0942, 0.1313, 0.1296, 0.0546],\n       [0.6422, 0.6496, 0.494 , 0.5824, 0.5468, 0.3991],\n       [0.345 , 0.3454, 0.2063, 0.2618, 0.2684, 0.1335],\n       [0.2229, 0.2251, 0.1115, 0.1797, 0.1778, 0.0743],\n       [0.0354, 0.029 , 0.015 , 0.0408, 0.0337, 0.0154],\n       [0.0336, 0.0314, 0.0114, 0.0266, 0.0203, 0.0094],\n       [0.2158, 0.2133, 0.11  , 0.154 , 0.1413, 0.067 ],\n       [0.3544, 0.3595, 0.2176, 0.2949, 0.3142, 0.1533],\n       [0.3672, 0.3518, 0.2227, 0.3052, 0.2838, 0.1576],\n       [0.2948, 0.2839, 0.1675, 0.2291, 0.2095, 0.1092],\n       [0.326 , 0.3177, 0.1872, 0.2533, 0.2428, 0.1237],\n       [0.3142, 0.2999, 0.1823, 0.264 , 0.2349, 0.1338],\n       [0.158 , 0.1487, 0.0769, 0.1181, 0.1031, 0.0491],\n       [0.1552, 0.1524, 0.0752, 0.1032, 0.1029, 0.0423],\n       [0.1279, 0.1193, 0.0603, 0.1067, 0.0931, 0.044 ],\n       [0.1817, 0.1735, 0.0925, 0.1814, 0.1668, 0.0787],\n       [0.1836, 0.1708, 0.092 , 0.1327, 0.1179, 0.0558],\n       [0.1964, 0.1914, 0.0996, 0.1455, 0.1364, 0.0618],\n       [0.274 , 0.2596, 0.1546, 0.2113, 0.1877, 0.1006],\n       [0.1113, 0.1052, 0.0511, 0.0681, 0.062 , 0.0272],\n       [0.2792, 0.2675, 0.1573, 0.212 , 0.1914, 0.1009],\n       [0.1566, 0.1512, 0.0755, 0.1035, 0.0954, 0.0424],\n       [0.1505, 0.1447, 0.0713, 0.0968, 0.087 , 0.0398],\n       [0.1156, 0.1069, 0.0542, 0.0911, 0.0801, 0.0357],\n       [0.3601, 0.3635, 0.2179, 0.2686, 0.2764, 0.1348],\n       [0.2143, 0.2124, 0.1103, 0.1619, 0.1587, 0.071 ],\n       [0.3346, 0.3289, 0.1938, 0.2622, 0.248 , 0.1282],\n       [0.1997, 0.1858, 0.1029, 0.1419, 0.1234, 0.0625],\n       [0.3899, 0.4119, 0.2432, 0.3412, 0.3899, 0.1794],\n       [0.6597, 0.6856, 0.5105, 0.582 , 0.6409, 0.4015],\n       [0.69  , 0.6787, 0.5665, 0.6233, 0.5762, 0.4527],\n       [0.6223, 0.604 , 0.474 , 0.5607, 0.5209, 0.3799],\n       [0.4553, 0.4458, 0.3031, 0.3931, 0.3799, 0.2307],\n       [0.6446, 0.6655, 0.4757, 0.6336, 0.6683, 0.402 ],\n       [0.0369, 0.0285, 0.0159, 0.0543, 0.0436, 0.0205]])"
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "scaled_set = scaler.fit_transform(filtered_data.to_numpy())\n",
    "scaled_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = fill_nan(scaled_data, scaled_data.size*0.2)\n",
    "\n",
    "input_tensor = torch.from_numpy(missing_data)\n",
    "input_tensor = input_tensor.view(input_tensor.shape[0], NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0000, 0.5460, 0.3637, 0.6208, 0.6683, 0.4507],\n        [0.6431, 0.0000, 0.5016, 0.0000, 0.5398, 0.4352],\n        [0.6015, 0.5957, 0.4494, 0.5564, 0.5084, 0.3745],\n        ...,\n        [0.4553, 0.4458, 0.0000, 0.3931, 0.3799, 0.0000],\n        [0.6446, 0.6655, 0.0000, 0.0000, 0.6683, 0.4020],\n        [0.0369, 0.0285, 0.0159, 0.0543, 0.0436, 0.0205]], dtype=torch.float64)"
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Autoencoder(\n  (enc1): Linear(in_features=6, out_features=4, bias=True)\n  (enc2): Linear(in_features=4, out_features=3, bias=True)\n  (enc3): Linear(in_features=3, out_features=2, bias=True)\n  (dec1): Linear(in_features=2, out_features=3, bias=True)\n  (dec2): Linear(in_features=3, out_features=4, bias=True)\n  (dec3): Linear(in_features=4, out_features=6, bias=True)\n)"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = torch.load('breast_autoencoder3')\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5451, 0.5367, 0.3880, 0.4945, 0.4702, 0.3162],\n        [0.4707, 0.4615, 0.3166, 0.4151, 0.3939, 0.2476],\n        [0.5940, 0.5875, 0.4454, 0.5469, 0.5239, 0.3739],\n        ...,\n        [0.3305, 0.3218, 0.1962, 0.2658, 0.2553, 0.1356],\n        [0.4777, 0.4684, 0.3226, 0.4225, 0.4008, 0.2531],\n        [0.0564, 0.0521, 0.0178, 0.0297, 0.0278, 0.0053]], dtype=torch.float64,\n       grad_fn=<AddmmBackward>)"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = my_model(input_tensor.double())\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "777,  866.0888,   19.2463,  127.1696, 1154.2572],\n       [   9.1222,   57.7154,  251.7255,    9.8216,   63.3015,  286.7583],\n       [   7.6546,   47.8477,  149.4457,    8.1878,   51.9996,  163.9222],\n       [   8.6782,   54.7291,  220.6866,    9.3267,   59.8776,  249.3709],\n       [  10.4269,   66.493 ,  343.1335,   11.277 ,   73.3726,  397.0921],\n       [   8.3575,   52.5715,  198.2041,    8.9689,   57.4015,  222.216 ],\n       [  11.4594,   73.4387,  415.4787,   12.4287,   81.3425,  484.4336],\n       [  11.3737,   72.8616,  409.4034,   12.3327,   80.6776,  477.0165],\n       [   9.2014,   58.2484,  257.2903,    9.91  ,   63.9137,  293.4933],\n       [  12.6562,   81.4891,  499.1931,   13.7629,   90.5743,  585.3242],\n       [  11.0649,   70.7846,  387.8276,   11.9885,   78.2968,  451.0428],\n       [  10.415 ,   66.4124,  342.2576,   11.2634,   73.2787,  395.9874],\n       [   8.2848,   52.0832,  193.1563,    8.8881,   56.8427,  216.171 ],\n       [   9.6768,   61.4466,  290.6066,   10.4404,   67.5836,  333.7223],\n       [  11.4266,   73.2175,  413.1275,   12.3918,   81.0868,  481.5337],\n       [  13.2972,   85.8015,  544.1556,   14.4782,   95.5245,  639.6657],\n       [   8.4279,   53.0452,  203.1076,    9.0473,   57.9438,  228.0962],\n       [   8.8325,   55.7676,  231.5011,    9.4989,   61.0692,  262.4232],\n       [   7.9209,   49.6373,  167.917 ,    8.4838,   54.0461,  186.0043],\n       [  11.7884,   75.6513,  438.454 ,   12.7952,   83.8784,  512.0805],\n       [   8.5253,   53.7004,  209.9198,    9.1559,   58.6951,  236.3041],\n       [  10.0071,   63.6695,  313.8046,   10.8092,   70.1362,  361.7862],\n       [  11.471 ,   73.517 ,  416.2886,   12.4416,   81.4321,  485.4042],\n       [   9.2611,   58.6504,  261.503 ,    9.9768,   64.376 ,  298.6131],\n       [  11.7983,   75.7189,  439.204 ,   12.8066,   83.9579,  513.0454],\n       [   7.8061,   48.8657,  159.936 ,    8.3561,   53.163 ,  176.4415],\n       [  10.717 ,   68.4446,  363.4793,   11.6007,   75.6128,  421.6789],\n       [  14.9259,   96.9144,  698.252 ,   16.7635,  110.7041,  884.8953],\n       [  10.7865,   68.9118,  368.2852,   11.6778,   76.1464,  427.4026],\n       [  10.9379,   69.9303,  378.9317,   11.8469,   77.3166,  440.305 ],\n       [   8.7454,   55.181 ,  225.3631,    9.4015,   60.3949,  254.9773],\n       [   9.3504,   59.2512,  267.7413,   10.0763,   65.0645,  306.1196],\n       [  11.4216,   73.1839,  412.7639,   12.3861,   81.0477,  481.0772],\n       [  11.1175,   71.1387,  391.5477,   12.0474,   78.7044,  455.5747],\n       [  10.202 ,   64.9795,  327.3724,   11.026 ,   71.6361,  378.0675],\n       [  14.2251,   92.1301,  631.1678,   15.7704,  104.12  ,  777.2528],\n       [   8.2831,   52.071 ,  192.9734,    8.8858,   56.8264,  215.8783],\n       [  16.9446,  110.6978,  891.6764,   19.6239,  129.6754, 1195.3548],\n       [  11.4296,   73.238 ,  413.3327,   12.3951,   81.1099,  481.7716],\n       [   8.5539,   53.8927,  211.9514,    9.1879,   58.9169,  238.7946],\n       [   9.8092,   62.3371,  299.8311,   10.5878,   68.6033,  344.7936],\n       [  14.004 ,   90.6202,  609.9483,   15.4572,  102.0413,  743.176 ],\n       [  10.3275,   65.824 ,  336.1683,   11.166 ,   72.6051,  388.6864],\n       [   7.7041,   48.1801,  152.8596,    8.2427,   52.379 ,  167.9822],\n       [  10.5978,   67.6425,  355.1157,   11.4676,   74.692 ,  411.5697],\n       [  13.8006,   89.2308,  590.4397,   15.1689,  100.1288,  711.8566],\n       [   8.6734,   54.6967,  220.3112,    9.3212,   59.8389,  248.8679],\n       [   9.0827,   57.4494,  248.9286,    9.7774,   62.9952,  283.3474],\n       [   8.7933,   55.5031,  228.7077,    9.4549,   60.764 ,  259.0022],\n       [  13.7647,   88.9853,  586.9655,   15.118 ,   99.7904,  706.2626],\n       [  21.1127,  140.0753, 1400.4051,   25.5584,  172.1367, 2066.0963],\n       [  10.2101,   65.0348,  328.0267,   11.0356,   71.7028,  378.9586],\n       [   9.9268,   63.129 ,  308.1216,   10.7193,   69.5137,  354.8573],\n       [  10.3713,   66.1187,  339.2495,   11.215 ,   72.9438,  392.4211],\n       [   9.1811,   58.1121,  255.8786,    9.8875,   63.7576,  291.8001],\n       [   9.901 ,   62.9549,  306.2789,   10.6903,   69.3128,  352.5939],\n       [   8.2211,   51.6546,  188.7227,    8.8172,   56.3523,  210.8574],\n       [   8.6505,   54.5433,  218.7596,    9.296 ,   59.6648,  247.0542],\n       [  10.8867,   69.5858,  375.3031,   11.7896,   76.9196,  435.8731],\n       [  10.1679,   64.7507,  325.03  ,   10.9883,   71.3753,  375.2925],\n       [   9.7606,   62.011 ,  296.5311,   10.5342,   68.2331,  340.9344],\n       [  14.581 ,   94.5601,  665.2569,   16.2748,  107.4645,  831.9611],\n       [  10.6861,   68.2361,  361.2265,   11.5657,   75.3702,  418.8546],\n       [  18.5315,  121.6913, 1062.6158,   21.8774,  145.1569, 1479.0865],\n       [  16.5701,  108.1402,  855.7519,   19.0932,  126.1547, 1137.673 ],\n       [  10.6995,   68.327 ,  362.2469,   11.5811,   75.4775,  420.1818],\n       [  20.3731,  134.8076, 1303.6181,   24.5037,  164.4062, 1897.8996],\n       [  10.0069,   63.6686,  313.8284,   10.8092,   70.1365,  361.858 ],\n       [  13.7844,   89.1209,  588.9234,   15.146 ,   99.978 ,  709.4379],\n       [  12.6946,   81.7473,  501.9159,   13.8059,   90.872 ,  588.6544],\n       [  16.2944,  106.2574,  829.3311,   18.7025,  123.5632, 1095.2668],\n       [  14.5999,   94.689 ,  667.0663,   16.3015,  107.6419,  834.8661],\n       [  10.9585,   70.0685,  380.3398,   11.8697,   77.4739,  441.9643],\n       [  14.5641,   94.444 ,  663.5763,   16.2508,  107.3038,  829.2338],\n       [   8.5425,   53.8163,  211.1513,    9.1752,   58.8291,  237.8231],\n       [  10.0887,   64.2181,  319.5052,   10.9001,   70.7651,  368.6515],\n       [   9.3102,   58.9806,  264.9198,   10.0315,   64.754 ,  302.7083],\n       [  10.9169,   69.7888,  377.4109,   11.8232,   77.1523,  438.4091],\n       [   8.678 ,   54.7274,  220.63  ,    9.3263,   59.874 ,  249.2525],\n       [   9.3698,   59.3816,  269.073 ,   10.0978,   65.2131,  307.6925],\n       [  10.8854,   69.577 ,  375.1962,   11.788 ,   76.9089,  435.7234],\n       [  10.151 ,   64.6368,  323.819 ,   10.9693,   71.2436,  373.7983],\n       [  10.2885,   65.561 ,  333.3747,   11.1222,   72.3011,  385.2434],\n       [  10.0447,   63.9218,  316.3889,   10.8508,   70.4239,  364.8498],\n       [  11.248 ,   72.0165,  400.6191,   12.1926,   79.7087,  466.4334],\n       [  10.9072,   69.7238,  376.7858,   11.8127,   77.0799,  437.7213],\n       [   9.3276,   59.098 ,  266.1543,   10.051 ,   64.8891,  304.2147],\n       [  15.0171,   97.5372,  707.0235,   16.8926,  111.5619,  898.9928],\n       [   9.3729,   59.4025,  269.3306,   10.1015,   65.2387,  308.0554],\n       [   8.6235,   54.3609,  216.8247,    9.2656,   59.454 ,  244.6732],\n       [  12.163 ,   78.1726,  464.7968,   13.2137,   86.7749,  543.9887],\n       [  15.5683,  101.3007,  759.8059,   17.6737,  116.7414,  983.6936],\n       [   9.0498,   57.2292,  246.7062,    9.7412,   62.7455,  280.7561],\n       [  11.7338,   75.2842,  434.6173,   12.7343,   83.4567,  507.4315],\n       [   9.1708,   58.0427,  255.1808,    9.8761,   63.679 ,  290.9895],\n       [   9.01  ,   56.9612,  243.9309,    9.6968,   62.4387,  277.4267],\n       [   9.8932,   62.9024,  305.7187,   10.6815,   69.2519,  351.901 ],\n       [  11.1825,   71.5761,  396.081 ,   12.1198,   79.2054,  461.019 ],\n       [  11.2592,   72.0924,  401.4975,   12.2056,   79.7994,  467.6078],\n       [  10.5847,   67.5544,  354.2128,   11.4531,   74.5915,  410.4988],\n       [   9.5782,   60.7825,  283.6118,   10.3299,   66.8184,  325.1771],\n       [   9.3535,   59.2722,  267.9771,   10.0799,   65.0894,  306.4262],\n       [  10.5927,   67.608 ,  354.7567,   11.4619,   74.6524,  411.1372],\n       [   9.8807,   62.8184,  304.8986,   10.6678,   69.1579,  350.9816],\n       [  10.1951,   64.934 ,  326.9357,   11.0187,   71.5854,  377.5887],\n       [  12.0936,   77.7047,  459.8248,   13.1356,   86.234 ,  537.8585],\n       [  15.1329,   98.3272,  718.0442,   17.0568,  112.6482,  916.6424],\n       [   8.839 ,   55.8113,  231.976 ,    9.5063,   61.1201,  263.0225],\n       [   9.5564,   60.6369,  282.1696,   10.3061,   66.6544,  323.5321],\n       [   9.3174,   59.0287,  265.4226,   10.0394,   64.8092,  303.318 ],\n       [   8.1009,   50.8473,  180.4367,    8.684 ,   55.431 ,  201.0126],\n       [   9.7222,   61.7521,  293.7559,   10.4909,   67.9329,  337.4813],\n       [  11.3677,   72.8212,  408.9501,   12.3258,   80.63  ,  476.4263],\n       [  10.2527,   65.3209,  330.9304,   11.0826,   72.0279,  382.3664],\n       [   9.3238,   59.0719,  265.874 ,   10.0466,   64.8589,  303.8646],\n       [  14.3863,   93.2296,  646.5099,   15.9989,  105.632 ,  801.8254],\n       [   9.3007,   58.9159,  264.1887,   10.0205,   64.6774,  301.752 ],\n       [   7.5506,   47.1494,  142.3528,    8.0729,   51.2058,  155.5919],\n       [  10.2578,   65.3549,  331.2848,   11.0883,   72.067 ,  382.7943],\n       [  13.6376,   88.1189,  574.8651,   14.938 ,   98.5988,  686.8758],\n       [   9.3023,   58.928 ,  264.4008,   10.0229,   64.6948,  302.1196],\n       [   9.466 ,   60.0285,  275.8292,   10.2052,   65.9562,  315.8726],\n       [   8.6306,   54.4085,  217.3224,    9.2735,   59.5087,  245.2768],\n       [   8.7563,   55.2546,  226.1579,    9.4139,   60.4805,  255.9737],\n       [   7.611 ,   47.5545,  146.435 ,    8.1394,   51.6649,  160.3431],\n       [   8.6665,   54.6502,  219.8163,    9.3134,   59.7851,  248.2571],\n       [   9.1364,   57.8118,  252.766 ,    9.8377,   63.4136,  288.0622],\n       [   8.7667,   55.3248,  226.9086,    9.4256,   60.5619,  256.9049],\n       [  12.1348,   77.9808,  462.6411,   13.1811,   86.5483,  541.1822],\n       [   9.4365,   59.8298,  273.7458,   10.1722,   65.7275,  313.3403],\n       [  18.0219,  118.062 ,  995.9312,   21.1507,  139.8307, 1363.2019],\n       [  13.7907,   89.1639,  589.5118,   15.1549,  100.0369,  710.3737],\n       [  10.2614,   65.3795,  331.5176,   11.0922,   72.0942,  383.0447],\n       [  12.5586,   80.8321,  492.3442,   13.6539,   89.8202,  577.0486],\n       [   7.5506,   47.1494,  142.3528,    8.0729,   51.2058,  155.5919],\n       [   9.5308,   60.4644,  280.3698,   10.2775,   66.4563,  321.3552],\n       [  10.5667,   67.4334,  352.9452,   11.433 ,   74.4525,  408.9583],\n       [   8.1663,   51.2877,  185.0309,    8.757 ,   55.9366,  206.5679],\n       [  10.3573,   66.024 ,  338.2073,   11.199 ,   72.8328,  391.091 ],\n       [  12.8676,   82.9114,  513.9988,   13.9987,   92.2059,  603.1886],\n       [  10.4814,   66.8595,  346.9893,   11.3379,   73.7948,  401.796 ],\n       [   9.6065,   60.9733,  285.6454,   10.3617,   67.0393,  327.6916],\n       [  13.0282,   83.9913,  525.2371,   14.1777,   93.4447,  616.7432],\n       [   9.7966,   62.2522,  298.9523,   10.5737,   68.5061,  343.7401],\n       [  11.6324,   74.6012,  427.4075,   12.6205,   82.669 ,  498.603 ],\n       [  12.4698,   80.2351,  486.1544,   13.5551,   89.1363,  569.6125],\n       [  11.2885,   72.2889,  403.4749,   12.2379,   80.022 ,  469.9058],\n       [   7.5506,   47.1494,  142.3528,    8.0729,   51.2058,  155.5919],\n       [   8.598 ,   54.1899,  215.063 ,    9.2373,   59.2586,  242.5716],\n       [  15.2341,   99.0195,  727.8384,   17.2002,  113.6023,  932.4104],\n       [  11.2617,   72.1085,  401.5663,   12.2078,   79.8138,  467.5639],\n       [  12.3339,   79.3207,  476.6373,   13.4035,   88.0874,  558.1314],\n       [   8.0548,   50.5374,  177.2569,    8.6328,   55.0774,  197.2352],\n       [   8.4344,   53.0888,  203.5882,    9.0547,   57.9949,  228.7109],\n       [   9.497 ,   60.2371,  277.9926,   10.2397,   66.1951,  318.4728],\n       [  10.3194,   65.7695,  335.5668,   11.1568,   72.5412,  387.9161],\n       [  10.5342,   67.2141,  350.6254,   11.3964,   74.1993,  406.112 ],\n       [   7.5506,   47.1494,  142.3528,    8.0729,   51.2058,  155.5919],\n       [  15.1567,   98.4901,  720.3488,   17.0905,  112.8727,  920.3526],\n       [  19.559 ,  129.0098, 1197.0854,   23.3427,  155.8972, 1712.7678],\n       [   9.4838,   60.1485,  277.1062,   10.2252,   66.095 ,  317.4497],\n       [   8.0236,   50.3276,  175.0398,    8.5979,   54.8354,  194.5172],\n       [  11.2347,   71.9266,  399.6845,   12.1777,   79.6056,  465.3083],\n       [   9.2194,   58.37  ,  258.59  ,    9.9304,   64.0546,  295.1059],\n       [  10.5774,   67.5053,  353.6504,   11.4447,   74.5331,  409.7544],\n       [   7.621 ,   47.6219,  147.1266,    8.1506,   51.7418,  161.1649],\n       [  13.2504,   85.4873,  540.9583,   14.4264,   95.1671,  635.9028],\n       [   8.8892,   56.1483,  235.4091,    9.5618,   61.5036,  267.0682],\n       [   9.4933,   60.2123,  277.7302,   10.2356,   66.1665,  318.1511],\n       [  11.3781,   72.8918,  409.7485,   12.3378,   80.7136,  477.4713],\n       [  11.3985,   73.0287,  411.177 ,   12.3605,   80.8708,  479.2002],\n       [  11.2462,   72.0039,  400.4929,   12.1905,   79.6944,  466.2888],\n       [   8.7099,   54.9421,  222.859 ,    9.3618,   60.1201,  251.933 ],\n       [  12.2432,   78.7113,  470.3161,   13.3026,   87.3892,  550.5336],\n       [  12.2655,   78.8613,  471.8729,   13.3274,   87.5611,  552.4059],\n       [   9.8663,   62.721 ,  303.8285,   10.6514,   69.0438,  349.6173],\n       [   8.5953,   54.1714,  214.8793,    9.2343,   59.2378,  242.3607],\n       [  13.2877,   85.7375,  543.445 ,   14.4673,   95.4492,  638.7512],\n       [   9.5655,   60.6976,  282.7838,   10.3161,   66.7233,  324.2507],\n       [  10.7939,   68.9621,  368.8662,   11.6864,   76.2064,  428.1785],\n       [  10.7784,   68.8567,  367.6854,   11.6686,   76.0821,  426.6453],\n       [   7.9364,   49.7411,  168.9717,    8.5008,   54.1641,  187.2441],\n       [  12.0162,   77.1834,  454.3514,   13.049 ,   85.634 ,  531.1945],\n       [  10.5598,   67.3875,  352.506 ,   11.4256,   74.4013,  408.4792],\n       [  12.1577,   78.1373,  464.4493,   13.2079,   86.7352,  543.5955],\n       [  17.8039,  116.5658,  974.0592,   20.8416,  137.7527, 1327.6065],\n       [   9.5498,   60.5921,  281.6981,   10.2986,   66.6028,  322.9562],\n       [  12.287 ,   79.0058,  473.4052,   13.3515,   87.728 ,  554.2913],\n       [   9.2397,   58.5061,  259.9641,    9.9527,   64.2089,  296.7086],\n       [  11.6174,   74.5007,  426.4443,   12.6043,   82.5572,  497.5481],\n       [  16.5667,  108.118 ,  855.5138,   19.0884,  126.1253, 1137.3353],\n       [   8.9309,   56.429 ,  238.343 ,    9.6084,   61.8261,  270.6226],\n       [   8.0861,   50.748 ,  179.4391,    8.6677,   55.3186,  199.8549],\n       [  10.2834,   65.5268,  333.033 ,   11.1166,   72.2625,  384.85  ],\n       [  10.7728,   68.8202,  367.3767,   11.6629,   76.0431,  426.3655],\n       [   9.3128,   58.9977,  265.0728,   10.0342,   64.7726,  302.8606],\n       [  15.4704,  100.6326,  750.4594,   17.535 ,  115.8224,  968.7091],\n       [  14.6606,   95.1019,  672.7804,   16.3874,  108.2089,  843.9896],\n       [   9.9461,   63.2586,  309.5092,   10.741 ,   69.6641,  356.5802],\n       [   7.5506,   47.1494,  142.3528,    8.0729,   51.2058,  155.5919],\n       [   9.5781,   60.7829,  283.6745,   10.3302,   66.8213,  325.3281],\n       [  19.547 ,  128.9242, 1195.5124,   23.3256,  155.7715, 1710.0344],\n       [   8.5352,   53.7676,  210.675 ,    9.1673,   58.7744,  237.2881],\n       [   8.3059,   52.2246,  194.6142,    8.9115,   57.0044,  217.912 ],\n       [  11.325 ,   72.5347,  406.0558,   12.2787,   80.305 ,  473.0479],\n       [   8.3927,   52.8091,  200.7403,    9.0086,   57.6766,  225.357 ],\n       [  11.5764,   74.2257,  423.6606,   12.5591,   82.2449,  494.2922],\n       [   9.9536,   63.3096,  310.0412,   10.7494,   69.7226,  357.2238],\n       [   9.7709,   62.0802,  297.1997,   10.5454,   68.3104,  341.674 ],\n       [  12.1156,   77.8529,  461.4034,   13.1604,   86.4054,  539.8098],\n       [   9.6835,   61.492 ,  291.0552,   10.4478,   67.6347,  334.2326],\n       [   8.6631,   54.6272,  219.5553,    9.3095,   59.7578,  247.915 ],\n       [  13.9321,   90.1292,  603.0793,   15.3552,  101.3659,  732.1629],\n       [  10.539 ,   67.2471,  350.9717,   11.4019,   74.2373,  406.5338],\n       [  11.4926,   73.6621,  417.7728,   12.4656,   81.5975,  487.1607],\n       [  18.2436,  119.6407, 1024.9392,   21.4668,  142.1477, 1413.6119],\n       [  11.4456,   73.346 ,  414.4964,   12.4132,   81.2355,  483.2263],\n       [   8.9925,   56.8432,  242.6543,    9.677 ,   62.3013,  275.8241],\n       [   7.8618,   49.2396,  163.7426,    8.4176,   53.5884,  180.9234],\n       [  19.93  ,  131.6524, 1245.6417,   23.8719,  159.7755, 1797.1488],\n       [   9.3427,   59.1991,  267.1962,   10.0677,   65.0047,  305.4582],\n       [   9.4251,   59.7536,  273.0102,   10.1598,   65.6426,  312.5264],\n       [   8.9748,   56.7238,  241.4012,    9.6572,   62.1639,  274.2988],\n       [   7.6258,   47.6538,  147.4543,    8.1558,   51.7782,  161.555 ],\n       [  10.6416,   67.9373,  358.1832,   11.5165,   75.0302,  415.2688],\n       [  10.1792,   64.826 ,  325.7648,   11.0005,   71.4596,  376.115 ],\n       [  11.5671,   74.1622,  422.9207,   12.5482,   82.1688,  493.2975],\n       [  10.624 ,   67.8181,  356.8972,   11.4965,   74.8915,  413.6592],\n       [   8.9591,   56.6191,  240.3792,    9.6402,   62.0466,  273.1538],\n       [   9.5439,   60.5528,  281.2797,   10.2921,   66.5573,  322.4399],\n       [  10.6811,   68.202 ,  360.8694,   11.56  ,   75.331 ,  418.4201],\n       [  16.4826,  107.5429,  847.3705,   18.9693,  125.3326, 1124.2211],\n       [   7.5506,   47.1494,  142.3528,    8.0729,   51.2058,  155.5919],\n       [  16.5742,  108.1692,  856.2222,   19.0991,  126.1956, 1138.4664],\n       [  10.8493,   69.3335,  372.6396,   11.7476,   76.6287,  432.6111],\n       [   9.1243,   57.7297,  251.8442,    9.8238,   63.3166,  286.8634],\n       [   7.737 ,   48.4012,  155.1323,    8.2792,   52.6314,  170.6865],\n       [   7.6379,   47.7355,  148.2966,    8.1693,   51.8716,  162.5602],\n       [   8.5894,   54.1317,  214.4651,    9.2277,   59.1922,  241.8607],\n       [  12.0384,   77.3346,  456.0904,   13.0748,   85.8143,  533.5059],\n       [  13.7057,   88.583 ,  581.3386,   15.0344,   99.237 ,  697.2426],\n       [  12.2067,   78.4662,  467.8155,   13.2622,   87.1101,  547.5825],\n       [   9.7132,   61.6919,  293.1712,   10.4811,   67.8655,  336.8308],\n       [  10.4027,   66.3303,  341.44  ,   11.25  ,   73.186 ,  395.0486],\n       [   9.354 ,   59.2753,  267.9728,   10.0802,   65.0914,  306.3737],\n       [   7.7453,   48.4564,  155.7013,    8.2884,   52.6946,  171.365 ],\n       [   8.5546,   53.8975,  212.0113,    9.1888,   58.9228,  238.8802],\n       [   9.1522,   57.9178,  253.8514,    9.8552,   63.5345,  289.3476],\n       [   9.4648,   60.0208,  275.7398,   10.2039,   65.9469,  315.7536],\n       [   8.9066,   56.2654,  236.665 ,    9.5814,   61.6395,  268.6307],\n       [   7.7648,   48.5879,  157.0469,    8.31  ,   52.8444,  172.9591],\n       [   7.623 ,   47.6353,  147.2652,    8.1528,   51.7571,  161.3314],\n       [  11.343 ,   72.6547,  407.2352,   12.2983,   80.4397,  474.3814],\n       [   9.0301,   57.0963,  245.3211,    9.7191,   62.5929,  279.0837],\n       [   8.9955,   56.8634,  242.8833,    9.6805,   62.3252,  276.1255],\n       [   8.7078,   54.9285,  222.738 ,    9.3597,   60.1053,  251.8147],\n       [  12.387 ,   79.6788,  480.4052,   13.463 ,   88.4998,  562.7303],\n       [   9.4183,   59.7075,  272.4506,   10.1518,   65.5864,  311.7483],\n       [  12.8774,   82.9773,  514.7418,   14.0099,   92.2839,  604.1579],\n       [   7.9176,   49.6151,  167.6611,    8.4799,   54.0196,  185.6639],\n       [  11.3797,   72.9029,  409.9181,   12.3399,   80.7286,  477.7459],\n       [   9.8288,   62.4702,  301.3139,   10.6103,   68.76  ,  346.7085],\n       [  13.3388,   86.0819,  547.1149,   14.5248,   95.8478,  643.2887],\n       [  14.7493,   95.7071,  681.255 ,   16.5131,  109.0416,  857.5805],\n       [  13.9646,   90.351 ,  606.1504,   15.4014,  101.6705,  737.0677],\n       [  17.0736,  111.5775,  903.9753,   19.8066,  130.8855, 1215.0681],\n       [   8.1734,   51.334 ,  185.4117,    8.7642,   55.9856,  206.8964]])"
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = scaler.inverse_transform(new_dataset.detach().numpy())\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('new_breast.csv', new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}